## Motivation: Data-Intensive Science {.smaller}

::: columns
::: {.column width="50%"}
![](images/data_plot.svg)

-  Data-intensive science experiments process huge amounts of data.
-  Data growth predictions keep moving the bar up.

:::
::: {.column width="50%"}
![](images/lhcopen_data.svg)

-  Data is continuously distributed across the world for research.
-  In one year of LHC running, over an exabyte of data is accessed.

:::
:::

::: {.footer}
Introduction
:::

::: {.notes}
- To expand on my motivation, I'll first talk about the use case that initially inspired my work.
- As you know, large science programs in fields like high-energy physics, genomics etc. deal with experiments that produce huge amounts of data.
- For instance, for the LHC, in one year, over an exabyte of data is accessed.
- This data also has to constantly be distributed across the world for research, which is a significant networking challenge.
:::

## Motivation: Data-Intensive Science {.smaller}

*N-DISE: NDN-based Data Distribution for Large-Scale Data-Intensive Science* [^ndise]:

::: {.incremental}
-   First high-performance NDN-based data delivery system for large-scale data-intensive science experiments.
-   Integration of state-of-the-art NDN forwarder, intelligent caching and forwarding, high-performance consumer/producer applications.
-   Extensive testing over wide-area network spanning 5 US campuses using CMS experiment data.
-   Individual contributions:
    - Built local testbed for prototyping.
    - Supported WAN deployment and testing.
    - Supported demonstrations during SC21 and SC22.
:::

[^ndise]: "N-DISE: NDN-based data distribution for large-scale data-intensive science", Wu, Y., Mutlu, F. V., Liu, Y., Yeh, E., Liu, R., ACM ICN 2022 @wu2022ndise.

::: {.footer}
Introduction
:::

::: {.notes}
- To address this, our lab led an effort to build a state-of-the-art, Named Data Networking based data distribution system, which you can read about in the paper we published in ICN 2022.
- The point here is, even in this state-of-the-art prototype, we were only able to allocate a small amount of cache space at each router. As you can see it is a drop in the bucket compared to the volumes we expect to be working with.
- I also want to briefly mention that, in a separate paper that describes a core technology that enabled the N-DISE system (the NDN-DPDK forwarder), the problem of scaling cache capacities and the need for specialized policies for operating larger caches was specifically outlined as part of future outlook.
- So there's a gap here that motivated my work.
:::

## Motivation: Data-Intensive Science

::: {style="font-size: 85%;"}
**Cache capacity challenge:** 20 GB of DRAM cache space allocated at each node.

::: {.incremental}
-   DRAM is the standard cache device due its speed; but is expensive and has limited capacity.
-   Next best option is NVMe SSD; is cheap and has large capacity, but much slower than DRAM.
-   Logical next step: use both! 
:::
:::

::: {.footer}
Introduction
:::

::: {.notes}
- Placeholder.
:::

## Motivation: Data-Intensive Science

::: {style="font-size: 85%;"}
**Cache capacity challenge:** 20 GB of DRAM cache space allocated at each node.

-   DRAM is the standard cache device due its speed; but is expensive and has limited capacity.
-   Next best option is NVMe SSD; is cheap and has large capacity, but much slower than DRAM.
-   Logical next step: use both! 
-   Open problem: "Expanding capacities with persistent memory or NVMe disk storage require novel multi-tier caching algorithms."[^ndndpdk]
:::

[^ndndpdk]: "NDN-DPDK: NDN forwarding at 100 Gbps on commodity hardware", Shi, J., Pesavento, D., & Benmohamed, L., ACM ICN 2020 @shi2020ndn.

::: {.footer}
Introduction
:::

::: {.notes}
- Placeholder.
:::