## Experiment Setting

::: {.incremental}
-  $\mc{S}(k)$ are selected uniformly at random
-  Routing: *Any* shortest path (in number of hops) between $n$ and $\mc{S}(k)$
-  Two cache tiers at every node
-  Requests generated for 100 simulation seconds, run terminates when all requests are resolved
-  Virtual plane algorithm slot length of 1 second, sliding window of size 100 slots
:::

::: {.footer}
Experiments
:::

::: {.notes}
- There are some additional assumptions that pertain to the experiment setting so let's go over those
:::

## Baselines

::: {.incremental}
-  Adapted replacements: LRU, LFU, FIFO, RANDOM
   -  LRU, FIFO and RANDOM are cost-unaware, paired with Leave Copy Everywhere admission
   -  LFU admission based on frequency
      - Cost-aware LFU adaptation uses similar benefit metric
-  All baseline caching policies paired with Least Response Time forwarding
:::

::: {.footer}
Experiments
:::

::: {.notes}
- Because there aren't really any policies, novel or established, we could directly compare against, we adapted our own baselines from well-known single-cache policies
- We adapted LRU, FIFO and RANDOM replacement but for these there isn't a good metric to incorporate costs, so those are cost-unaware and for admission they're paired with the basic Leave Copy Everywhere policy
- We adapted LFU similarly, but also made a cost-aware LFU adaptation which uses a cache benefit metric similar to the one we devised for our aproach
- Least response time forwarding simply chooses the link with smallest delay for last satisfied request
:::

## Topologies {.smaller}

::: columns
::: {.column width="50%"}
::: {layout="[[-1],[-1],[1]]"}
![Abilene (11 nodes)](images/abilene.svg)
:::
:::
::: {.column width="50%"}
![GEANT (34 nodes)](images/geant.svg)
:::
:::

::: {.footer}
Experiments
:::

::: {.notes}
- Alright, so when it comes to experiment settings, I first have to stress that the experimentation space for this work is enormous
- So the results I'll show here are those that I think most succinctly show that our approach can deliver on our goals
- To start off, these are the four topologies I conducted experiments over
- On the left are Abilene and Geant which are real network topologies, and on the right are two stylized graphs
:::

## Parameter Reference Table {.smaller}

| Parameter | Description | Value |
|:-:|:-:|:-:|
|$K$|Number of objects in catalog $\mc{K}$|1000|
|$\sum_{\kin} \lambda^k_n$|Total request arrival rate at each $n$ in objects/sec|10|
|$\alpha$|Zipf's law parameter for object popularity distribution|0.75|
|$C_{ab}$|Capacity of each link $\abin$, in objects|10|
|$L_{n_1}$|Capacity of tier 1 at each $n$, in objects|5|
|$r_{n_1}$|Read rate of tier 1 at each $n$, in objects/sec|20|
|$c^a_{n_1}$, $c^e_{n_1}$| Admission and eviction costs of tier 1 at each $n$|4, 2|
|$r_{n_2}$|Read rate of tier 2 at each $n$, in objects/sec|10|
|$c^a_{n_2}$, $c^e_{n_2}$| Admission and eviction costs of tier 2 at each $n$|2, 1|
: Common parameters for all scenarios {tbl-colwidths="[10,80,10]"}

::: {.footer}
Experiments
:::

::: {.notes}
- As I said, there are a great number of parameters for these experiments and I'm not going to cover each one in the interest of time, but we have this table for reference if needed
:::

## Cache Capacity

::: columns
::: {.column width="50%"}
![VIP/MVIP vs. LFU](images/size_comp_abilene_075_15_delay.svg)
:::
::: {.column width="50%"}
![Other baselines](images/size_comp_baselines_abilene_075_15_delay.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Delay with increasing cache capacities. Abilene, $\gamma=0.75$, $\lambda=15$.
:::

::: {.footer}
Experiments
:::

## Cache Capacity

::: columns
::: {.column width="47%"}
![Cache hits](images/size_comp_abilene_075_15_hits.svg)
:::
::: {.column width="53%"}
![Cache read delays](images/size_comp_abilene_075_15_hit_delays.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Cache hits and delay due to cache reads. Abilene, $\gamma=0.75$, $\lambda=15$.
:::

::: {.footer}
Experiments
:::

## Cache Capacity

![VIP/MVIP vs. LFU](images/size_comp_geant_all_075_15.svg){width=55% height=55% fig-align="center"}

::: {style="font-size: 80%; text-align: center"}
Delay with increasing cache capacities. Geant, $\gamma=0.75$, $\lambda=15$.
:::

::: {.footer}
Experiments
:::

## Cache Capacity

::: columns
::: {.column width="47%"}
![Cache hits](images/size_comp_geant_075_15_hits.svg)
:::
::: {.column width="53%"}
![Cache read delays](images/size_comp_geant_075_15_hit_delays.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Cache hits and delay due to cache reads. Geant, $\gamma=0.75$, $\lambda=15$.
:::

::: {.footer}
Experiments
:::

## Request Pattern Parameters

::: columns
::: {.column width="50%"}
![$\gamma=0.75$](images/mt_req_geant_delay.svg)
:::
::: {.column width="50%"}
![$\lambda=15$](images/zipf_geant_15_delay.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Delay with increasing $\lambda$ and $\gamma$. Geant topology. $L_{n_2}$ chosen based on minimum delay points for two tier cases.
:::

## More Topologies {.smaller}

![Placeholder.](images/alltops_075_15.svg){width=70% height=70% fig-align="center"}

![Placeholder.](images/alltops_075_15_table.svg){width=70% height=70% fig-align="center"}

::: {.footer}
Experiments
:::

## Delay-Penalty Trade-off

::: columns
::: {.column width="50%"}
![$\gamma=0.75$](images/mt_pen_abilene_15_075.svg)
:::
::: {.column width="50%"}
![$\gamma=0.5$](images/mt_pen_abilene_15_05.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Delay vs. penalty curves for MVIP and PA-LFU policies. Abilene, $\lambda=15$. $\omega$ decreases to the right.
:::

::: {.footer}
Experiments
:::

## Delay-Penalty Trade-off

::: columns
::: {.column width="50%"}
![$\gamma=0.75$](images/mt_pen_geant_15_075.svg)
:::
::: {.column width="50%"}
![$\gamma=0.5$](images/mt_pen_geant_15_05.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Delay vs. penalty curves for MVIP and PA-LFU policies. Geant, $\lambda=15$. $\omega$ decreases to the right.
:::

::: {.footer}
Experiments
:::

## Interest Aggregation

Placeholder.

::: {.footer}
Experiments
:::

## Interest Aggregation

::: columns
::: {.column width="50%"}
![$\gamma=0.75$](images/mt_req_ia_vip_geant_delay.svg)
:::
::: {.column width="50%"}
![$\lambda=30$](images/zipf_ia_geant_delay.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
VIP vs. MVIP, with and without interest aggregation. Geant, $L_{n_1}=5$, $L_{n_2}=200$ for MVIP and $L_{n_1}=13$ for VIP.
:::

::: {.footer}
Experiments
:::

## Interest Aggregation

::: columns
::: {.column width="50%"}
![VIP/MVIP vs. LFU](images/size_comp_ia_geant_075_50_delay.svg)
:::
::: {.column width="50%"}
![Other baselines](images/size_comp_ia_geant_075_50_baselines_delay.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Delay with increasing cache capacities under interest aggregation. Geant, $\gamma=0.75$, $\lambda=50$.
:::

::: {.footer}
Experiments
:::

## Interest Aggregation

::: columns
::: {.column width="50%"}
![Cache hits](images/size_comp_ia_geant_075_50_hits.svg)
:::
::: {.column width="50%"}
![Second tier hits vs. reads](images/size_comp_ia_geant_075_50_hits_reads_tier2.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Number of cache hits and cache reads issued under interest aggregation. Geant topology, $\lambda=50$, $\gamma=0.75$.
:::

::: {.footer}
Experiments
:::

## Interest Aggregation

::: columns
::: {.column width="50%"}
![$\gamma=0.75$](images/mt_pen_ia_geant_30_075.svg)
:::
::: {.column width="50%"}
![$\gamma=0.5$](images/mt_pen_ia_geant_30_05.svg)
:::
:::

::: {style="font-size: 80%; text-align: center"}
Delay vs. penalty curves, MVIP vs. PA-LFU with and without interest aggregation. Geant, $\lambda=30$. $\omega$ decreases to the right.
:::

::: {.footer}
Experiments
:::