<!DOCTYPE html>
<html lang="en"><head>
<script src="proposal_slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="proposal_slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="proposal_slides_files/libs/quarto-html/popper.min.js"></script>
<script src="proposal_slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="proposal_slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="proposal_slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="proposal_slides_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="proposal_slides_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <meta name="author" content="Research Advisor: Edmund Yeh Committee Members: Elif Uysal, Stratis Ioannidis">
  <title>Cost-aware Joint Caching and Forwarding in Networks with Diverse Cache Resources</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="proposal_slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="proposal_slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #383a42;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #383a42; } /* Normal */
    code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
    code span.an { color: #50a14f; } /* Annotation */
    code span.at { color: #a626a4; } /* Attribute */
    code span.bn { color: #986801; } /* BaseN */
    code span.bu { color: #a626a4; } /* BuiltIn */
    code span.cf { color: #a626a4; } /* ControlFlow */
    code span.ch { color: #50a14f; } /* Char */
    code span.cn { color: #986801; } /* Constant */
    code span.co { color: #a0a1a7; font-style: italic; } /* Comment */
    code span.cv { color: #e45649; font-style: italic; } /* CommentVar */
    code span.do { color: #e45649; } /* Documentation */
    code span.dt { color: #a626a4; } /* DataType */
    code span.dv { color: #986801; } /* DecVal */
    code span.er { color: #f44747; text-decoration: underline; } /* Error */
    code span.ex { color: #4078f2; font-weight: bold; } /* Extension */
    code span.fl { color: #986801; } /* Float */
    code span.fu { color: #4078f2; } /* Function */
    code span.im { color: #50a14f; } /* Import */
    code span.in { color: #c45b00; } /* Information */
    code span.kw { color: #a626a4; } /* Keyword */
    code span.op { color: #a626a4; } /* Operator */
    code span.ot { color: #27ae60; } /* Other */
    code span.pp { color: #a626a4; } /* Preprocessor */
    code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
    code span.sc { color: #0184bc; } /* SpecialChar */
    code span.ss { color: #da4453; } /* SpecialString */
    code span.st { color: #50a14f; } /* String */
    code span.va { color: #e45649; } /* Variable */
    code span.vs { color: #da4453; } /* VerbatimString */
    code span.wa { color: #da4453; } /* Warning */
  </style>
  <link rel="stylesheet" href="proposal_slides_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="styles/styles.css">
  <link href="proposal_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="proposal_slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="proposal_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="proposal_slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Cost-aware Joint Caching and Forwarding in Networks with Diverse Cache Resources</h1>
  <p class="subtitle"><s>Farouk Multi</s> Faruk Volkan Mutlu - PhD Proposal Review</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Research Advisor: Edmund Yeh<br>Committee Members: Elif Uysal, Stratis Ioannidis 
</div>
</div>
</div>

</section>
<section id="outline" class="slide level2">
<h2>Outline</h2>
<ul>
<li>Primary Contribution
<ul>
<li><strong>Introduction</strong>: Motivation, Challenges, Related Work</li>
<li><strong>Technical</strong>: System Model, Optimization Framework</li>
<li><strong>Practical</strong>: Strategy, Experiments, Results</li>
<li><strong>Proposed Work</strong></li>
</ul></li>
<li>Other Contributions</li>
<li>Conclusion and Acknowledgements</li>
</ul>
<div class="footer">
<p>Outline</p>
</div>
<div class="hidden">
<p><span class="math display">\[
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\nin}{n \in \mc{N}}
\newcommand{\kin}{k \in \mc{K}}
\newcommand{\jin}{j \in \mc{J}_n}
\newcommand{\kjin}{(k,j) \in \mc{B}_{n,i}}
\newcommand{\iin}{i \in \mc{I}_n}
\newcommand{\ain}{a \in \mc{N}}
\newcommand{\bin}{b \in \mc{N}}
\newcommand{\abin}{(a,b) \in \mc{L}}
\newcommand{\about}{(a,b) \not\in \mc{L}^k}
\newcommand{\betasum}{\sum\limits ^{\sigma_n}_{i=1} \beta_{n,i}}
\newcommand{\betasumnl}{\sum ^{\sigma_n}_{i=1} \beta_{n,i}}
\newcommand{\betasumind}{\sum\limits ^{\sigma_n}_{i=1} \beta_{n,i}\mathbf{1}_{[\kjin]}}
\newcommand{\minpen}{\Psi(\boldsymbol{\lambda})}
\newcommand{\drift}{\Delta(\mathbf{V}(t))}
\newcommand{\pen}{\mathbb{E}[p(t)|\mathbf{V}(t)]}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\definecolor{neured}{RGB}{200, 16, 46}
\]</span></p>
</div>
</section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>

</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<div>
<ul>
<li class="fragment"><strong>Context</strong>: Information-centric networking (ICN), in-network caching, content delivery networks (CDNs)</li>
<li class="fragment"><strong>Motivation</strong>: Data volume grows exponentially, cache capacities are stagnant</li>
<li class="fragment"><strong>Challenge</strong>: Operating larger caches in a efficiently is difficult
<ul>
<li class="fragment">Are slower storage elements viable as caches?</li>
<li class="fragment">What are the costs of operating large caches?</li>
<li class="fragment">How can we get the most out of caches in the network?</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To begin, here’s a brief overview of my primary research that I will present today.</li>
<li>First off, for context, my work is based on the Information-centric Networking paradigm, or ICN for short.</li>
<li>The Internet today is built on communication network principles, but its primary use is data distribution, so ICN aims to steer it in that direction by making data the primary entity of the network, rather than endpoints.</li>
<li>In particular, I’m targeting a core functionality of ICNs called in-network caching, which lets every router in the network maintain its own cache, making caching decentralized and more scalable.</li>
<li>However, my work is also applicable within today’s Internet, especially for systems like CDNs, where it could be used as an overlay.</li>
<li>The main motivation for my work is simply that the volume of data continuously grows, but the capacities of our caches are somewhat stagnant.</li>
<li>Of course there are many obstacles in the way of scaling cache capacities. We’ll specifically look at three considerations: (1) are slower storage elements viable as caches? (2) what are the costs of operating large caches? (3) how can we get the most out of caches in the network?</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="overview-1" class="slide level2">
<h2>Overview</h2>
<ul>
<li><strong>Context</strong>: Information-centric networking (ICN), in-network caching, content delivery networks (CDNs)</li>
<li><strong>Motivation</strong>: Data volume grows exponentially, cache capacities are stagnant</li>
<li><strong>Challenge</strong>: Operating larger caches in a efficiently is difficult</li>
<li><strong>Goal</strong>: Caching policy that addresses these considerations</li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>By the end, our goal is to come up with a policy that addresses these considerations</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="use-case-data-intensive-science" class="slide level2">
<h2>Use Case: Data-Intensive Science</h2>
<ul>
<li>Data-intensive science experiments (high-energy physics, genomics etc.) process huge amounts of data
<ul>
<li>In one year of LHC running, over an exabyte (<span class="math inline">\(10^{18}\)</span> bytes) of data is accessed</li>
<li>In November 2018, 16 petabytes (<span class="math inline">\(1.6 \times 10^{16}\)</span> bytes) of data were written on tape at CERN</li>
</ul></li>
<li>Data is continuously distributed across the world for research</li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To expand on my motivation, I’ll first talk about the use case that initially inspired my work.</li>
<li>As you know, large science programs in fields like high-energy physics, genomics etc. deal with experiments that produce huge amounts of data.</li>
<li>For instance, for the LHC, in one year, over an exabyte of data is accessed.</li>
<li>This data also has to constantly be distributed across the world for research, which is a significant networking challenge.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="use-case-data-intensive-science-1" class="slide level2">
<h2>Use Case: Data-Intensive Science</h2>
<ul>
<li><em>“N-DISE: NDN-based Data Distribution for Large-Scale Data-Intensive Science”</em>, Y. Wu, F. V. Mutlu, et al.
<ul>
<li>20 gigabytes (<span class="math inline">\(2 \times 10^{10}\)</span> bytes) of DRAM cache space at each node</li>
<li>“Increasing capacities via NVMe SSDs require novel caching strategies” (NDN-DPDK forwarder paper<sup>1</sup>)</li>
</ul></li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To address this, our lab led an effort to build a state-of-the-art, Named Data Networking based data distribution system, which you can read about in the paper we published in ICN 2022.</li>
<li>The point here is, even in this state-of-the-art prototype, we were only able to allocate a small amount of cache space at each router. As you can see it is a drop in the bucket compared to the volumes we expect to be working with.</li>
<li>I also want to briefly mention that, in a separate paper that describes a core technology that enabled the N-DISE system (the NDN-DPDK forwarder), the problem of scaling cache capacities and the need for specialized policies for operating larger caches was specifically outlined as part of future outlook.</li>
<li>So there’s a gap here that motivated my work.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn1"><p>“NDN-DPDK: NDN forwarding at 100 Gbps on commodity hardware”, Shi, J., Pesavento, D., &amp; Benmohamed, L, ACM ICN 2020.</p></li></ol></aside></section>
<section id="the-capacity-challenge" class="slide level2">
<h2>The Capacity Challenge</h2>
<div>
<ul>
<li class="fragment">DRAM is the primary cache device since it is fast (32-64 GB/s for DDR5)</li>
<li class="fragment">However, DRAM offers small capacities at a high and exponentially increasing cost ($3 to $12 / GB)</li>
<li class="fragment">Next best option is NVMe SSD, offering large capacities at significantly lower costs ($0.1 / GB)</li>
<li class="fragment">NVMe SSDs are much slower than DRAM (11.7 GB/s for fastest PCIe 5.0)</li>
</ul>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now I want to give you a better idea about why scaling cache capacities is such a challenge.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="capacity-challenge-toy-example" class="slide level2 smaller">
<h2>Capacity Challenge: Toy Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/toynet_cache.svg" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(C_{ab}\)</span></td>
<td style="text-align: left;">Capacity of link <span class="math inline">\((a,b)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mathcal{N}_c\)</span></td>
<td style="text-align: left;">Set of consumer nodes</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(r_{n_j}\)</span></td>
<td style="text-align: left;">Read rate of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(L_{n_j}\)</span></td>
<td style="text-align: left;">Cache size of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:50%;">
<ul>
<li>Catalog of 1000 objects, ranked in popularity by <span class="body-highlight">Zipf’s law</span></li>
<li>Objects cached by rank:
<ul>
<li>Tier 1: 1-10</li>
<li>Tier 2: 11-40</li>
<li>Tier 3: 41-100</li>
</ul></li>
</ul>
</div>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now, to both illustrate the capacity challenge more precisely, and to underline how slower caches may help us here, I brought in a toy example.</li>
<li>Here we’re looking at a simple network with a catalog of objects, all hosted by one server.</li>
<li>We assume the popularity distribution of these objects are governed by Zipf’s law. We have a set of consumers making requests for these objects, which go through a forwarder.</li>
<li>The forwarder has three potential tiers of cache, with the first being a fast and small tier, the middling being a lot larger but slower, then the last one being even larger but much slower.</li>
<li>If the forwarder can respond to a request from one its cache tiers, it does so instead of forwarding it to the server. There is a fixed caching policy at the forwarder, according to a priori knowledge of object popularities, as you can see on the screen.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="case-for-additional-slower-caches" class="slide level2 smaller">
<h2>Case for Additional, Slower Caches</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/zipf_1k.svg"></p>
<ul>
<li>Most popular 1% of objects make up one fifth of all requests</li>
<li>Most popular 10% of objects make up half of all requests</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/two_tiers.svg"></p>
<ul>
<li>Second tier operates slower but improves delay for high request rates</li>
<li>This is due to the diminishing returns emerging from Zipf’s law</li>
</ul>
</div>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>First off, on the left hand side, we see the CDF for Zipf’s law. The key observation there is that, in this network, roughly one fifth of all requests will be for the most popular 1% of objects, and half of all requests will be for the most popular 10%.</li>
<li>Now, on the right hand side, we see how adding the middling tier on top of the first tier impacts the total delay in the network. Even though the second tier is slower, it improves delay when there’s more traffic.</li>
<li>This can be linked directly to our observation from Zipf’s law, because even though the second tier has a larger amount of objects cached, the frequency of requests that hit the second tier does not exceed its read capacity, since those objects are less popular.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="case-for-additional-slower-caches-1" class="slide level2 smaller">
<h2>Case for Additional, Slower Caches</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/zipf_1k.svg"></p>
<ul>
<li>Most popular 1% of objects make up one fifth of all requests</li>
<li>Most popular 10% of objects make up half of all requests</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/three_tiers.svg"></p>
<ul>
<li>Addition of the third tier impacts performance negatively</li>
<li>This is due to trading link delay with cache read delay</li>
</ul>
</div>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>However, adding the last tier, even though it expands our total cache capacity, impacts delay negatively</li>
<li>Because what I just explained does not hold for the third tier since its much larger and much slower</li>
<li>So we end up trading the delay that would occur on the server link with worse read delay on the third tier.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-cost-challenge" class="slide level2">
<h2>The Cost Challenge</h2>
<ul>
<li>Caches are not free to use: admissions, replacements, even idle operation has an energy cost</li>
</ul>
<div class="columns">
<div class="column" style="width:42%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>DRAM power consumption</figcaption>
<p><img data-src="images/dram_power.png"></p>
</figure>
</div>
</div><div class="column" style="width:58%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>NVMe power consumption</figcaption>
<p><img data-src="images/ssd_power.png"></p>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now of course the capacity challenge is not the only obstacle in our way. There’s another major consideration which is operational costs.</li>
<li>Caches are not free to use, each admission and replacement, and even idle operation has a real cost in energy so if we’re adding even more cache devices we have to be mindful of this cost.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-cost-challenge-1" class="slide level2">
<h2>The Cost Challenge</h2>
<ul>
<li>Caches are not free to use: admissions, replacements, even idle operation has an energy cost</li>
<li>SSDs also wear out over time as they’re written</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>NVMe Endurance</figcaption>
<p><img data-src="images/ssd_endurance.png" style="width:70.0%;height:70.0%"></p>
</figure>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>And on top of that, SSDs also wear out as they’re written, which, although modern SSDs are very durable, is still a significant consideration because dynamic caching operates at a small time scale so storage will be rewritten quite frequently</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="coupling-caching-with-forwarding" class="slide level2">
<h2>Coupling Caching with Forwarding</h2>
<ul>
<li>Benefits of caching more pronounced when caching and forwarding decisions are tightly coupled
<ul>
<li>“<em>Coupling caching and forwarding: benefits, analysis, and implementation</em>”, G. Rossini, D. Rossi, ICN 2014</li>
</ul></li>
<li>This is even more critical with larger, slower caches</li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Finally, we look at the question of, we can handle caching adequately, how can we make sure we’re actually making the most of those caches in the network?</li>
<li>This is where the act of tying caching and forwarding together comes in.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="goal" class="slide level2">
<h2>Goal</h2>
<p>Develop a joint forwarding and caching policy that:</p>
<ul>
<li>Tracks user demand for objects as basis for decisions</li>
<li>Utilizes diverse cache resources effectively:
<ul>
<li>Ensures devices are receiving <span class="body-highlight">sustainable hit rates</span></li>
<li>Makes <span class="body-highlight">high-value</span> replacement decisions</li>
</ul></li>
<li>Utilizes bandwidth resources effectively:
<ul>
<li>Steers requests toward caching points</li>
<li>Forwards requests avoiding congestion</li>
</ul></li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now, having looked at these considerations, let’s reiterate our goal.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="related-work" class="slide level2">
<h2>Related Work</h2>
<ul>
<li><em>“Multi-Terabyte and multi-Gbps information centric routers”</em>, G. Rossini, D. Rossi, M. Garetto, E. Leonardi, INFOCOM 2014</li>
<li><em>“Hierarchical Content Stores in High-Speed ICN Routers: Emulation and Prototype Implementation”</em>, R. B. Mansilha, L. Saino, M. Barcellos, M. Gallo, E. Leonardi, D. Perino, D. Rossi, ICN 2015</li>
<li><em>“Exploiting parallelism in hierarchical content stores for high-speed ICN routers”</em>, R. B. Mansilha, M. Barcellos, E. Leonardi, D. Rossi, COMNET 2017</li>
</ul>
<div class="footer">
<p>Related Work</p>
</div>
<aside class="notes">
<ul>
<li>Now, to conclude the introduction, I want to briefly point out some related work.</li>
<li>This connected series of papers you see on the screen, which come from the same group that authored the one about coupling caching and forwarding that I just discussed, is the closest related work in my opinion.</li>
<li>These papers lay out similar concerns about cache capacities and the relevant challenges.</li>
<li>However, their work targets the system layer. They deal with lower level implementation details of how to integrate SSDs into the actual data structures that make up the caches in ICNs.</li>
<li>In these works, while the authors rely on traditional cache admission and replacement policies, they also point out that specialized policies may result in better performant systems.</li>
<li>They also do not consider the coupling of forwarding decisions.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="related-work-vip" class="slide level2">
<h2>Related Work: VIP</h2>
<p><em>“VIP: a framework for joint dynamic forwarding and caching in named data networks”</em>, E. M. Yeh, T. Ho, Y. Cui, M. Burd, R. Liu, D. Leong, ACM ICN 2014</p>
<ul>
<li>Couples caching and forwarding</li>
<li>Models read rate of caches</li>
<li>Virtual and data plane separation makes algorithm simpler to operate</li>
<li>Lyapunov drift analysis integrates easily with costs</li>
</ul>
<div class="footer">
<p>Related Work</p>
</div>
<aside class="notes">
<ul>
<li>Lastly, perhaps the single most important paper for my work is the VIP paper by Prof.&nbsp;Yeh and co-authors, as my work directly extends this paper.</li>
<li>So let me go over why that is.</li>
<li>Recall the earlier paper I mentioned about coupling caching and forwarding; coincidentally these two papers appeared in the same conference and the VIP paper proposed a strategy that does exactly that, which suits our goals as well.</li>
<li>Furthermore, this paper includes the read capacities of cache devices in its system model, which is one of the parameters of primary concern to us.</li>
<li>The core feature of this paper is a separation of the data plane mechanisms from the “virtual plane”, where control decisions take place, which we also adopt as it makes building these strategies simpler.</li>
<li>Finally, there is a technical benefit here because the analysis for VIP is based on Lyapunov drift, which has an extension called drift-plus-penalty, that gives us a direct venue for incorporating cache utilization costs.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="system-model" class="title-slide slide level1 center">
<h1>System Model</h1>
<aside class="notes">
<p>That concludes the introduction and leads me into the system model that we’re dealing with.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="system-model-1" class="slide level2">
<h2>System Model</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/system_model.svg" style="width:60.0%;height:60.0%"></p>
</figure>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>Here’s a simple illustration of the system model the separation and interaction between the virtual and data planes we’re adopting from the VIP paper.</li>
<li>The data plane is where actual network functionality is performed. The virtual plane uses the request arrival information from the data plane; its where control decisions are made.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-model" class="slide level2">
<h2>Data Plane Model</h2>
<p>Data plane model based on general ICN principles:</p>
<div>
<ul>
<li class="fragment">Unit of content is <em>data object</em>; each object <span class="math inline">\(\kin\)</span> has a unique source <span class="math inline">\(\mc{S}(k)\)</span></li>
<li class="fragment">Any node <span class="math inline">\(n \not = \mc{S}(k)\)</span> can cache <span class="math inline">\(k\)</span></li>
<li class="fragment">Every data object has the <span class="body-highlight">same size</span><br>
</li>
<li class="fragment">Requests can enter network at any node; sources or caching nodes can respond to requests with data</li>
<li class="fragment">Data responses follow request path back to requester</li>
</ul>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>The principles of the data plane are based on those of a classical ICN.</li>
<li>We use “data object” as the unit of content in the network and assume that each object has a unique source node.</li>
<li>We particularly assume every object has the same size, which is a crucial assumption we’ll need to remember for later.</li>
<li>Requests can enter network at any node. A request for an object can be met with a data response at the source node for that object or at any node that caches that object.</li>
<li>Those data responses will follow the path of the request back to the requester (inverse of the path, of course)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-model-1" class="slide level2">
<h2>Data Plane Model</h2>
<p><span class="body-highlight">Multi-tiered caching model</span> adds following properties:</p>
<div>
<ul>
<li class="fragment">Any node can have any number of cache tiers</li>
<li class="fragment">A node can cache an object in at most one of its tiers (<span class="body-highlight">cache exclusivity</span>)</li>
<li class="fragment">An object evicted from one tier can <span class="body-highlight">migrate</span> to another tier at the same node</li>
</ul>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>The multi-tiered caching model I propose adds the following properties to those basic mechanisms.</li>
<li>Any node can have cache tiers and can cache any object in one of those tiers unless it already sources that object.</li>
<li>A node can cache an object in at most one of its tiers. This means that we don’t duplicate objects across cache tiers. This is a crucial constraint we’ll also need to remember for later.</li>
<li>An object evicted from one tier can migrate to another tier at the same node. So an eviction from one tier is not necessarily final for an object.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-model" class="slide level2">
<h2>Virtual Plane Model</h2>
<p>Virtual plane model based on (Yeh, 2014):</p>
<ul>
<li><em>Virtual interest packets (VIPs)</em> generated alongside exogenous requests</li>
<li>Every node keeps a <span class="body-highlight">VIP counter</span> for every object <span class="math inline">\(\kin\)</span></li>
<li>VIPs are removed at object sources and caching nodes</li>
<li>Discrete time slots <span class="math inline">\(t = \{1,2,...\}\)</span></li>
<li>Beginning of each time slot, each node decides where and how to forward its VIPs, as well as how to cache objects</li>
</ul>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>Now, on to the virtual plane model, which is largely based on the original VIP paper. We’ll go over it briefly.</li>
<li>First off, anytime an exogenous request enters the data plane network, a virtual interest packet (VIP for short) is generated in the virtual plane at that node. These VIPs can only be removed at sources or caching points.</li>
<li>Each node maintains a VIP counter for each object in the network. We can interpret these counts as queues that describe unsatisfied demand for objects. Another useful way to think of VIP counts is as a “potential” value, where the potential is high at request entry points and low at sources and caching points. We’ll refer back to this interpretation later.</li>
<li>We’re considering integer time slots in the virtual plane where caching and forwarding decisions for each time slot are made at the beginning of that time slot and network state changes via events that happen in the data plane within the window from the beginning of one time slot to the next.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-model-1" class="slide level2">
<h2>Virtual Plane Model</h2>
<p>Virtual plane model expanded with multiple cache tiers and <span class="body-highlight">penalties</span>:</p>
<ul>
<li>Each cache admission and eviction in virtual plane incurs a penalty</li>
<li>Network can configure <span class="body-highlight">weight of penalties</span> via parameter <span class="math inline">\(\omega\)</span></li>
</ul>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>The multi-tiered caching model that I propose, which incorporates cache utilization costs, extends the virtual plane model.</li>
<li>Each cache admission and eviction in virtual plane incurs a penalty, and a configurable weight parameter, <span class="math inline">\(\omega\)</span>, lets the network determine the importance of penalties in its overall objective</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="vip-queue-dynamics" class="slide level2">
<h2>VIP Queue Dynamics</h2>
<p><span class="body-highlight">VIP queue evolution</span> for object <span class="math inline">\(k\)</span> at node <span class="math inline">\(n\)</span>, where <span class="math inline">\((x)^+ = max(x,0)\)</span>:</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation}
    V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
    + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \color{#A4804A}{\sum\limits_{j \in \mathcal{J}_n} r_{n_j} s^k_{n_j}(t)} \Bigg)^+    
\end{equation}\]</span>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(V^k_n(t)\)</span>: VIP count for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></p>
<p><span class="math inline">\(A^k_n(t)\)</span>: Number of exogenous requests for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></p>
<p><span class="math inline">\(\mu^k_{ab}(t)\)</span>: Allocated rate of VIPs for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span> during <span class="math inline">\(t\)</span></p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(\mathcal{J}_n\)</span>: Set of cache tiers at <span class="math inline">\(n\)</span></p>
<p><span class="math inline">\(r_{n_j}\)</span>: Read rate of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></p>
<p><span class="math inline">\(s^k_{n_j}(t)\)</span>: Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span></p>
</div>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>This inequality shows how VIP counts change from slot to slot in the virtual plane</li>
<li>First term is VIPs forwarded away from the node, then we have the exogenous arrivals, then VIPs that arrive from other nodes and finally, VIPs removed due to caching. Notice that this term is dependent on the read rate of the cache tier</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="penalty-accumulation" class="slide level2">
<h2>Penalty Accumulation</h2>
<p>Penalty incurred by caching action <span class="math inline">\(s^k_{n_j}(t)\)</span>:</p>
<span class="math display">\[\begin{equation}
    p^k_{n_j}(t) \triangleq
    \left\{ \begin{array}{ll}
        c^a_{n_j}, &amp; \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = 1 \\
        c^e_{n_j}, &amp; \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = -1 \\
       0, &amp; \text{otherwise}
   \end{array} \right.
\end{equation}\]</span>
Sum penalty during <span class="math inline">\(t\)</span>: <span class="math inline">\(p(t) = \sum_{\kin, \nin, \jin} p^k_{n_j}(t)\)</span>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(s^k_{n_j}(t)\)</span>: Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span></p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(c^a_{n_j}\)</span>: Admission cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span> <span class="math inline">\(c^e_{n_j}\)</span>: Eviction cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></p>
</div>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>This definition shows how caching actions translate to penalties incurred</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="virtual-plane-optimization" class="title-slide slide level1 center">
<h1>Virtual Plane Optimization</h1>
<aside class="notes">
<p>With the system model described, we will now look at our control algorithm in the virtual plane.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="optimization-goal" class="slide level2">
<h2>Optimization Goal</h2>
<p><em>“Operate close to VIP network stability region boundary while keeping sum penalty small.”</em></p>
<p>Minimize upper bound of <span class="body-highlight">drift-plus-penalty</span><sup>1</sup> expression:</p>
<span class="math display">\[\begin{equation}
    \drift + \omega \pen
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    \drift \triangleq \mathbb{E}[\mathcal{L}(\mathbf{V}(t+1))-\mc{L}(\mathbf{V}(t))|\mathbf{V}(t)]
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    \mc{L}(\mathbf{V}(t)) \triangleq \sum\limits_{\nin, \kin} (V^k_n(t))^2
\end{equation}\]</span>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The goal of our optimization in the virtual plane, is to operate as close as possible to the boundary of the stability region (which we will define formally later) of the network of VIP queues, while keeping penalties accumulated small</li>
<li>So in this way, we’re not trying to make a precisely optimal decision each time slot, but rather we’re trying to minimize the upper bound on this drift-plus-penalty expression you see on screen, which is based on an extension to Lyapunov optimization devised by Neely</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn2"><p>“Energy optimal control for time-varying wireless networks.”, Neely, M. J, IEEE Trans. Inf. Theory, 2006.</p></li></ol></aside></section>
<section id="virtual-plane-caching" class="slide level2">
<h2>Virtual Plane Caching</h2>
<p>Beginning of each slot <span class="math inline">\(t\)</span>, at each node <span class="math inline">\(n\)</span>, observe <span class="math inline">\((V^k_n(t))_{k \in \mathcal{K}, n \in \mathcal{N}}\)</span> and perform <span class="body-highlight">caching</span> by choosing <span class="math inline">\(s^k_{n_j}(t)\)</span> for each <span class="math inline">\(\kin\)</span> and each <span class="math inline">\(j \in \mathcal{J}_n\)</span> with capacity <span class="math inline">\(L_{n_j}\)</span> to:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - \omega p^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>And here’s how we tackle this optimization. We devise an algorithm that’s made of two steps (caching and forwarding), which chooses the respective variables every time slot, to optimize a certain objective based on the VIP counts. We’re looking at the caching step right now.</li>
<li>Obviously there is a lot of math to get to this expression for the objective function, but I’ll give you the intuition briefly.</li>
<li>Because we want to remove as many VIPs from the network as fast as possible, we want to cache the higher VIP count objects in the faster tiers, which is why the read rate multiplies the VIP count here.</li>
<li>However, we also want to make sure that our choices in caching actions do not add large penalties that outweigh the benefits. Of course the importance of that is determined by omega.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-forwarding" class="slide level2">
<h2>Virtual Plane Forwarding</h2>
<p>Perform <span class="body-highlight">forwarding</span> as in (Yeh, 2014), by choosing <span class="math inline">\(\mu^k_{ab}(t)\)</span> for each <span class="math inline">\(\kin\)</span> and <span class="math inline">\(\abin\)</span>:</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\abin} \mu^k_{ab}(t) (V^k_a(t) - V^k_b(t)) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} \mu^k_{ab}(t) \leq C_{ba}, \; \forall \, \abin \\
        &amp; \quad \mu^k_{ab}(t) \geq 0, \; \forall \, \kin, \; \abin \\
        &amp; \quad \mu^k_{ab}(t) = 0, \; \forall \, \kin, \; (a,b) \not \in \mc{L}^k
\end{align}\]</span>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\mc{L}\)</span>: Set of links in network</p>
<p><span class="math inline">\(C_{ab}\)</span>: Capacity of link <span class="math inline">\((a,b)\)</span></p>
</div><div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\mc{L}^k\)</span>: Set of links allowed to transmit VIPs of <span class="math inline">\(k\)</span>, determined by routing policy</p>
</div>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>And here’s the forwarding step.</li>
<li>The intuition here again comes from thinking of VIP counts as potential representing unsatisfied demand. So with the forwarding step, we’re making sure VIP flows follow large differences in potential, essentially steering interests toward sinks, meaning sources or caches.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="theorem-stability-region" class="slide level2">
<h2>Theorem: Stability Region</h2>
<p>VIP <span class="body-highlight">stability region</span> <span class="math inline">\(\Lambda\)</span> consists of all arrival rates <span class="math inline">\(\boldsymbol{\lambda} = (\lambda^k_n)_{\kin,\nin}\)</span> such that:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{equation}
    \lambda^k_n \leq \sum\limits_{\bin} f^k_{nb} - \sum\limits_{\ain} f^k_{an} + \sum\limits_{\jin} r_{n_j} \betasumind
\end{equation}\]</span>
</div>
<hr>
<div style="font-size: 70%; text-align: center">
<p><span class="math inline">\(f^k_{ab}\)</span>: Time-average VIP flow for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span></p>
</div>
<div class="columns">
<div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\mc{B}_{n,i}\)</span>: i-th among all <span class="math inline">\(\sigma_n\)</span> possible cache placement sets at <span class="math inline">\(n\)</span>; if <span class="math inline">\((k,j) \in \mc{B}_{n,i}\)</span> during <span class="math inline">\(t\)</span>, <span class="math inline">\(s^k_{n_j}(t)\)</span> = 1</p>
</div><div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\beta_{n,i}\)</span>: Fraction of time objects at <span class="math inline">\(n\)</span> are placed according to <span class="math inline">\(\mc{B}_{n,i}\)</span>; <span class="math inline">\(0 \leq \beta_{n,i} \leq 1\)</span> and <span class="math inline">\(\sum^{\sigma_n}_{i=1} \beta_{n,i} = 1\)</span></p>
</div>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The analysis of our approach comes in two steps. We’re following the structure of Lyapunov drift-based analysis, which was also used in the VIP paper, to first define the stability region of the network of VIP counts (which can be seen as queues) in the virtual plane.</li>
<li>The inequality on the screen essentially defines the boundary of that stability region, relating the arrival rate that can be satisfied contingent on the long term average VIP flow over links, as well as VIPs removed via cache tiers.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="theorem-trade-off" class="slide level2 smaller">
<h2>Theorem: Trade-off</h2>
<p>Given VIP arrival rate vector <span class="math inline">\(\boldsymbol{\lambda}\)</span>, if there exists <span class="math inline">\(\boldsymbol{\epsilon}\)</span> such that <span class="math inline">\(\boldsymbol{\lambda} + \boldsymbol{\epsilon} \in \Lambda\)</span>, then the network of VIP queues under the proposed algorithm satisfies the following:</p>
<span class="math display">\[\begin{equation}
    \lim\limits_{T \rightarrow \infty} \frac{1}{T} \sum\limits^{T-1}_{t=0} \sum\limits_{\nin, \kin} \mathbb{E}[V^k_n(t)] \leq \frac{NB}{\epsilon} + \frac{\omega}{2\epsilon} \minpen
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    \lim\limits_{T \rightarrow \infty} \frac{1}{T}\sum\limits^{T-1}_{t=0} \mathbb{E}[p(t)] \leq \frac{2NB}{\omega} + \minpen
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    B \triangleq \frac{1}{2N} \sum_{\nin} \bigg((\mu^{out}_{n,max})^2 + 2(\mu^{out}_{n,max})r_{n,max} + \big(\textstyle \sum_{\kin}A^k_{n,max} + \mu^{in}_{n,max} + r_{n,max})^2 \bigg)
\end{equation}\]</span>
<p><span class="math inline">\(\Psi(\boldsymbol{\lambda})\)</span> is the minimum time-average sum penalty achievable by a feasible and stabilizing randomized policy.</p>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The second step of our analysis is what actually shows the guarantees that our algorithm can provide. Here, we use the definition of the stability region, which is why we needed the previous step.</li>
<li>These two expressions define the upper bounds for time average VIP queue sizes and accumulated penalty in the virtual plane network.</li>
<li>The essential observation here is the trade-off between the bounds. As you can see, the omega value controls which bound we wish to prioritize, because setting it small means lower average queue sizes which translates to better performance, but at the cost of potentially much larger penalties. Setting it large is the inverse of that situation.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<p>We can rewrite <span class="body-highlight">caching</span> step optimization problem.</p>
<div style="font-size: 100%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - \omega p^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Now of course, the validity of our approach still hinges on whether we can solve the two optimization problems from the two steps of our algorithm.</li>
<li>To do so for the caching step, we will first rewrite it to clean up this unpleasant form we’ve shown before. And to do that, we will use a two-step transformation of variables.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-1" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<p>We can rewrite <span class="body-highlight">caching</span> step optimization problem.</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} b^k_{n_j}(t) s^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align}\]</span>
<span class="math display">\[\begin{equation}
    b^k_{n_j}(t) \triangleq \left\{ \begin{array}{ll}
        r_{n_j} V^k_n(t) - \omega c^a_{n_j}, &amp; \text{if} \; s^k_{n_j}(t-1) = 0 \\
        r_{n_j} V^k_n(t) + \omega c^e_{n_j}, &amp; \text{if} \; s^k_{n_j}(t-1) = 1
    \end{array} \right.
\end{equation}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The first step here is defining an auxiliary “benefit” term and using that to simplify the objective function.</li>
<li>You’ll notice that the problem now looks to be in the form of a generalized assignment problem.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-2" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<p>Use equal object sizes, decide variables for each one-object <span class="body-highlight">cache slot</span>. Rewrite problem as <span class="body-highlight">linear assignment problem</span>.</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\iin} b^k_{n_i}(t) s^k_{n_i}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_i}(t) \leq 1, \; \forall \, \iin \\
        &amp; \quad \sum\limits_{\iin} s^k_{n_i}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_i}(t) \in \{0, 1\}, \; \forall \, \kin, \; \iin
\end{align}\]</span>
</div>
<div style="font-size: 70%;">
<p><span class="math inline">\(\mc{I}_n \triangleq \{1, 2, ..., \sum_{\jin} L_{n_j}\}, \; \mc{I}_{n_j} \triangleq \{1 + \sum^{j - 1}_{\ell = 1} L_{n_\ell}, ..., \sum^{j}_{\ell = 1} L_{n_\ell}\}\)</span></p>
<p>If <span class="math inline">\(i \in \mc{I}_{n_j}\)</span>, then <span class="math inline">\(b^k_{n_j}(t) = b^k_{n_i}(t)\)</span> and <span class="math inline">\(s^k_{n_j}(t) = s^k_{n_i}(t)\)</span>.</p>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Now please recall the assumption we made in our model that every data object has the same size, because it is critical here.</li>
<li>Using that assumption, we can think of each cache tier as made up of several “cache slots” that can each take one object, depending of course on the total capacity of the tier. Each of these cache slots of course have the same read rate and cost parameters as the tier it belongs in.</li>
<li>Now, also recall the cache exclusivity constraint of the original problem. We can easily see that exclusivity across tiers directly translates to exclusivity across these cache slots.</li>
<li>Using these facts we can rewrite the problem again, this time in the form of a linear assignment problem.</li>
<li>Luckily, there are methods that can solve this problem in polynomial time. We specifically rely on a modification of the Jonker-Volgenant algorithm.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="forwarding-solution" class="slide level2">
<h2>Forwarding Solution</h2>
<p><em>Backpressure</em> solution to forwarding optimization problem as in (Yeh, 2014).</p>
<span class="math display">\[\begin{equation}
   \mu^k_{ab}(t) =
   \left\{ \begin{array}{ll}
      C_{ba}, &amp; \text{if} \; k = k^*_{ab}(t) \; \text{and} \; W^k_{ab}(t) &gt; 0 \\
      0, &amp; \text{otherwise}
   \end{array} \right.
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
\begin{split}
   W^k_{ab}(t) &amp; \triangleq V^k_a(t) - V^k_b(t), \\
   k^*_{ab}(t) &amp; \triangleq \argmax\limits_{\{k: \abin^k\}} W^k_{ab}(t)
\end{split}
\end{equation}\]</span>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>As for the solution to the forwarding step, a neat thing about our extension here is that we don’t actually alter the results for forwarding from the original VIP paper.</li>
<li>So we can use the backpressure solution that was devised there directly.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="data-plane-strategy" class="title-slide slide level1 center">
<h1>Data Plane Strategy</h1>

</section>
<section id="transition-to-data-plane" class="slide level2">
<h2>Transition to Data Plane</h2>
<p>There are several considerations when applying our approach in the data plane:</p>
<ul>
<li>Per-packet forwarding and caching decisions</li>
<li>Assumption of immediate access to any object for caching purposes does not hold</li>
<li><span class="body-highlight">Oscillatory</span><sup>1</sup> nature of VIP counts impractical for data plane caching</li>
</ul>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>So first off, there are several things about using the virtual plane algorithm with the mechanics of the data plane</li>
<li>The virtual plane decisions are made in discrete time slots, but of course the data plane decisions have to be reactive and continuous</li>
<li>Another major point is that, for caching decisions, when we change the relevant variables in the virtual plane, we inherently assume that we can have access to that object immediately, this obviously won’t hold in the data plane</li>
<li>Finally, there’s an observation made in the original VIP paper about VIP counts which applies here, which is that they are oscillatory. Because VIP counts change frequently and drastically, cache states also tend to change quickly. Basing caching on this behavior directly is impractical in the data plane.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn3"><p>When the VIP count for an object becomes large, we make decisions in the virtual plane that will quickly drive the count down.</p></li></ol></aside></section>
<section id="data-plane-caching" class="slide level2 smaller">
<h2>Data Plane Caching</h2>
<p>Define the <span class="body-highlight">cache score</span> metric as in (Yeh, 2014):</p>
<span class="math display">\[\begin{equation}
    CS^k_n(t) \triangleq \frac{1}{T} \sum^t_{\tau = t - T + 1} \sum_{(a,n) \in \mc{L}^k} v^k_{an}(\tau)
\end{equation}\]</span>
<p>Define the <span class="body-highlight">eviction target</span> for tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span> as follows:</p>
<span class="math display">\[\begin{equation}
   k^{min}_{n_j}(t) = \argmin_{\{k \in \mc{K}_{n_j}(t)\}} CS^k_n(t)
\end{equation}\]</span>
<hr>
<table>
<colgroup>
<col style="width: 23%">
<col style="width: 76%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mc{v}^k_{ab}\)</span></td>
<td style="text-align: left;">Actual number of VIPs for <span class="math inline">\(k\)</span> transmitted over <span class="math inline">\((a,b)\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(T\)</span></td>
<td style="text-align: left;">Size of sliding window in time slots</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mc{K}_{n_j}(t)\)</span></td>
<td style="text-align: left;">Set of objects cached in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>So to address all of these, we begin by adopting the cache score metric, which is based on a sliding window average of received VIPs</li>
<li>Then we define the eviction target for each cache tier, as shown in the second expression on screen</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-caching-1" class="slide level2 smaller">
<h2>Data Plane Caching</h2>
<p>Define the <span class="body-highlight">cache benefit</span> metric as follows:</p>
<span class="math display">\[\begin{equation}
    CB^k_{n_j}(t) = \begin{cases}
        \begin{array}{l}
             r_{n_j}(CS^k_n(t) - CS^{k^{min}_{n_j}(t)}_n(t)) - \omega(c^a_{n_j} + c^e_{n_j}), \text{if} \, j \, \text{is full} \\
             r_{n_j} CS^k_n(t) - \omega c^a_{n_j}, \; \text{otherwise}
        \end{array}
    \end{cases}
\end{equation}\]</span>
<p>When data object <span class="math inline">\(k \not \in \mc{K}_{n_j}(t)\)</span> arrives at <span class="math inline">\(n\)</span> during slot <span class="math inline">\(t\)</span>, <span class="body-highlight">data plane caching policy</span> at <span class="math inline">\(n\)</span> behaves as follows:</p>
<ul>
<li>Find cache tier offering highest cache benefit, i.e.&nbsp;<span class="math inline">\(j^* = \argmax_{\{ \jin \}} CB^k_{n_j}(t)\)</span></li>
<li>If <span class="math inline">\(CB^k_{n_{j^*}}(t) &gt; 0\)</span>, admit object into tier <span class="math inline">\(j^*\)</span>
<ul>
<li>If <span class="math inline">\(j^*\)</span> is full, i.e.&nbsp;<span class="math inline">\(|\mc{K}_{n_{j^*}}(t)| = L_{n_{j^*}}\)</span>, <span class="math inline">\(k\)</span> replaces <span class="math inline">\(k^{min}_{n_{j^*}}\)</span></li>
</ul></li>
<li>If a replacement happened in <span class="math inline">\(j^* &lt; |\mc{J}_n|\)</span>, set <span class="math inline">\(k = k^{min}_{n_{j^*}}\)</span>, then start the process over</li>
</ul>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>Of course, because we also consider costs, we need a metric that incorporates those, in other words, balances cache scores against weighted penalties, whether it be for admission or replacement; we call this the cache benefit metric</li>
<li>Now that the defined this, here’s the operation of the data plane caching policy</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-forwarding" class="slide level2">
<h2>Data Plane Forwarding</h2>
<p>Forwarding strategy is as in (Yeh, 2014). When a request for object <span class="math inline">\(k \not \in \mc{K}_{n_j}(t), \; \forall \jin\)</span>, arrives at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span>, the request is forwarded to the following node:</p>
<span class="math display">\[\begin{equation}
    b^k_n(t) = \argmax_{\{ b:(n,b) \in \mc{L}^k \}} \frac{1}{T} \sum\limits^t_{t'=t-T+1} v^k_{nb}(t)
\end{equation}\]</span>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>As for the forwarding, again we base it on the findings of the VIP paper, and use a similar sliding window average, this time of outgoing VIP flow, to make forwarding decisions</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="chunk-level-decisions" class="slide level2">
<h2>Chunk-level Decisions</h2>
<p>At chunk-level in data plane, we observe the following principles:</p>
<ul>
<li>If a data object is admitted to (evicted from) a cache tier, all its chunks must be admitted to (evicted from) that tier.</li>
<li>Forwarding decision is made upon receiving request for a first chunk. Requests for subsequent chunks are forwarded to the same node.</li>
</ul>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>As a final note, recall that our model and approach is at the object level, but in the real world, the data plane operates at a chunk (or packet) level</li>
<li>So here are the two principles we would observe when applying our approach at the chunk level</li>
<li>(Talk about bullet points)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="experiments" class="title-slide slide level1 center">
<h1>Experiments</h1>
<aside class="notes">
<ul>
<li>Alright, so how does our strategy fare in experimental evaluations</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simulation-setup" class="slide level2">
<h2>Simulation Setup</h2>
<ul>
<li>Object-level simulation framework built with Python using the SimPy library</li>
<li>Modular, object-oriented design to allow future extension</li>
<li>Multi-threading allowing thread-per-experiment execution</li>
<li>Experiment parameters and output in JSON format for easy parsing</li>
<li>Thorough statistic logging</li>
</ul>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Firstly, when I say experiments here I strictly mean simulation experiments</li>
<li>And I wanted to throw in this slide here at the beginning because it took quite a bit of time and care to build the simulator that I used to run experiments for this work</li>
<li>(Talk about bullet points)</li>
<li>And I needed to build this because existing simulators didn’t cover what I needed, and were missing some features I wanted and modifying them would’ve taken even more time</li>
<li>But of course this is also far from perfect, but we’ll get to that at the very end</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="experiment-setting" class="slide level2 smaller">
<h2>Experiment Setting</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Abilene (11 nodes)</figcaption>
<p><img data-src="images/abilene.svg"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>GEANT (34 nodes)</figcaption>
<p><img data-src="images/geant.svg"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>4x4 Grid (16 nodes)</figcaption>
<p><img data-src="images/grid.svg"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>3-Regular (50 nodes)</figcaption>
<p><img data-src="images/3reg.svg"></p>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Alright, so when it comes to experiment settings, I first have to stress that the experimentation space for this work is quite overwhelming and not straightforward</li>
<li>So the results I’ll show here are those that I think most succinctly show that our approach can deliver on our goals</li>
<li>To start off, these are the four topologies I conducted experiments over</li>
<li>On the left are Abilene and Geant which are real network topologies, and on the right are two stylized graphs</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="experiment-setting-1" class="slide level2 smaller">
<h2>Experiment Setting</h2>
<ul>
<li>Content source for each <span class="math inline">\(k\)</span> is selected uniformly at random; content sources have infinite read rate</li>
<li>Routing: Allow <span class="math inline">\(n\)</span> to forward requests for <span class="math inline">\(k\)</span> to any neighbor on <em>any</em> shortest path between <span class="math inline">\(n\)</span> and <span class="math inline">\(\mc{S}(k)\)</span> (in number of hops)</li>
<li>All nodes have the same two cache tiers available</li>
<li>Adapted replacement baselines: LRU, LFU, FIFO, RANDOM
<ul>
<li>LRU, FIFO and RANDOM cost-unaware, paired with LCE admission</li>
<li>LFU has both aware and unaware adaptations, admission based on frequency</li>
</ul></li>
<li>All baseline caching policies paired with Least Response Time forwarding</li>
<li>Nodes generate requests for some number of simulation seconds, simulation run terminates when all requests are resolved</li>
<li>Virtual plane algorithm with slot length of 1 sec and sliding window of size <span class="math inline">\(T=100\)</span></li>
</ul>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Of course there are some additional assumptions that pertain to the experiment setting so let’s go over those</li>
<li>Firstly, we pick the source for each object uniformly at random and we assume sources have infinite read rate; <em>this is not real world accurate since sources would also be holding objects in disks, but it helps to do this in simulations so we can focus on the caching side of things</em></li>
<li>We assume routing is pre-determined, since it’s not in our scope here, and the given policy is simple: a node can forward requests for an object on any shortest path (in hops) between itself and the source node for that object.</li>
<li><em>This may sound a bit limiting, but if we actually look at the topologies we’re dealing with, you can see that for a lot of source-destination pairs there is going to be many same-length shortest paths</em></li>
<li>These experiments all have two tiers of cache at every node, <em>and this is again due to how large the parameter space is and comes from a point of trying to simplify that as much as possible</em></li>
<li>Now, because there aren’t any policies, novel or established, we could directly compare against, we had to build our own baselines by adapting single-cache policies</li>
<li>We adapted LRU, FIFO and RANDOM replacement but for these there isn’t a good way to incorporate costs, so those are cost-unaware and for admission they’re paired with the basic Leave Copy Everywhere policy</li>
<li>We adapted LFU similarly, but also made a cost-aware LFU adaptation which uses a cache benefit metric similar to the one we devised for our aproach</li>
<li>Least response time forwarding simply means that each node monitors, for each outgoing link, the delay of the last request sent over that link and satisfied, and chooses the link with the smallest delay to forward requests</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="experiment-setting-2" class="slide level2 smaller">
<h2>Experiment Setting</h2>
<table>
<caption>Parameters for all topologies</caption>
<colgroup>
<col style="width: 10%">
<col style="width: 80%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(K\)</span></td>
<td style="text-align: center;">Number of objects in catalog <span class="math inline">\(\mc{K}\)</span></td>
<td style="text-align: center;">1000</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\sum_{\kin} \lambda^k_n\)</span></td>
<td style="text-align: center;">Total request arrival rate at each <span class="math inline">\(n\)</span> in objects/sec</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\alpha\)</span></td>
<td style="text-align: center;">Zipf’s law parameter for object popularity distribution</td>
<td style="text-align: center;">0.75</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(C_{ab}\)</span></td>
<td style="text-align: center;">Capacity of each link <span class="math inline">\(\abin\)</span>, in objects</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(|\mc{J}_n|\)</span></td>
<td style="text-align: center;">Number of cache tiers at each <span class="math inline">\(n\)</span></td>
<td style="text-align: center;">2</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(L_{n_1}\)</span></td>
<td style="text-align: center;">Capacity of tier 1 at each <span class="math inline">\(n\)</span>, in objects</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(r_{n_1}\)</span></td>
<td style="text-align: center;">Read rate of tier 1 at each <span class="math inline">\(n\)</span>, in objects/sec</td>
<td style="text-align: center;">20</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(c^a_{n_1}\)</span>, <span class="math inline">\(c^e_{n_1}\)</span></td>
<td style="text-align: center;">Admission and eviction costs of tier 1 at each <span class="math inline">\(n\)</span></td>
<td style="text-align: center;">4, 2</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(r_{n_2}\)</span></td>
<td style="text-align: center;">Read rate of tier 2 at each <span class="math inline">\(n\)</span>, in objects/sec</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(c^a_{n_2}\)</span>, <span class="math inline">\(c^e_{n_2}\)</span></td>
<td style="text-align: center;">Admission and eviction costs of tier 2 at each <span class="math inline">\(n\)</span></td>
<td style="text-align: center;">2, 1</td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>As I said, there are a great number of parameters for these experiments and I’m not going to cover each one in the interest of time, but we have this table for reference if needed</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="results-i" class="slide level2 smaller">
<h2>Results I</h2>
<p><strong>Scenario</strong>: No penalties (<span class="math inline">\(\omega=0\)</span>), <span class="math inline">\(L_{n_1} = 5\)</span> and <span class="math inline">\(L_{n_2} = 100\)</span> at each <span class="math inline">\(n\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>  Total delay, as fraction of total delay without any caching</figcaption>
<p><img data-src="images/tops_delay_v3.svg" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Cache hits, percentage of hits in the first tier on the left, total number of hits on the right</figcaption>
<p><img data-src="images/tops_hits_v3.svg" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Now I want to move on to our findings</li>
<li>First, I’ll show results from a scenario where we actually ignore penalties, which we can easily do for our approach by setting omega to be zero</li>
<li>We’re comparing our strategy to cost-unaware baselines here</li>
<li>The figure up top shows the total delay in the network, normalized to the total delay achieved without any caching</li>
<li>This figure illustrates our point about how managing larger caches is difficult, because as you can see, the “naive” policies are struggling quite a bit, at times showing worse performance than would be achieved with no caches at all</li>
<li>Our VIP-based approach performs the best across all experiments, though LFU is not that far behind</li>
<li>The bottom figure reveals more insights as to why the results are as they are because it shows the distribution of cache tiers among the two tiers as well as total cache hits</li>
<li>Now note that here the first tier can cache 5 objects, while the second tier can cache 100, so the capacity difference is 20-fold</li>
<li>However, with our approach, anywhere between 15% to 20% of cache hits are occurring on the first tier, much larger than other baselines, showing that we’re able to balance the amount of cache hits better</li>
<li>You’ll notice in most cases our approach doesn’t even have the highest total number of cache hits, and that’s because it is set up to handle the rate of cache hits properly</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="results-ii" class="slide level2 smaller">
<h2>Results II</h2>
<p><strong>Scenario</strong>: Cost-unaware policies excluded, <span class="math inline">\(\omega &gt; 0\)</span>. <span class="math inline">\(L_{n_1}=5\)</span>, best value of <span class="math inline">\(L_{n_2}\)</span> picked.</p>
<div class="body-centered">
<p>Delay vs.&nbsp;penalty (<span class="math inline">\(\omega\)</span> decreases to the right)</p>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>   Abilene</figcaption>
<p><img data-src="images/pen_vs_delay_abilene_v2.svg"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     4x4 Grid</figcaption>
<p><img data-src="images/pen_vs_delay_grid_v2.svg"></p>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Now we move on to a scenario with penalties, dropping the “naive” policies and keeping only the cost-aware adaptation of LFU as a baseline</li>
<li>We’ll be looking at how each policy balances the delay vs.&nbsp;penalty trade-off; total delay on the y-axis, total penalty on the x-axis</li>
<li>Now I want to point out here that different second tier capacities are used for the two policies. This is because I experimented with a range of values for each and picked the best performing round value</li>
<li>The reason for this connects to the challenges in managing these larger, slower caches.</li>
<li>I talked about this in the very beginning, and we’ve also seen how it manifests in the earlier results.</li>
<li>This in itself is a long discussion, but the gist is that I wanted to represent the best of the competing policy here.</li>
<li>As we can see, in the Abilene and Grid topologies our approach is generally outperforming the adapted LFU</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="results-ii-1" class="slide level2 smaller">
<h2>Results II</h2>
<p><strong>Scenario</strong>: Cost-unaware policies excluded, <span class="math inline">\(\omega &gt; 0\)</span>. Best value of <span class="math inline">\(L_{n_2}\)</span> picked.</p>
<div class="body-centered">
<p>Delay vs.&nbsp;penalty (<span class="math inline">\(\omega\)</span> decreases to the right)</p>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>    GEANT</figcaption>
<p><img data-src="images/pen_vs_delay_geant_v2.svg"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>    3-Regular</figcaption>
<p><img data-src="images/pen_vs_delay_regular_v2.svg"></p>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>The situation is similar for the Geant and 3-regular topologies as well, though in the latter, there is a small operating region where LFU overtakes our approach</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="proposed-work" class="title-slide slide level1 center">
<h1>Proposed Work</h1>

</section>
<section id="improvements" class="slide level2">
<h2>Improvements</h2>
<div class="fragment">
<p>There is still room for improvement</p>
</div>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/big-room.webp" style="width:65.0%;height:65.0%"></p>
</figure>
</div>
<p>… and it’s a big room</p>
</div>
<div class="footer">
<p>Super Funny Joke</p>
</div>
<aside class="notes">
<ul>
<li>So as much as I’d like to say I’ll be pursuing a shiny new goal for the remainder of my time here, there are still aspects of this work that needs to be covered</li>
<li>So this section will be centered about those improvements I’m planning on pursuing</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cache-read-bandwidth" class="slide level2 smaller">
<h2>Cache Read Bandwidth</h2>
<p>Current model assumes read rate of each object is independent of all others.</p>
<span class="math display">\[\begin{equation}
    V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
    + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \sum\limits_{j \in \mathcal{J}_n} \color{#C8102E}{r_{n_j}} s^k_{n_j}(t) \Bigg)^+
\end{equation}\]</span>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside class="notes">
<ul>
<li>First and foremost, while the modeling of read rate is essential in this work, the way we do it is not very accurate</li>
<li>We treat the read rate parameter as if it is independent for each object, which indicates that there is a guaranteeable rate that can be provided per object, no matter how many objects are cached in that tier</li>
<li>This is an okay assumption, but given the strict rate limitations we’re working with, is not great</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cache-read-bandwidth-1" class="slide level2 smaller">
<h2>Cache Read Bandwidth</h2>
<p>Current model assumes read rate of each object is independent of all others.</p>
<span class="math display">\[\begin{equation}
    \color{#C0C0C0}{V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
    + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \sum\limits_{j \in \mathcal{J}_n}} \color{#C8102E}{r_{n_j}} \color{#C0C0C0}{s^k_{n_j}(t) \Bigg)^+}    
\end{equation}\]</span>
<p>We need to make this more accurate when considering slower caches.</p>
<span class="math display">\[\begin{equation}
   \color{#C0C0C0}{V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
   + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \sum\limits_{j \in \mathcal{J}_n}} \color{#C8102E}{r^k_{n_j}(t)} \color{#C0C0C0}{s^k_{n_j}(t) \Bigg)^+}
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
   \sum_{\kin} r^k_{n_j}(t) \leq r_{n_j}, \; \forall t   
\end{equation}\]</span>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside class="notes">
<ul>
<li>To be perfectly honest, this is an oversight on my end. This is something I’ve known about VIP for a bit, first pointed out to me by my labmate Yuanhao in fact, during one of our conversations about it</li>
<li>For the original work, it may not matter as much, because there the target was still a small but fast cache, for which this assumption works better</li>
<li>But in the beginning of this work I was trying to move a bit fast because I wanted to see how the strategy would perform, and at the time I had lofty goals about a real implementation as well</li>
<li>But after many experiments, I am now convinced this is something we need to address</li>
<li>And the way we’ll do that is simply by enforcing a cache read bandwidth constraint</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cache-read-bandwidth-2" class="slide level2 smaller">
<h2>Cache Read Bandwidth</h2>
<p>Additional control action each time slot, in product form with another control action</p>
<span class="math display">\[\begin{equation}
\text{maximize} \quad \sum\limits_{\kin} \sum\limits_{\jin} V^k_{n}(t) r^k_{n_j}(t) s^k_{n_j}(t) - p^k_{n_j}(t)
\end{equation}\]</span>
<p>Read rate no longer a constant, VIPs drained via caching represented with a flow variable, like VIP flow terms over links</p>
<span class="math display">\[\begin{equation}
   F^k_{n_j}(t) \triangleq r^k_{n_j}(t) s^k_{n_j}(t), \qquad f^k_{n_j} = \frac{1}{t} \sum^{t}_{\tau=1} r^k_{n_j}(\tau) s^k_{n_j}(\tau)
\end{equation}\]</span>
<p><strong>Expectation</strong>: Stability region and its analysis changes significantly; complexity of caching problem solution reduces</p>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside class="notes">
<ul>
<li>Now, how does that change things?</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="different-object-sizes" class="slide level2 smaller">
<h2>Different Object Sizes</h2>
<p>Equal object sizes assumption makes analysis straightforward, but is not realistic.</p>
<p>Let <span class="math inline">\(z^k\)</span> be the size of object <span class="math inline">\(k\)</span> in bits. Redefine <span class="math inline">\(L_{n_j}\)</span> be the cache capacity of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span> in bits, instead of objects. The caching problem changes as follows:</p>
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - \omega p^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} z^k s^k_{n_j}(t) \leq L_{n_j}, \; \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \kin, \; \jin
\end{align}\]</span>
<p>Problem no longer a LAP but a GAP instead (NP-hard).</p>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside class="notes">
<ul>
<li>Now, here’s another shortcoming of the model, which I alluded to earlier in the presentation</li>
<li>(Go over slide content)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="different-object-sizes-1" class="slide level2 smaller">
<h2>Different Object Sizes</h2>
<ul>
<li>Combined with cache bandwidth constraints, solution may still be low-complexity</li>
<li>We have to reevaluate how we treat VIP counts:
<ul>
<li>Copies of a larger object are produced at a slower rate</li>
<li>VIPs for smaller objects can be drained at a higher rate</li>
<li>Without adjustments, service may prioritize smaller objects</li>
</ul></li>
<li>Combined with multi-tiered caches, this raises the <span class="body-highlight">integrity</span> question, i.e.&nbsp;should we require that nodes cache all chunks of an object in the same tier?
<ul>
<li>If not, complexity of the caching problem increases dramatically</li>
<li>Chunk-level strategy may serve this scenario better</li>
<li>Prefetching could be utilized<sup>1</sup></li>
</ul></li>
</ul>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn4"><p>Prefetching is actually one of the techniques G. Rossini, D. Rossi, et al.&nbsp;used to make SSDs viable as part of “content stores”</p></li></ol></aside></section>
<section id="virtual-plane---data-plane-gap" class="slide level2 smaller">
<h2>Virtual Plane - Data Plane Gap</h2>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>… oops, didn’t see you there</figcaption>
<p><img data-src="images/elephant.webp" style="width:65.0%;height:65.0%"></p>
</figure>
</div>
<audio data-autoplay="" id="elephant" src="audio/elephant.mp3">
</audio>
<script>
  var audio = document.getElementById("elephant");
  audio.volume = 0.1;
</script>
</div>
<div class="footer">
<p>Super Funny Callback</p>
</div>
<aside class="notes">
<ul>
<li>Ah, I was hoping we wouldn’t run into him</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane---data-plane-gap-1" class="slide level2 smaller">
<h2>Virtual Plane - Data Plane Gap</h2>
<ul>
<li>Some disparities between the two planes lead to a gap building over time
<ul>
<li>Virtual plane assumes nodes can immediately cache any object in the network</li>
<li>Data plane requires nodes to respond to requests from cache if available
<ul>
<li>This makes <span class="body-highlight">upward migrations</span><sup>1</sup> difficult in data plane</li>
</ul></li>
<li>Length of time slots, interest aggregation etc. further extend this gap</li>
</ul></li>
<li>Amending the gap is difficult, but it must be quantified:
<ul>
<li>Measure delay between a caching decision in the virtual plane, and when it is realized in data plane</li>
<li>Estimate difference between performance and cost metrics under virtual plane assumptions vs.&nbsp;data plane results</li>
</ul></li>
</ul>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside class="notes">

<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn5"><p>When a large amount of unsatisfied demand builds up for an object cached in a slower tier, causing that object to be moved into a faster tier</p></li></ol></aside></section>
<section id="cache-exclusivity" class="slide level2 smaller">
<h2>Cache Exclusivity</h2>
<span class="math display">\[\begin{equation}
\sum_{\jin} s^k_{n_j}(t) \leq 1, \quad \kin
\end{equation}\]</span>
<p>Useful in view of <span class="body-highlight">interest aggregation</span><sup>1</sup>, but very restrictive:</p>
<ul>
<li>Without interest aggregation, duplicates across tiers could extend bandwidth</li>
<li>Removing cache exclusivity could also help with upward migration problem</li>
<li>Without this constraint, algorithm operates over individual tiers independently; reduced complexity, adaptations to baselines unnecessary</li>
</ul>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn6"><p>When a node receives an interest for an object while it already is waiting on the data packet from an earlier interest for the same object, it won’t send out the new interest. The data that returns for the earlier interest will be used to satisfy the new interest.</p></li></ol></aside></section>
<section id="better-experiments" class="slide level2">
<h2>Better Experiments</h2>
<ul>
<li>Python is convenient but not highly-scalable for DES frameworks. Julia is a great alternative for both convenience and performance.</li>
<li>Per-experiment multi-threading is not effective. Simulator core should be multi-threaded to improve <span class="body-highlight">scale-up</span>; per-experiment <span class="body-highlight">scale-out</span> can also be used.</li>
<li>Current codebase has some comments but little documentation and examples. Easily <span class="body-highlight">improvable</span> simulator and <span class="body-highlight">reproducible</span> results crucial.</li>
</ul>
<div class="footer">
<p>Proposed Work</p>
</div>
</section></section>
<section>
<section id="conclusion-other-contributions" class="title-slide slide level1 center">
<h1>Conclusion &amp; Other Contributions</h1>

</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<div>
<ul>
<li class="fragment">We address a critical and practical problem in scaling high-throughput caching networks</li>
<li class="fragment">Our proposed model and approach achieves our goals and performs decently, but has shortcomings</li>
<li class="fragment">Some improvements can be made by reiterating on technical details, further fine tuning requires experimentation</li>
</ul>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Model</strong>: Arbitrary multi-hop wireless heterogenous network (HetNet) topology:</p>
<ul>
<li>MCs, SCs, and users; MCs and SCs have wireline backhaul connections</li>
<li>All wireless transmissions share channel, i.e.&nbsp;no interference management</li>
<li>All nodes can be equipped with caches</li>
<li>Pre-determined shortest path (in hops) routing</li>
</ul>
<p><strong>Goal</strong>: Minimize delay in network by controlling power and caching allocation</p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>HetNet illustration</figcaption>
<p><img data-src="images/hetnet.svg"></p>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-1" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p>
<span class="math display">\[\begin{equation}
\text{SINR}_{vu}(S)=\frac{ G_{vu}s_{vu}}{N_u+  \sum\limits_{j\in V\backslash v}G_{ju}\sum\limits_{w}s_{jw}+G_{vu}\sum\limits_{w\neq u}s_{vw}}
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
f(\text{SINR}_{vu}(S)) = \frac{1}{\log_2(1+\text{SINR}_{vu}(S))}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-2" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p>
<span class="math display">\[\begin{equation}
D_{(i,p)}^o(X,S)=\sum\limits_{k=1}^{|p|-1}f(\text{SINR}_{p_{k+1}p_k}(S))\prod\limits_{l=1}^k (1-x_{p_l i})
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
D^o(X,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)}{D_{(i,p)}^o(X,S)}}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-3" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p></li>
<li><p>Convex relaxation on these leads to reduced-complexity formulation (RCF)</p>
<span class="math display">\[\begin{equation}
D_{(i,p)}(Y,S)={\sum\limits_{k=1}^{|p|-1}f(\text{SINR}_{p_{k+1}p_k}(S)) g_{p_k i}(Y) }
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
g_{p_k i}(Y)=1-\min\Big\{1,\sum\limits_{l=1}^k y_{p_l i}\Big\},\,\quad\forall\, y_{p_li}\in [0, 1]
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
D(Y,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)} D_{(i,p)}(Y,S)}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-4" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p></li>
<li><p>Convex relaxation on these leads to reduced-complexity formulation (RCF)</p>
<span class="math display">\[\begin{equation}
D(Y,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)} D_{(i,p)}(Y,S)}
\end{equation}\]</span></li>
<li><p>RCF is not jointly convex in power and caching</p></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-5" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Use projected subgradient method to solve for local minima in general case</p>
<span class="math display">\[\begin{equation}
\begin{aligned}
    &amp; S^{t+1} = S^t + \xi_S^t(\bar{S}^t - S^t) \\
    &amp; \bar{S}^t = [S^t - w_S^t d_S^t]^+_{\mathcal{D}_S} \\
    &amp; \boldsymbol{y}^{t+1} = \boldsymbol{y}^t + \xi^t_{\boldsymbol{y}}(\boldsymbol{\bar{y}}^t - \boldsymbol{y}^t) \\
    &amp; \boldsymbol{\bar{y}}^t = [\boldsymbol{y}^t - w_Y^t d^t_{\boldsymbol{y}}]^+_{\mathcal{D}_{\boldsymbol{y}}} \\
    &amp; d_S^t = \nabla_S D(Y^t,S^t), \; d^t_{\boldsymbol{y}} \in \partial_{\boldsymbol{y}}D(Y^t,S^t) \\
    &amp; \xi^t_{\boldsymbol{y}} = \frac{D^t - \hat{D}^t}{||d_{\boldsymbol{y}}^t||^2}, \; \xi_S^t = \frac{D^t - \hat{D}^t}{||d_S^t||^2}
\end{aligned}
\end{equation}\]</span>
</div><div class="column" style="width:50%;">
<p><strong>Projected Subgradient Method</strong></p>
<ul>
<li><p>Initialize: Choose <span class="math inline">\(S^{0}\)</span>, <span class="math inline">\(\boldsymbol{y}^{0}\)</span></p></li>
<li><p><strong>do</strong></p>
<ul>
<li>Compute subgradient <span class="math inline">\(d^t_S, d^t_{\boldsymbol{y}}\)</span></li>
<li>Determine step sizes <span class="math inline">\(\xi^t_{\boldsymbol{y}}\)</span>, <span class="math inline">\(\xi_S^t\)</span></li>
<li>Compute projected variables <span class="math inline">\(\boldsymbol{\bar{y}}^t\)</span>, <span class="math inline">\(\bar{S}^t\)</span></li>
<li>Update <span class="math inline">\(S^{t+1}\)</span> and <span class="math inline">\(\boldsymbol{y}^{t+1}\)</span></li>
<li>Let <span class="math inline">\(t=t+1\)</span></li>
</ul></li>
<li><p><strong>while</strong> <span class="math inline">\(D^t - D^{t-1} &gt; \epsilon\)</span></p></li>
<li><p>Let <span class="math inline">\((\boldsymbol{y}^{*}_{sub},S^{*}_{sub}) = (\boldsymbol{y}^{t},S^{t})\)</span></p></li>
<li><p>Rounding</p></li>
</ul>
</div>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-6" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     Power budget</figcaption>
<p><img data-src="images/hetnet_result1.svg" style="width:55.0%;height:55.0%"></p>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-7" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     SC cache capacity</figcaption>
<p><img data-src="images/hetnet_result3.svg" style="width:55.0%;height:55.0%"></p>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-8" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     Zipf parameter</figcaption>
<p><img data-src="images/hetnet_result2.svg" style="width:55.0%;height:55.0%"></p>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section></section>
<section id="thanks-questions" class="title-slide slide level1 center">
<h1>Thanks &amp; Questions</h1>

</section>

<section>
<section id="appendices" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Appendices</h1>

</section>
<section id="appendix-a-other-references" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix A: Other References</h2>
<ul>
<li><em>“Toward terabyte-scale caching with SSD in a named data networking router”</em>, W. So, T. Chung, H. Yuan, D. Oran, M. Stapp, ANCS 2014</li>
<li><em>“On Designing Optimal Memory Damage Aware Caching Policies for Content-Centric Networks”</em>, S. Shukla, A. A. Abouzeid, WiOpt 2016</li>
</ul>
<div class="footer">
<p>Appendices</p>
</div>
</section>
<section id="appendix-b-model-notation" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix B: Model Notation</h2>
<table>
<caption>Table of Notations</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 80%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mathcal{G}\)</span></td>
<td style="text-align: left;">Directed graph representing the network topology</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\((\mathcal{N},\mathcal{L})\)</span></td>
<td style="text-align: left;">Set of nodes and links in <span class="math inline">\(\mathcal{G}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(C_{ab}\)</span></td>
<td style="text-align: left;">Transmission capacity (in objects/sec) of link <span class="math inline">\((a,b)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mathcal{K}\)</span></td>
<td style="text-align: left;">Set of data objects in the network</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mc{S}(k)\)</span></td>
<td style="text-align: left;">Content source node for <span class="math inline">\(k \in \mathcal{K}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mathcal{J}_n\)</span></td>
<td style="text-align: left;">Set of cache tiers at node <span class="math inline">\(n \in \mathcal{N}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(L_{n_j}\)</span></td>
<td style="text-align: left;">Size (in objects) of cache tier <span class="math inline">\(j \in \mathcal{J}_n\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(r_{n_j}\)</span></td>
<td style="text-align: left;">Read rate of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(c^a_{n_j}\)</span></td>
<td style="text-align: left;">Admission cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(c^e_{n_j}\)</span></td>
<td style="text-align: left;">Eviction cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Appendices</p>
</div>
</section>
<section id="appendix-b-model-notation-1" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix B: Model Notation</h2>
<table>
<caption>Table of Notations</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 80%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\lambda^k_n\)</span></td>
<td style="text-align: left;">Exogenous request arrival rate for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(t\)</span></td>
<td style="text-align: left;">Time slot referring to time interval <span class="math inline">\([t, t+1)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(A^k_n(t)\)</span></td>
<td style="text-align: left;">Number of exogenous requests for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(s^k_{n_j}(t)\)</span></td>
<td style="text-align: left;">Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(p^k_{n_j}(t)\)</span></td>
<td style="text-align: left;">Penalty incurred by the choice of <span class="math inline">\(s^k_{n_j}(t)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(p(t)\)</span></td>
<td style="text-align: left;">Sum penalty incurred during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\omega\)</span></td>
<td style="text-align: left;">Penalty importance weight</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(V^k_n(t)\)</span></td>
<td style="text-align: left;">VIP count for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mathbf{V}(t)\)</span></td>
<td style="text-align: left;">Vector of VIP queue states during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mu^k_{ab}(t)\)</span></td>
<td style="text-align: left;">Allocated rate of VIPs for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Appendices</p>
</div>
</section>
<section id="appendix-c-analysis-notation" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix C: Analysis Notation</h2>
<table>
<colgroup>
<col style="width: 30%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(A^k_{n,max}\)</span></td>
<td style="text-align: left;">Finite value such that <span class="math inline">\(A^k_n(t) \leq A^k_{n,max}\)</span> for all <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(A_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total exogenous arrivals at node <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span> across all <span class="math inline">\(\kin\)</span>, i.e.&nbsp;<span class="math inline">\(A_{n,max} \triangleq \sum_{\kin}A^k_{n,max}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mu^{out}_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total allocated transmission rate for VIPs across all <span class="math inline">\((n,b) \in \mc{L}\)</span>, i.e.&nbsp;<span class="math inline">\(\mu^{out}_{n,max} \triangleq \sum_{\bin}C_{nb}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mu^{in}_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total allocated transmission rate for VIPs across all <span class="math inline">\((a,n) \in \mc{L}\)</span>, i.e.&nbsp;<span class="math inline">\(\mu^{in}_{n,max} \triangleq \sum_{\bin}C_{an}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(r_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total rate that can be served by all cache tiers at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\Psi(\boldsymbol{\lambda})\)</span></td>
<td style="text-align: left;">Minimum time-average sum penalty achievable by a feasible and stabilizing randomized policy</td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Appendices</p>
</div>
</section>
<section id="appendix-d-simulator-snippets" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix D: Simulator Snippets</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Node</a></li><li><a href="#tabset-1-2">Cache</a></li><li><a href="#tabset-1-3">Link</a></li><li><a href="#tabset-1-4">Caching Policy</a></li><li><a href="#tabset-1-5">Forwarding Policy</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">class</span> Node(<span class="bu">object</span>):</span>
<span id="cb1-2"><a href="#cb1-2"></a>   <span class="co"># ...</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>   <span class="kw">def</span> packetReceiver(<span class="va">self</span>, remote_id):</span>
<span id="cb1-4"><a href="#cb1-4"></a>      <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb1-5"><a href="#cb1-5"></a>         pkt <span class="op">=</span> <span class="cf">yield</span> <span class="va">self</span>.in_links[remote_id].get()</span>
<span id="cb1-6"><a href="#cb1-6"></a>         <span class="cf">if</span> pkt.isData():</span>
<span id="cb1-7"><a href="#cb1-7"></a>               <span class="cf">yield</span> <span class="va">self</span>.env.timeout(<span class="dv">1</span><span class="op">/</span><span class="va">self</span>.in_links[remote_id].link_cap)</span>
<span id="cb1-8"><a href="#cb1-8"></a>         <span class="cf">if</span> pkt.isData() <span class="kw">or</span> pkt.isInterest():</span>
<span id="cb1-9"><a href="#cb1-9"></a>               <span class="va">self</span>.pkt_buffer.put((remote_id, pkt))</span>
<span id="cb1-10"><a href="#cb1-10"></a>   <span class="kw">def</span> packetProcessor(<span class="va">self</span>):</span>
<span id="cb1-11"><a href="#cb1-11"></a>      <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb1-12"><a href="#cb1-12"></a>         remote_id, pkt <span class="op">=</span> <span class="cf">yield</span> <span class="va">self</span>.pkt_buffer.get()</span>
<span id="cb1-13"><a href="#cb1-13"></a>         <span class="cf">if</span> pkt.isInterest():</span>
<span id="cb1-14"><a href="#cb1-14"></a>               <span class="va">self</span>.receiveInterest(remote_id, pkt.request)</span>
<span id="cb1-15"><a href="#cb1-15"></a>         <span class="cf">elif</span> pkt.isData():</span>
<span id="cb1-16"><a href="#cb1-16"></a>               <span class="va">self</span>.receiveData(pkt.request)</span>
<span id="cb1-17"><a href="#cb1-17"></a>   <span class="co"># ...</span></span>
<span id="cb1-18"><a href="#cb1-18"></a>   <span class="kw">def</span> forwardInterest(<span class="va">self</span>, request):</span>
<span id="cb1-19"><a href="#cb1-19"></a>        <span class="va">self</span>.sendInterestPacket(<span class="va">self</span>.fib[request.object_id][<span class="dv">0</span>], request)</span>
<span id="cb1-20"><a href="#cb1-20"></a>        <span class="cf">return</span></span>
<span id="cb1-21"><a href="#cb1-21"></a></span>
<span id="cb1-22"><a href="#cb1-22"></a>    <span class="kw">def</span> decideCaching(<span class="va">self</span>, object_id):</span>
<span id="cb1-23"><a href="#cb1-23"></a>        <span class="cf">yield</span> <span class="va">self</span>.env.timeout(<span class="dv">0</span>)</span>
<span id="cb1-24"><a href="#cb1-24"></a>        <span class="cf">return</span></span>
<span id="cb1-25"><a href="#cb1-25"></a>   <span class="co"># ...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-2">
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">class</span> Cache(<span class="bu">object</span>):</span>
<span id="cb2-2"><a href="#cb2-2"></a>   <span class="kw">def</span> cacheController(<span class="va">self</span>):</span>
<span id="cb2-3"><a href="#cb2-3"></a>      <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb2-4"><a href="#cb2-4"></a>         task <span class="op">=</span> <span class="cf">yield</span> <span class="va">self</span>.task_queue.get()</span>
<span id="cb2-5"><a href="#cb2-5"></a>         <span class="cf">if</span> task.<span class="bu">type</span> <span class="op">==</span> <span class="st">'r'</span>:</span>
<span id="cb2-6"><a href="#cb2-6"></a>               obj <span class="op">=</span> <span class="cf">yield</span> <span class="va">self</span>.env.process(<span class="va">self</span>.readProcess(task.object_id))</span>
<span id="cb2-7"><a href="#cb2-7"></a>               <span class="va">self</span>.out_buffer.put(obj)</span>
<span id="cb2-8"><a href="#cb2-8"></a>         <span class="cf">elif</span> task.<span class="bu">type</span> <span class="op">==</span> <span class="st">'w'</span>:</span>
<span id="cb2-9"><a href="#cb2-9"></a>               <span class="cf">yield</span> <span class="va">self</span>.env.process(<span class="va">self</span>.writeProcess(task.object_id))</span>
<span id="cb2-10"><a href="#cb2-10"></a>   <span class="co">#...</span></span>
<span id="cb2-11"><a href="#cb2-11"></a>   <span class="kw">def</span> readObject(<span class="va">self</span>, object_id):</span>
<span id="cb2-12"><a href="#cb2-12"></a>      <span class="va">self</span>.stats[<span class="st">'reads'</span>] <span class="op">+=</span> <span class="dv">1</span>            </span>
<span id="cb2-13"><a href="#cb2-13"></a>      task <span class="op">=</span> CacheTask(<span class="bu">type</span> <span class="op">=</span> <span class="st">'r'</span>, object_id <span class="op">=</span> object_id)</span>
<span id="cb2-14"><a href="#cb2-14"></a>      tic <span class="op">=</span> <span class="va">self</span>.env.now</span>
<span id="cb2-15"><a href="#cb2-15"></a>      <span class="va">self</span>.task_queue.put(task)</span>
<span id="cb2-16"><a href="#cb2-16"></a>      obj <span class="op">=</span> <span class="cf">yield</span> <span class="va">self</span>.out_buffer.get()</span>
<span id="cb2-17"><a href="#cb2-17"></a>      <span class="va">self</span>.stats[<span class="st">'read_delay'</span>] <span class="op">+=</span> <span class="va">self</span>.env.now <span class="op">-</span> tic</span>
<span id="cb2-18"><a href="#cb2-18"></a>      <span class="cf">return</span> obj</span>
<span id="cb2-19"><a href="#cb2-19"></a>   <span class="kw">def</span> cacheObject(<span class="va">self</span>, object_id):</span>
<span id="cb2-20"><a href="#cb2-20"></a>      <span class="va">self</span>.stats[<span class="st">'writes'</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb2-21"><a href="#cb2-21"></a>      <span class="va">self</span>.contents.append(object_id)</span>
<span id="cb2-22"><a href="#cb2-22"></a>      <span class="va">self</span>.cur_size <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb2-23"><a href="#cb2-23"></a>      task <span class="op">=</span> CacheTask(<span class="bu">type</span> <span class="op">=</span> <span class="st">'w'</span>, object_id <span class="op">=</span> object_id)</span>
<span id="cb2-24"><a href="#cb2-24"></a>      <span class="va">self</span>.task_queue.put(task)</span>
<span id="cb2-25"><a href="#cb2-25"></a>      <span class="cf">return</span> <span class="va">True</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-3">
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">class</span> Link(<span class="bu">object</span>):</span>
<span id="cb3-2"><a href="#cb3-2"></a>   <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, env, link_cap, prop_delay):</span>
<span id="cb3-3"><a href="#cb3-3"></a>      <span class="va">self</span>.env <span class="op">=</span> env</span>
<span id="cb3-4"><a href="#cb3-4"></a>      <span class="va">self</span>.link_cap <span class="op">=</span> link_cap</span>
<span id="cb3-5"><a href="#cb3-5"></a>      <span class="va">self</span>.pipe <span class="op">=</span> sp.Store(env)</span>
<span id="cb3-6"><a href="#cb3-6"></a>   <span class="kw">def</span> put(<span class="va">self</span>, pkt):</span>
<span id="cb3-7"><a href="#cb3-7"></a>      <span class="va">self</span>.pipe.put(pkt)</span>
<span id="cb3-8"><a href="#cb3-8"></a>   <span class="kw">def</span> get(<span class="va">self</span>):</span>
<span id="cb3-9"><a href="#cb3-9"></a>      <span class="cf">return</span> <span class="va">self</span>.pipe.get()</span>
<span id="cb3-10"><a href="#cb3-10"></a></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="kw">class</span> VipLink(<span class="bu">object</span>):</span>
<span id="cb3-12"><a href="#cb3-12"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, env):</span>
<span id="cb3-13"><a href="#cb3-13"></a>        <span class="va">self</span>.env <span class="op">=</span> env</span>
<span id="cb3-14"><a href="#cb3-14"></a>        <span class="va">self</span>.update_pipe <span class="op">=</span> sp.Store(env)</span>
<span id="cb3-15"><a href="#cb3-15"></a>        <span class="va">self</span>.vip_pipe <span class="op">=</span> sp.Store(env)    </span>
<span id="cb3-16"><a href="#cb3-16"></a>    <span class="kw">def</span> pushUpdate(<span class="va">self</span>, pkt):</span>
<span id="cb3-17"><a href="#cb3-17"></a>        <span class="va">self</span>.update_pipe.put(pkt)    </span>
<span id="cb3-18"><a href="#cb3-18"></a>    <span class="kw">def</span> getUpdate(<span class="va">self</span>):</span>
<span id="cb3-19"><a href="#cb3-19"></a>        <span class="cf">return</span> <span class="va">self</span>.update_pipe.get()    </span>
<span id="cb3-20"><a href="#cb3-20"></a>    <span class="kw">def</span> pushVips(<span class="va">self</span>, pkt):</span>
<span id="cb3-21"><a href="#cb3-21"></a>        <span class="va">self</span>.vip_pipe.put(pkt)    </span>
<span id="cb3-22"><a href="#cb3-22"></a>    <span class="kw">def</span> getVips(<span class="va">self</span>):</span>
<span id="cb3-23"><a href="#cb3-23"></a>        <span class="cf">return</span> <span class="va">self</span>.vip_pipe.get()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-4">
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">class</span> UNIFNode(Node):</span>
<span id="cb4-2"><a href="#cb4-2"></a>   <span class="kw">def</span> decideCaching(<span class="va">self</span>, object_id):</span>
<span id="cb4-3"><a href="#cb4-3"></a>      cache <span class="op">=</span> np.random.choice(<span class="va">self</span>.caches)</span>
<span id="cb4-4"><a href="#cb4-4"></a>      <span class="cf">if</span> cache.isFull():</span>
<span id="cb4-5"><a href="#cb4-5"></a>         victim_id <span class="op">=</span> np.random.choice(cache.contents)</span>
<span id="cb4-6"><a href="#cb4-6"></a>         <span class="cf">yield</span> <span class="va">self</span>.env.process(cache.replaceObject(victim_id, object_id))</span>
<span id="cb4-7"><a href="#cb4-7"></a>      <span class="cf">else</span>:</span>
<span id="cb4-8"><a href="#cb4-8"></a>         cache.cacheObject(object_id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-5">
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">class</span> RoundRobinNode(Node):</span>
<span id="cb5-2"><a href="#cb5-2"></a>   <span class="kw">def</span> addFIB(<span class="va">self</span>, fib):</span>
<span id="cb5-3"><a href="#cb5-3"></a>      <span class="bu">super</span>().addFIB(fib)</span>
<span id="cb5-4"><a href="#cb5-4"></a>      <span class="va">self</span>.link_queues <span class="op">=</span> {}</span>
<span id="cb5-5"><a href="#cb5-5"></a>      <span class="cf">for</span> k <span class="kw">in</span> fib:</span>
<span id="cb5-6"><a href="#cb5-6"></a>         <span class="va">self</span>.link_queues[k] <span class="op">=</span> deque(fib[k])</span>
<span id="cb5-7"><a href="#cb5-7"></a>   </span>
<span id="cb5-8"><a href="#cb5-8"></a>   <span class="kw">def</span> forwardInterest(<span class="va">self</span>, request):</span>
<span id="cb5-9"><a href="#cb5-9"></a>      object_id <span class="op">=</span> request.object_id</span>
<span id="cb5-10"><a href="#cb5-10"></a>      remote_id <span class="op">=</span> <span class="va">self</span>.link_queues[object_id][<span class="dv">0</span>]</span>
<span id="cb5-11"><a href="#cb5-11"></a>      <span class="va">self</span>.link_queues[object_id].rotate(<span class="dv">1</span>)</span>
<span id="cb5-12"><a href="#cb5-12"></a>      <span class="va">self</span>.sendInterestPacket(remote_id, request)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="footer">
<p>Appendices</p>
</div>

<img src="images/neu_logo.svg" class="slide-logo r-stretch"><div class="footer footer-default">

</div>
</section></section>

    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="proposal_slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="proposal_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="proposal_slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="proposal_slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="proposal_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="proposal_slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="proposal_slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="proposal_slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="proposal_slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="proposal_slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>