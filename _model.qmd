## Data Plane Model {.smaller}

::: columns
::: {.column width=40%}

- Unit of content is ***data object***.
    - Each object $\kin$ is of ***unit size***.
    - Each $k$ has unique source $\mc{S}(k)$.
    - Any node $n \not = \mc{S}(k)$ can cache $k$.

[• Requests can enter network at any node.]{.fragment fragment-index=1}

[• Responses carry data back, following reverse path.]{.fragment fragment-index=2}

[• Nodes can respond from their cache.]{.fragment fragment-index=3}

:::
::: {.column width=60%}

::: {.r-stack}
![](images/dpmodel_1.svg){.fragment fragment-index=1 width="1200" fig-align="center" style="transform: translateY(40%)"}

![](images/dpmodel_2.svg){.fragment fragment-index=2 width="1200" fig-align="center" style="transform: translateY(40%)"}

![](images/dpmodel_3.svg){.fragment fragment-index=3 width="1200" fig-align="center" style="transform: translateY(40%)"}
:::

:::
:::

::: {.footer}
System Model
:::

::: {.notes}
- The principles of the data plane are based on those of a classical ICN.
- We use "data object" as the unit of content in the network and assume that each object has a unique source node.
- We particularly assume every object has the same size, which is a crucial assumption we'll need to remember for later.
- Requests can enter network at any node. A request for an object can be met with a data response at the source node for that object or at any node that caches that object.
- Those data responses will follow the path of the request back to the requester (inverse of the path, of course)
:::

## Data Plane Model {.smaller}

::: columns
::: {.column width=80%}

::: {style="font-size: 120%;"}
We propose a [multi-tiered caching model]{.body-highlight}:

• Nodes can have arbitrary number of *cache tiers*.

[• A node can cache an object in at most one of its tiers, i.e. caches are *exclusive*.]{.fragment fragment-index=1}

[• Cache operations are *non-blocking*; hits yield data based on transfer rate and can be queued.]{.fragment fragment-index=2}

[• Each admission or eviction has an associated [utilization cost]{.body-highlight}.]{.fragment fragment-index=3}

[• An object evicted from one tier can [migrate]{.body-highlight} to another tier at the same node.]{.fragment fragment-index=4}
:::

:::
::: {.column width=20%}
::: {.r-stack}
![](images/tier2_admit.svg){.fragment .fade-in-then-out fragment-index=3 width="648" height="360" style="display: block; margin-left: auto; margin-right: 10px; transform: translateY(25%);"}

![](images/migration.svg){.fragment .fade-in fragment-index=4 width="648" height="360" style="display: block; margin-left: auto; margin-right: 10px; transform: translateY(25%);"}
:::
:::
:::


::: {.footer}
System Model
:::

## Virtual Plane Model

::: {style="font-size: 75%;"}
Virtual control plane model using the [VIP framework]{.body-highlight}[^vipog]:

- *Virtual interest packets (VIPs)* generated alongside exogenous requests.
    - Every node keeps a [VIP counter]{.body-highlight} for every object $\kin$.
    - VIPs are removed at object sources and caching nodes.
- Discrete time slots indexed $t = 1, 2, ...$. At the beginning of each slot:
    - Nodes update neighbors with local counter states using small message.
    - Virtual plane algorithm decides cache placement and transmission allocations.
    - VIPs removed / forwarded, counters updated.
:::

[^vipog]: "VIP: A framework for joint dynamic forwarding and caching in named data networks", Yeh, E., Ho, T., Cui, Y., Burd, M., Liu, R., & Leong, D., ACM ICN 2014 @yeh2014vip.

::: {.footer}
System Model
:::

::: {.notes}
- Now, on to the virtual plane model, which is largely based on the original VIP paper. We'll go over it briefly.
- First off, anytime an exogenous request enters the data plane network, a virtual interest packet (VIP for short) is generated in the virtual plane at that node. These VIPs can only be removed at sources or caching points.
- Each node maintains a VIP counter for each object in the network. We can interpret these counts as queues that describe unsatisfied demand for objects. Another useful way to think of these counters is as "potential" values, much like electrical potential, where the potential is high at request entry points and low at sources and caching points.
- We're considering discrete time slots in the virtual plane where caching and forwarding decisions for each time slot are made at the beginning of that time slot.
:::

## VIP Queue Dynamics
[VIP queuing dynamics]{.body-highlight} with multi-tiered caching for object $\kin$ at node $\nin$:

::: {style="font-size: 70%;"}
```{=tex}
\begin{equation*}
    V^k_n(t+1) \leq \Big(V\knt - \textcolor{#C8102E}{\sum\limits_{\jin} r_{n_j} s\knjt} - \sum\limits_{\bin}\mu^k_{nb}(t) \Big)^+ + A\knt 
    + \sum\limits_{\ain}\mu^k_{an}(t)    
\end{equation*}
```
:::
<hr>

::: columns
::: {.column width="50%" style="font-size: 75%;"}
$V^k_n(t)$: VIP count for $k$ at $n$ during $t$.

$A^k_n(t)$: Number of exogenous requests for $k$ at $n$ during $t$.

$\mu^k_{ab}(t)$: Allocated rate of VIPs for $k$ over $(a,b)$ during $t$.
:::
::: {.column width="50%" style="font-size: 75%;"}
$\mathcal{J}_n$: Set of cache tiers at $n$.

$r_{n_j}$: Read rate of tier $j$ at $n$.

$s^k_{n_j}(t)$: Caching state of $k$ in tier $j$ at $n$ at the beginning of $t$.

$(x)^+ = max(x,0)$
:::
:::

::: {.footer}
System Model
:::

::: {.notes}
- This inequality shows how VIP counts change from slot to slot in the virtual plane
- First term is VIPs forwarded away from the node, then we have the exogenous arrivals, then VIPs that arrive from other nodes and finally, VIPs removed due to caching. Notice that this term is dependent on the read rates of cache tiers.
:::