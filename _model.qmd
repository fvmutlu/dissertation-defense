## System Model

![](images/system_model.svg){fig-align="center" width="60%" height="60%"}

::: {.footer}
System Model
:::

::: {.notes}
- Here's a simple illustration of the system model the separation and interaction between the virtual and data planes we're adopting from the VIP paper.
- The data plane is where actual network functionality is performed. The virtual plane uses the request arrival information from the data plane; its where control decisions are made.
:::

## Data Plane Model
Data plane model based on general ICN principles:

::: {.incremental}
-   Unit of content is *data object*; each object $\kin$ has a unique source $\mc{S}(k)$
-   Any node $n \not = \mc{S}(k)$ can cache $k$
-   Every data object has the [same size]{.body-highlight}    
-   Requests can enter network at any node; sources / caching nodes respond to requests with data
-   Data responses follow request path back to requester
:::

::: {.footer}
System Model
:::

::: {.notes}
- The principles of the data plane are based on those of a classical ICN.
- We use "data object" as the unit of content in the network and assume that each object has a unique source node.
- We particularly assume every object has the same size, which is a crucial assumption we'll need to remember for later.
- Requests can enter network at any node. A request for an object can be met with a data response at the source node for that object or at any node that caches that object.
- Those data responses will follow the path of the request back to the requester (inverse of the path, of course)
:::

## Data Plane Model
[Multi-tiered caching model]{.body-highlight} adds following properties:

::: {.incremental}
-   Any node can have any number of cache tiers
-   A node can cache an object in at most one of its tiers ([cache exclusivity]{.body-highlight})
-   An object evicted from one tier can [migrate]{.body-highlight} to another tier at the same node
:::

::: {.footer}
System Model
:::

::: {.notes}
- The multi-tiered caching model I propose adds the following properties to those basic mechanisms.
- Any node can have cache tiers and can cache any object in one of those tiers unless it already sources that object.
- A node can cache an object in at most one of its tiers. This means that we don't duplicate objects across cache tiers. This is also something critical to keep in mind.
- An object evicted from one tier can migrate to another tier at the same node. So an eviction from one tier is not necessarily final for an object.
:::

## Virtual Plane Model
Virtual plane model based on (Yeh, 2014):

::: {.incremental}
-  *Virtual interest packets (VIPs)* generated alongside exogenous requests
-  Every node keeps a [VIP counter]{.body-highlight} for every object $\kin$
-  VIPs are removed at object sources and caching nodes
-  Discrete time slots $t = \{1,2,...\}$
-  Beginning of each time slot, each node decides where and how to forward its VIPs, as well as how to cache objects
:::

::: {.footer}
System Model
:::

::: {.notes}
- Now, on to the virtual plane model, which is largely based on the original VIP paper. We'll go over it briefly.
- First off, anytime an exogenous request enters the data plane network, a virtual interest packet (VIP for short) is generated in the virtual plane at that node. These VIPs can only be removed at sources or caching points.
- Each node maintains a VIP counter for each object in the network. We can interpret these counts as queues that describe unsatisfied demand for objects. Another useful way to think of these counters is as "potential" values, much like electrical potential, where the potential is high at request entry points and low at sources and caching points.
- We're considering discrete time slots in the virtual plane where caching and forwarding decisions for each time slot are made at the beginning of that time slot.
:::

## Virtual Plane Model
Virtual plane model expanded with multiple cache tiers and [penalties]{.body-highlight}:

-   Each cache admission and eviction in virtual plane incurs a penalty
-   Network can configure [weight of penalties]{.body-highlight} via parameter $\omega$

::: {.footer}
System Model
:::

::: {.notes}
- The multi-tiered caching model that I propose, which incorporates cache utilization costs, extends the virtual plane model.
- Each cache admission and eviction in virtual plane incurs a penalty, and a configurable weight parameter, $\omega$, lets the network determine the importance of penalties in its overall objective
:::

## VIP Queue Dynamics
[VIP queue evolution]{.body-highlight} for object $k$ at node $n$, where $(x)^+ = max(x,0)$:

::: {style="font-size: 70%;"}
```{=tex}
\begin{equation}
    V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t) 
    + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \color{#A4804A}{\sum\limits_{j \in \mathcal{J}_n} r_{n_j} s^k_{n_j}(t)} \Bigg)^+    
\end{equation}
```
:::
<hr>

::: columns
::: {.column width="50%" style="font-size: 75%;"}
$V^k_n(t)$: VIP count for $k$ at $n$ during $t$

$A^k_n(t)$: Number of exogenous requests for $k$ at $n$ during $t$

$\mu^k_{ab}(t)$: Allocated rate of VIPs for $k$ over $(a,b)$ during $t$
:::
::: {.column width="50%" style="font-size: 75%;"}
$\mathcal{J}_n$: Set of cache tiers at $n$

$r_{n_j}$: Read rate of tier $j$ at $n$

$s^k_{n_j}(t)$: Caching state of $k$ in tier $j$ at $n$ at the beginning of $t$
:::
:::

::: {.footer}
System Model
:::

::: {.notes}
- This inequality shows how VIP counts change from slot to slot in the virtual plane
- First term is VIPs forwarded away from the node, then we have the exogenous arrivals, then VIPs that arrive from other nodes and finally, VIPs removed due to caching. Notice that this term is dependent on the read rates of cache tiers.
:::

## Penalty Accumulation

Penalty incurred by caching action $s^k_{n_j}(t)$:
```{=tex}
\begin{equation}
    p^k_{n_j}(t) \triangleq 
    \left\{ \begin{array}{ll}
        c^a_{n_j}, & \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = 1 \\
        c^e_{n_j}, & \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = -1 \\
       0, & \text{otherwise}
   \end{array} \right.
\end{equation}
```
[Sum penalty during $t$: $p(t) = \sum_{\kin, \nin, \jin} p^k_{n_j}(t)$]{.fragment}
<hr>

::: columns
::: {.column width="50%" style="font-size: 75%;"}
$s^k_{n_j}(t)$: Caching state of $k$ in tier $j$ at $n$ at the beginning of $t$
:::
::: {.column width="50%" style="font-size: 75%;"}
$c^a_{n_j}$: Admission cost of tier $j$ at node $n$
$c^e_{n_j}$: Eviction cost of tier $j$ at node $n$
:::
:::

::: {.footer}
System Model
:::

::: {.notes}
- This definition shows how caching actions translate to penalties incurred
- (Fragment in) We'll also be concerned with the sum penalty across the network
:::