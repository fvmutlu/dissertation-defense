<!DOCTYPE html>
<html lang="en"><head>
<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/tabby.min.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="index_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.56">

  <meta name="author" content="Research Advisor: Edmund Yeh Committee Members: Elif Uysal, Stratis Ioannidis">
  <title>Cost-aware Joint Caching and Forwarding in Networks with Diverse Cache Resources</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #383a42;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #383a42; } /* Normal */
    code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
    code span.an { color: #50a14f; } /* Annotation */
    code span.at { color: #a626a4; } /* Attribute */
    code span.bn { color: #986801; } /* BaseN */
    code span.bu { color: #a626a4; } /* BuiltIn */
    code span.cf { color: #a626a4; } /* ControlFlow */
    code span.ch { color: #50a14f; } /* Char */
    code span.cn { color: #986801; } /* Constant */
    code span.co { color: #a0a1a7; font-style: italic; } /* Comment */
    code span.cv { color: #e45649; font-style: italic; } /* CommentVar */
    code span.do { color: #e45649; } /* Documentation */
    code span.dt { color: #a626a4; } /* DataType */
    code span.dv { color: #986801; } /* DecVal */
    code span.er { color: #f44747; text-decoration: underline; } /* Error */
    code span.ex { color: #4078f2; font-weight: bold; } /* Extension */
    code span.fl { color: #986801; } /* Float */
    code span.fu { color: #4078f2; } /* Function */
    code span.im { color: #50a14f; } /* Import */
    code span.in { color: #c45b00; } /* Information */
    code span.kw { color: #a626a4; } /* Keyword */
    code span.op { color: #a626a4; } /* Operator */
    code span.ot { color: #27ae60; } /* Other */
    code span.pp { color: #a626a4; } /* Preprocessor */
    code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
    code span.sc { color: #0184bc; } /* SpecialChar */
    code span.ss { color: #da4453; } /* SpecialString */
    code span.st { color: #50a14f; } /* String */
    code span.va { color: #e45649; } /* Variable */
    code span.vs { color: #da4453; } /* VerbatimString */
    code span.wa { color: #da4453; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="styles/styles.css">
  <link href="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script>
  MathJax = {
    loader: {
      load: ['[tex]/boldsymbol']
    },
    tex: {
      tags: "all",
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      packages: {
        '[+]': ['boldsymbol']
      },
      macros: {
        mc: ["\\mathcal{#1}", 1],
        mb: ["\\mathbf{#1}", 1],
        nin: "n \\in \\mathcal{N}",
        bin: "b \\in \\mathcal{N}",
        kin: "k \\in \\mathcal{K}",
        jin: "j \\in \\mathcal{J}_n",
        kjin: "(k,j) \\in \\mathcal{B}_{n,i}",
        nbin: "(n,b) \\in \\mathcal{L}",
        knt: "\^k_n(t)",
        knjt: "\^k_{n_j}(t)",
        argmax: "\\mathop{\\mathrm{argmax}}",
        argmin: "\\mathop{\\mathrm{argmin}}",
      }
    }
  };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Cost-aware Joint Caching and Forwarding in Networks with Diverse Cache Resources</h1>
  <p class="subtitle">Faruk Volkan Mutlu - PhD Dissertation Defense Presentation</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Research Advisor: Edmund Yeh<br>Committee Members: Elif Uysal, Stratis Ioannidis 
</div>
</div>
</div>

</section>
<section id="overview-outline" class="slide level2 smaller">
<h2>Overview &amp; Outline</h2>
<div style="font-size: 110%;">
<ul>
<li class="fragment"><strong>Context</strong>: Information-centric networking (ICN), in-network caching.</li>
<li class="fragment"><strong>Motivation</strong>: Data volume grows exponentially, cache capacities do not scale.</li>
<li class="fragment"><strong>Challenge</strong>: Operating larger caches efficiently is difficult.</li>
<li class="fragment"><strong>Goal</strong>: Policy that observes cache characteristics to address this challenge.</li>
<li class="fragment"><span class="body-highlight">Primary Contribution:</span> Joint <em>multi-tiered caching</em> and forwarding policy for networks with diverse cache resources.
<ul>
<li class="fragment"><strong>Introduction</strong>: Motivation, Challenges, Related Work.</li>
<li class="fragment"><strong>Technical</strong>: System Model, Optimization Framework.</li>
<li class="fragment"><strong>Practical</strong>: Policies, Simulation Experiments, Results.</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Outline</p>
</div>
<div class="hidden">
<p><span class="math display">\[
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\nin}{n \in \mc{N}}
\newcommand{\kin}{k \in \mc{K}}
\newcommand{\jin}{j \in \mc{J}_n}
\newcommand{\knt}{^k_n(t)}
\newcommand{\knjt}{^k_{n_j}(t)}
\newcommand{\kjin}{(k,j) \in \mc{B}_{n,i}}
\newcommand{\iin}{i \in \mc{I}_n}
\newcommand{\ain}{a \in \mc{N}}
\newcommand{\bin}{b \in \mc{N}}
\newcommand{\abin}{(a,b) \in \mc{L}}
\newcommand{\about}{(a,b) \not\in \mc{L}^k}
\newcommand{\betasum}{\sum\limits ^{\sigma_n}_{i=1} \beta_{n,i}}
\newcommand{\betasumnl}{\sum ^{\sigma_n}_{i=1} \beta_{n,i}}
\newcommand{\multind}{\mathbf{1}_{[\kjin]}}
\newcommand{\betasumind}{\sum\limits ^{\sigma_n}_{i=1} \beta_{n,i}\mathbf{1}_{[\kjin]}}
\newcommand{\minpen}{\Psi(\boldsymbol{\lambda})}
\newcommand{\drift}{\Delta(\mathbf{V}(t))}
\newcommand{\norm}[1]{\lVert{#1}\rVert^2_2}
\newcommand{\pen}{\mathbb{E}[P(t)|\mathbf{V}(t)]}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\definecolor{neured}{RGB}{200, 16, 46}
\]</span></p>
</div>
</section>
<section>
<section id="introduction" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Introduction</h1>

</section>
<section id="motivation-data-intensive-science" class="slide level2 smaller">
<h2>Motivation: Data-Intensive Science</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/data_plot.svg"></p>
<ul>
<li>Data-intensive science experiments process huge amounts of data.</li>
<li>Data growth predictions keep moving the bar up.</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/lhcopen_data.svg"></p>
<ul>
<li>Data is continuously distributed across the world for research.</li>
<li>In one year of LHC running, over an exabyte of data is accessed.</li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To expand on my motivation, I’ll first talk about the use case that initially inspired my work.</li>
<li>As you know, large science programs in fields like high-energy physics, genomics etc. deal with experiments that produce huge amounts of data.</li>
<li>For instance, for the LHC, in one year, over an exabyte of data is accessed.</li>
<li>This data also has to constantly be distributed across the world for research, which is a significant networking challenge.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation-data-intensive-science-1" class="slide level2 smaller">
<h2>Motivation: Data-Intensive Science</h2>
<p><em>N-DISE: NDN-based Data Distribution for Large-Scale Data-Intensive Science</em> <sup>1</sup>:</p>
<div>
<ul>
<li class="fragment">First high-performance NDN-based data delivery system for large-scale data-intensive science experiments.</li>
<li class="fragment">Integration of state-of-the-art NDN forwarder, intelligent caching and forwarding, high-performance consumer/producer applications.</li>
<li class="fragment">Extensive testing over wide-area network spanning 5 US campuses using CMS experiment data.</li>
<li class="fragment">Individual contributions:
<ul>
<li class="fragment">Built local testbed for prototyping.</li>
<li class="fragment">Supported WAN deployment and testing.</li>
<li class="fragment">Supported demonstrations during SC21 and SC22.</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To address this, our lab led an effort to build a state-of-the-art, Named Data Networking based data distribution system, which you can read about in the paper we published in ICN 2022.</li>
<li>The point here is, even in this state-of-the-art prototype, we were only able to allocate a small amount of cache space at each router. As you can see it is a drop in the bucket compared to the volumes we expect to be working with.</li>
<li>I also want to briefly mention that, in a separate paper that describes a core technology that enabled the N-DISE system (the NDN-DPDK forwarder), the problem of scaling cache capacities and the need for specialized policies for operating larger caches was specifically outlined as part of future outlook.</li>
<li>So there’s a gap here that motivated my work.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn1"><p>“N-DISE: NDN-based data distribution for large-scale data-intensive science”, Wu, Y., Mutlu, F. V., Liu, Y., Yeh, E., Liu, R., ACM ICN 2022 <span class="citation" data-cites="wu2022ndise"><a href="#/references" role="doc-biblioref" onclick="">[1]</a></span></p></li></ol></aside></section>
<section id="motivation-data-intensive-science-2" class="slide level2">
<h2>Motivation: Data-Intensive Science</h2>
<div style="font-size: 85%;">
<p><strong>Cache capacity challenge:</strong> 20 GB of DRAM cache space allocated at each node.</p>
<div>
<ul>
<li class="fragment">DRAM is the standard cache device due its speed; but is expensive and has limited capacity.</li>
<li class="fragment">Next best option is NVMe SSD; is cheap and has large capacity, but much slower than DRAM.</li>
<li class="fragment">Logical next step: use both!</li>
</ul>
</div>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Placeholder.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation-data-intensive-science-3" class="slide level2">
<h2>Motivation: Data-Intensive Science</h2>
<div style="font-size: 85%;">
<p><strong>Cache capacity challenge:</strong> 20 GB of DRAM cache space allocated at each node.</p>
<ul>
<li>DRAM is the standard cache device due its speed; but is expensive and has limited capacity.</li>
<li>Next best option is NVMe SSD; is cheap and has large capacity, but much slower than DRAM.</li>
<li>Logical next step: use both!</li>
<li>Open problem: “Expanding capacities with persistent memory or NVMe disk storage require novel multi-tier caching algorithms.”<sup>1</sup></li>
</ul>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Placeholder.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn2"><p>“NDN-DPDK: NDN forwarding at 100 Gbps on commodity hardware”, Shi, J., Pesavento, D., &amp; Benmohamed, L., ACM ICN 2020 <span class="citation" data-cites="shi2020ndn"><a href="#/references" role="doc-biblioref" onclick="">[2]</a></span></p></li></ol></aside></section>
<section id="toy-example" class="slide level2 smaller">
<h2>Toy Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/toynet_cache.svg" class="quarto-figure quarto-figure-center" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(C_{ab}\)</span></td>
<td style="text-align: left;">Capacity of link <span class="math inline">\((a,b)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mathcal{N}_c\)</span></td>
<td style="text-align: left;">Set of consumer nodes</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(r_{n_j}\)</span></td>
<td style="text-align: left;">Read rate of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(L_{n_j}\)</span></td>
<td style="text-align: left;">Cache size of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:50%;">
<ul>
<li>Catalog of 1000 objects, ranked in popularity by <span class="body-highlight">Zipf’s law</span></li>
<li>Objects cached by rank:
<ul>
<li>Tier 1: 1-10</li>
<li>Tier 2: 11-50 (100)</li>
</ul></li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now, to both illustrate the capacity challenge more precisely, and to underline how slower caches may help us here, I brought in a toy example.</li>
<li>Here we’re looking at a simple network with a catalog of objects, all hosted by one server.</li>
<li>We assume the popularity distribution of these objects are governed by Zipf’s law. We have a set of consumers making requests for these objects, which go through a forwarder.</li>
<li>The forwarder has three potential tiers of cache, with the first being a fast and small tier, the middling being a lot larger but slower, then the last one being even larger but much slower.</li>
<li>If the forwarder can respond to a request from one its cache tiers, it does so instead of forwarding it to the server. There is a fixed caching policy at the forwarder, according to a priori knowledge of object popularities, as you can see on the screen.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="toy-example-1" class="slide level2 smaller">
<h2>Toy Example</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/zipf_1k.svg"></p>
<ul>
<li>Most popular 1% of objects make up one fifth of all requests</li>
<li>Most popular 10% of objects make up half of all requests</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/small_tiers.svg"></p>
<ul>
<li>Second tier operates slower but improves delay for high request rates</li>
<li>Part of uplink traffic shifted to second tier reducing congestion</li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>First off, on the left hand side, we see the CDF for Zipf’s law. The key observation there is that, in this network, roughly one fifth of all requests will be for the most popular 1% of objects, and half of all requests will be for the most popular 10%.</li>
<li>Now, on the right hand side, we see how adding the middling tier on top of the first tier impacts the total delay in the network. Even though the second tier is slower, it improves delay when there’s more traffic.</li>
<li>This can be linked directly to our observation from Zipf’s law, because even though the second tier has a larger amount of objects cached, the frequency of requests that hit the second tier does not exceed its read capacity, since those objects are less popular.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="toy-example-2" class="slide level2 smaller" data-visibility="uncounted">
<h2>Toy Example</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/zipf_1k.svg"></p>
<ul>
<li>Most popular 1% of objects make up one fifth of all requests</li>
<li>Most popular 10% of objects make up half of all requests</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/all_tiers.svg"></p>
<ul>
<li>Addition of second tier capacity impacts performance negatively</li>
<li>Diverted traffic approaches rate limit of second tier, making it a bottleneck</li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>However, adding the last tier, even though it expands our total cache capacity, impacts delay negatively</li>
<li>Because what I just explained does not hold for the third tier since its much larger and much slower</li>
<li>So we end up trading the delay that would occur on the server link with worse read delay on the third tier.</li>
<li>In summary, larger and slower caches are viable, but we have to be careful in managing them.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="further-considerations" class="slide level2 smaller">
<h2>Further Considerations</h2>
<ul>
<li>Benefits of caching more pronounced when caching and forwarding decisions are tightly coupled<sup>1</sup>.
<ul>
<li>Even more critical with larger, slower caches: traffic should be diverted intelligently so congestion is balanced.</li>
</ul></li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn3"><p>“<em>Coupling caching and forwarding: benefits, analysis, and implementation</em>”, G. Rossini, D. Rossi, ICN 2014</p></li></ol></aside></section>
<section id="further-considerations-1" class="slide level2 smaller" data-visibility="uncounted">
<h2>Further Considerations</h2>
<ul>
<li>Benefits of caching more pronounced when caching and forwarding decisions are tightly coupled<sup>1</sup>.
<ul>
<li>Even more critical with larger, slower caches: traffic should be diverted intelligently so congestion is balanced.</li>
</ul></li>
<li>Caches are not free to use; each operation has an energy cost.</li>
</ul>
<div class="columns">
<div class="column" style="width:42%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/dram_power.png" style="width:80.0%;height:80.0%"></p>
<figcaption>DRAM power consumption</figcaption>
</figure>
</div>
</div><div class="column" style="width:58%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/ssd_power.png" style="width:80.0%;height:80.0%"></p>
<figcaption>NVMe power consumption</figcaption>
</figure>
</div>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn4"><p>“<em>Coupling caching and forwarding: benefits, analysis, and implementation</em>”, G. Rossini, D. Rossi, ICN 2014</p></li></ol></aside></section>
<section id="further-considerations-2" class="slide level2 smaller" data-visibility="uncounted">
<h2>Further Considerations</h2>
<ul>
<li>Benefits of caching more pronounced when caching and forwarding decisions are tightly coupled<sup>1</sup>.
<ul>
<li>Even more critical with larger, slower caches: traffic should be diverted intelligently so congestion is balanced.</li>
</ul></li>
<li>Caches are not free to use; each operation has an energy cost.
<ul>
<li>SSDs also wear out over time as their contents are overwritten.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/ssd_endurance.png" style="width:70.0%;height:70.0%"></p>
<figcaption>NVMe Endurance</figcaption>
</figure>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now of course the capacity challenge is not the only obstacle in our way. There’s another major consideration which is operational costs.</li>
<li>Caches are not free to use, each admission and replacement, and even idle operation has a real cost in energy so if we’re adding even more cache devices we have to be mindful of this cost.</li>
<li>Finally, we look at the question of how can we make sure we’re actually making the most of caches in the network?</li>
<li>Because, now that we’re adding larger caches that are difficult to operate, and also adding costs into the equation, we really want to make sure we’re getting the benefits.</li>
<li>This is where the act of tying caching and forwarding together comes in.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn5"><p>“<em>Coupling caching and forwarding: benefits, analysis, and implementation</em>”, G. Rossini, D. Rossi, ICN 2014</p></li></ol></aside></section>
<section id="goal-contributions" class="slide level2">
<h2>Goal &amp; Contributions</h2>
<p>Develop a joint forwarding and caching policy that:</p>
<ul>
<li>Tracks user demand for objects as basis for decisions.</li>
<li>Utilizes diverse cache resources effectively:
<ul>
<li>Ensures devices are receiving <span class="body-highlight">sustainable hit rates</span>.</li>
<li>Makes <span class="body-highlight">high-value</span> replacement decisions.</li>
</ul></li>
<li>Utilizes bandwidth resources effectively:
<ul>
<li>Steers requests toward caching points.</li>
<li>Forwards requests avoiding congestion.</li>
</ul></li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now, having looked at these considerations, let’s make our goal more explicit.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="related-work" class="slide level2">
<h2>Related Work</h2>
<div style="font-size: 90%;">
<ul>
<li>Literature regarding adoption of <em>flash</em> in ICN:
<ul>
<li>Feasibility of SSD <em>Content Store</em> at Internet scale <span class="citation" data-cites="perino2011reality"><a href="#/references" role="doc-biblioref" onclick="">[3]</a></span>.</li>
<li><em>Hierarchical Content Store</em>, SSD prefetch layer masked behing DRAM <span class="citation" data-cites="rossini2014multi"><a href="#/references" role="doc-biblioref" onclick="">[4]</a></span>, <span class="citation" data-cites="mansilha2015hierarchical"><a href="#/references" role="doc-biblioref" onclick="">[5]</a></span>, <span class="citation" data-cites="mansilha2017exploiting"><a href="#/references" role="doc-biblioref" onclick="">[6]</a></span>.</li>
<li>Non-blocking caching I/O <span class="citation" data-cites="so2014toward"><a href="#/references" role="doc-biblioref" onclick="">[7]</a></span>, <span class="citation" data-cites="pan2021nb"><a href="#/references" role="doc-biblioref" onclick="">[8]</a></span>.</li>
<li>Flash damage aware caching <span class="citation" data-cites="shukla2016designing"><a href="#/references" role="doc-biblioref" onclick="">[9]</a></span>.</li>
</ul></li>
<li>Joint caching and forwarding policies <span class="citation" data-cites="yeh2014vip"><a href="#/references" role="doc-biblioref" onclick="">[10]</a></span>, <span class="citation" data-cites="ioannidis2017jointly"><a href="#/references" role="doc-biblioref" onclick="">[11]</a></span>, <span class="citation" data-cites="mahdian2017mindelay"><a href="#/references" role="doc-biblioref" onclick="">[12]</a></span>.
<ul>
<li>VIP framework <span class="citation" data-cites="yeh2014vip"><a href="#/references" role="doc-biblioref" onclick="">[10]</a></span>: congestion-aware, incorporates cache read rates.</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Related Work</p>
</div>
</section></section>
<section>
<section id="system-model" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>System Model</h1>
<aside class="notes">
<p>That concludes the introduction and leads me into the system model that we’re dealing with.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="system-model-1" class="slide level2">
<h2>System Model</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/system_model.svg" class="quarto-figure quarto-figure-center" style="width:60.0%;height:60.0%"></p>
</figure>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>Here’s a simple illustration of the system model the separation and interaction between the virtual and data planes we’re adopting from the VIP paper.</li>
<li>The data plane is where actual network functionality is performed. The virtual plane uses the request arrival information from the data plane; its where control decisions are made.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-model" class="slide level2">
<h2>Data Plane Model</h2>
<p>Object-level data plane model based on general ICN principles:</p>
<div>
<ul>
<li class="fragment">Unit of content is <em>data object</em>.</li>
<li class="fragment">Each object <span class="math inline">\(\kin\)</span> has a unique source <span class="math inline">\(\mc{S}(k)\)</span>.</li>
<li class="fragment">Every data object has the same <em>unit size</em>.</li>
<li class="fragment">Any node <span class="math inline">\(n \not = \mc{S}(k)\)</span> can cache <span class="math inline">\(k\)</span>.</li>
</ul>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>The principles of the data plane are based on those of a classical ICN.</li>
<li>We use “data object” as the unit of content in the network and assume that each object has a unique source node.</li>
<li>We particularly assume every object has the same size, which is a crucial assumption we’ll need to remember for later.</li>
<li>Requests can enter network at any node. A request for an object can be met with a data response at the source node for that object or at any node that caches that object.</li>
<li>Those data responses will follow the path of the request back to the requester (inverse of the path, of course)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-model-1" class="slide level2">
<h2>Data Plane Model</h2>
<div>
<p>• Requests can enter network at any node.</p>
<p><span class="fragment" data-fragment-index="2">• Responses carry data back, following reverse path.</span></p>
<p><span class="fragment" data-fragment-index="3">• Nodes can respond from their cache.</span></p>
</div>
<div class="r-stack">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/dpmodel_1.svg" class="quarto-figure quarto-figure-center" width="648" height="360"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/dpmodel_2.svg" class="fragment quarto-figure quarto-figure-center" data-fragment-index="2" width="648" height="360"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/dpmodel_3.svg" class="fragment quarto-figure quarto-figure-center" data-fragment-index="3" width="648" height="360"></p>
</figure>
</div>
</div>
<div class="footer">
<p>System Model</p>
</div>
</section>
<section id="data-plane-model-2" class="slide level2">
<h2>Data Plane Model</h2>
<div class="columns">
<div class="column" style="width:80%;">
<p>We propose following <span class="body-highlight">multi-tiered caching model</span> properties:</p>
<p>• Any node can have any number of cache tiers.</p>
<p>• A node can cache an object in at most one of its tiers (<span class="body-highlight">cache exclusivity</span>).</p>
<p><span class="fragment" data-fragment-index="1">• An object evicted from one tier can <span class="body-highlight">migrate</span> to another tier at the same node.</span></p>
<p><span class="fragment" data-fragment-index="2">• Each admission or eviction has an associated <span class="body-highlight">utilization cost</span>.</span></p>
</div><div class="column" style="width:20%;">
<div class="r-stack">
<p><img data-src="images/tier1_admit.svg" class="fragment fade-out" style="display: block; margin-left: auto; margin-right: 10px; transform: translateY(25%);" data-fragment-index="1" width="648" height="360"></p>
<p><img data-src="images/tier2_admit.svg" class="fragment fade-in-then-out" style="display: block; margin-left: auto; margin-right: 10px; transform: translateY(25%);" data-fragment-index="1" width="648" height="360"></p>
<p><img data-src="images/migration.svg" class="fragment fade-in" style="display: block; margin-left: auto; margin-right: 10px; transform: translateY(25%);" data-fragment-index="2" width="648" height="360"></p>
</div>
</div></div>
<div class="footer">
<p>System Model</p>
</div>
</section>
<section id="virtual-plane-model" class="slide level2">
<h2>Virtual Plane Model</h2>
<div style="font-size: 75%;">
<p>Virtual control plane model using the <span class="body-highlight">VIP framework</span><sup>1</sup>:</p>
<div>
<ul>
<li class="fragment"><em>Virtual interest packets (VIPs)</em> generated alongside exogenous requests.
<ul>
<li class="fragment">Every node keeps a <span class="body-highlight">VIP counter</span> for every object <span class="math inline">\(\kin\)</span>.</li>
<li class="fragment">VIPs are removed at object sources and caching nodes.</li>
</ul></li>
<li class="fragment">Discrete time slots indexed <span class="math inline">\(t = 1, 2, ...\)</span>; following happens beginning of each time slot:
<ul>
<li class="fragment">Nodes update neighbors with local counter states using small message.</li>
<li class="fragment">VIPs are removed via caching and forwarded to neighbors, counters updated.</li>
</ul></li>
</ul>
</div>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>Now, on to the virtual plane model, which is largely based on the original VIP paper. We’ll go over it briefly.</li>
<li>First off, anytime an exogenous request enters the data plane network, a virtual interest packet (VIP for short) is generated in the virtual plane at that node. These VIPs can only be removed at sources or caching points.</li>
<li>Each node maintains a VIP counter for each object in the network. We can interpret these counts as queues that describe unsatisfied demand for objects. Another useful way to think of these counters is as “potential” values, much like electrical potential, where the potential is high at request entry points and low at sources and caching points.</li>
<li>We’re considering discrete time slots in the virtual plane where caching and forwarding decisions for each time slot are made at the beginning of that time slot.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn6"><p>“VIP: A framework for joint dynamic forwarding and caching in named data networks”, Yeh, E., Ho, T., Cui, Y., Burd, M., Liu, R., &amp; Leong, D., ACM ICN 2014 <span class="citation" data-cites="yeh2014vip"><a href="#/references" role="doc-biblioref" onclick="">[10]</a></span></p></li></ol></aside></section>
<section id="vip-queue-dynamics" class="slide level2">
<h2>VIP Queue Dynamics</h2>
<p><span class="body-highlight">VIP queuing dynamics</span> with multi-tiered caching for object <span class="math inline">\(\kin\)</span> at node <span class="math inline">\(\nin\)</span>, where <span class="math inline">\((x)^+ = max(x,0)\)</span>:</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation*}
    V^k_n(t+1) \leq \Big(V\knt - \textcolor{#C8102E}{\sum\limits_{\jin} r_{n_j} s\knjt} - \sum\limits_{\bin}\mu^k_{nb}(t) \Big)^+ + A\knt
    + \sum\limits_{\ain}\mu^k_{an}(t)    
\end{equation*}\]</span>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(V^k_n(t)\)</span>: VIP count for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span>.</p>
<p><span class="math inline">\(A^k_n(t)\)</span>: Number of exogenous requests for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span>.</p>
<p><span class="math inline">\(\mu^k_{ab}(t)\)</span>: Allocated rate of VIPs for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span> during <span class="math inline">\(t\)</span>.</p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(\mathcal{J}_n\)</span>: Set of cache tiers at <span class="math inline">\(n\)</span>.</p>
<p><span class="math inline">\(r_{n_j}\)</span>: Read rate of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span>.</p>
<p><span class="math inline">\(s^k_{n_j}(t)\)</span>: Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span>.</p>
</div></div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>This inequality shows how VIP counts change from slot to slot in the virtual plane</li>
<li>First term is VIPs forwarded away from the node, then we have the exogenous arrivals, then VIPs that arrive from other nodes and finally, VIPs removed due to caching. Notice that this term is dependent on the read rates of cache tiers.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="virtual-plane-optimization" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Virtual Plane Optimization</h1>
<aside class="notes">
<p>With the system model described, we will now look at our control algorithm in the virtual plane.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<ul>
<li>We seek an algorithm that can:
<ul>
<li>Guarantee stability of all VIP queues.</li>
<li>Maintain total VIP queue backlog small.</li>
<li>Keep cache-related costs minimal.</li>
</ul></li>
<li>Placeholder.</li>
</ul>
<div class="footer">
<p>Optimization Framework</p>
</div>
</section>
<section id="theorem-stability-region" class="slide level2">
<h2>Theorem: Stability Region</h2>
<p>VIP <span class="body-highlight">stability region</span> <span class="math inline">\(\Lambda\)</span> consists of all arrival rates <span class="math inline">\(\boldsymbol{\lambda} = (\lambda^k_n)_{\kin,\nin}\)</span> such that:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{equation*}
    \lambda^k_n \leq \sum\limits_{\bin} f^k_{nb} - \sum\limits_{\ain} f^k_{an} +  \betasum \sum\limits_{\jin} r_{n_j} \multind
\end{equation*}\]</span>
</div>
<hr>
<div style="font-size: 70%; text-align: center">
<p><span class="math inline">\(f^k_{ab}\)</span>: Time-average actual VIP flow for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span></p>
</div>
<div class="columns">
<div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\mc{B}_{n,i}\)</span>: i-th among all <span class="math inline">\(\sigma_n\)</span> possible cache placement sets at <span class="math inline">\(n\)</span>; if <span class="math inline">\((k,j) \in \mc{B}_{n,i}\)</span> during <span class="math inline">\(t\)</span>, <span class="math inline">\(s^k_{n_j}(t)\)</span> = 1.</p>
</div><div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\beta_{n,i}\)</span>: Fraction of time objects at <span class="math inline">\(n\)</span> are placed according to <span class="math inline">\(\mc{B}_{n,i}\)</span>; <span class="math inline">\(0 \leq \beta_{n,i} \leq 1\)</span> and <span class="math inline">\(\sum^{\sigma_n}_{i=1} \beta_{n,i} = 1\)</span>.</p>
</div></div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The analysis of our approach comes in two steps. We’re following the structure of Lyapunov drift-based analysis here, so we first define the stability region of the virtual plane network.</li>
<li>The inequality on the screen essentially defines the boundary of that stability region, relating the arrival rates that can be satisfied to the long term average VIP flow over links, as well as VIPs removed via cache tiers.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-penalties" class="slide level2">
<h2>Virtual Plane Penalties</h2>
<p>Data plane costs reflected into virtual plane framework; admissions and evictions in virtual plane incur <span class="body-highlight">penalties</span>:</p>
<div style="font-size: 75%;">
<span class="math display">\[\begin{equation*}
    p^k_{n_j}(t) \triangleq
    \left\{ \begin{array}{ll}
        c^a_{n_j}, &amp; \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = 1 \\
        c^e_{n_j}, &amp; \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = -1 \\
       0, &amp; \text{otherwise}
   \end{array} \right.
\end{equation*}\]</span>
<p>Sum penalty during <span class="math inline">\(t\)</span>: <span class="math inline">\(P(t) = \sum_{\kin, \nin, \jin} p^k_{n_j}(t)\)</span>.</p>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(s^k_{n_j}(t)\)</span>: Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span>.</p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(c^a_{n_j}\)</span>: Admission cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span>. <span class="math inline">\(c^e_{n_j}\)</span>: Eviction cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span>.</p>
</div></div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The multi-tiered caching model that I propose, which incorporates cache utilization costs, extends the virtual plane model.</li>
<li>Each cache admission and eviction in virtual plane incurs a penalty, and a configurable weight parameter, <span class="math inline">\(\omega\)</span>, lets the network determine the importance of penalties in its overall objective</li>
<li>This definition shows how caching actions translate to penalties incurred</li>
<li>(Fragment in) We’ll also be concerned with the sum penalty across the network</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="optimization-goal" class="slide level2">
<h2>Optimization Goal</h2>
<p>Minimize upper bound of <span class="body-highlight">drift-plus-penalty</span><sup>1</sup> expression:</p>
<span class="math display">\[\begin{equation*}
    \drift + \omega \pen
\end{equation*}\]</span>
<p>where <span class="math inline">\(\omega \geq 0\)</span> is the <span class="body-highlight">penalty importance weight</span> and</p>
<span class="math display">\[\begin{equation*}
    \drift \triangleq \mathbb{E}[\mathcal{L}(\mathbf{V}(t+1))-\mc{L}(\mathbf{V}(t))|\mathbf{V}(t)]
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
    \mc{L}(\mathbf{V}(t)) \frac{1}{2} \triangleq \sum\limits_{\nin, \kin} (V^k_n(t))^2
\end{equation*}\]</span>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The goal of our optimization in the virtual plane, is to operate as close as possible to the boundary of the stability region of the network of VIP queues, which we will define formally in a bit, while keeping penalties accumulated small.</li>
<li>(Fragment in) In particular, we’re trying to minimize the upper bound on this drift-plus-penalty expression you see on screen, which is based on an extension to Lyapunov optimization devised by Neely.</li>
<li>So in this way, we’re not necessarily trying to make a precisely optimal decision each time slot, but trying to minimize the expected value of an upper bound.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn7"><p>“Stochastic network optimization with application to communication and queueing systems.”, M. J. Neely, Springer Nature, 2022. <span class="citation" data-cites="neely2022stochastic"><a href="#/references" role="doc-biblioref" onclick="">[13]</a></span></p></li></ol></aside></section>
<section id="virtual-plane-algorithm" class="slide level2">
<h2>Virtual Plane Algorithm</h2>
<ul>
<li>Placeholder.</li>
</ul>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>And here’s how we tackle this optimization. We devise an algorithm that’s made of two steps (caching and forwarding), which chooses the respective variables every time slot, to optimize a certain objective based on the VIP counts. We’re looking at the caching step right now.</li>
<li>Obviously there is a lot of math to get to this expression for the objective function, but I’ll give you the intuition briefly.</li>
<li>Because we want to remove as many VIPs from the network as fast as possible, we want to cache the higher VIP count objects in the faster tiers, which is why the read rate multiplies the VIP count here.</li>
<li>However, we also want to make sure that our choices in caching actions do not add large penalties that outweigh the benefits. Of course the importance of that is determined by omega.</li>
<li>And of course we have the cache tier capacity constraints and the cache exclusivity constraints</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-algorithm-1" class="slide level2">
<h2>Virtual Plane Algorithm</h2>
<p>Perform <span class="body-highlight">caching</span> by choosing <span class="math inline">\(s^k_{n_j}(t)\)</span> for each <span class="math inline">\(\kin\)</span> and <span class="math inline">\(j \in \mathcal{J}_n\)</span> to:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{align*}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - \omega p^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align*}\]</span>
</div>
</section>
<section id="lemma-caching-solution" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<div style="font-size: 85%;">
<p>We can rewrite <span class="body-highlight">caching</span> step optimization problem as <em>multiple knapsack problem</em>.</p>
</div>
<div style="font-size: 75%;">
<span class="math display">\[\begin{align*}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} b^k_{n_j}(t) s^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align*}\]</span>
<span class="math display">\[\begin{equation*}
    b^k_{n_j}(t) \triangleq \left\{ \begin{array}{ll}
        r_{n_j} V^k_n(t) - \omega c^a_{n_j}, &amp; \text{if} \; s^k_{n_j}(t-1) = 0 \\
        r_{n_j} V^k_n(t) + \omega c^e_{n_j}, &amp; \text{if} \; s^k_{n_j}(t-1) = 1
    \end{array} \right.
\end{equation*}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Now of course, the validity of our approach hinges on whether we can solve the optimization problem from the caching step.</li>
<li>To do so, we will first rewrite it to clean up this unpleasant form we’ve shown before. And to do that, we will use a two-step transformation of variables.</li>
<li>The first step here is defining an auxiliary “benefit” term and using that to simplify the objective function.</li>
<li>You’ll notice that the problem now looks to be in the form of a generalized assignment problem.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-1" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<div style="font-size: 80%;">
<p>Objects are equally sized; decide variables for each one-object <span class="body-highlight">cache slot</span>; obtain equivalent <span class="body-highlight">linear assignment problem</span>.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/transform.svg" class="quarto-figure quarto-figure-center" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Placeholder.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-2" class="slide level2" data-visibility="uncounted">
<h2>Lemma: Caching Solution</h2>
<div style="font-size: 80%;">
<p>Objects are equally sized; decide variables for each one-object <span class="body-highlight">cache slot</span>; obtain equivalent <span class="body-highlight">linear assignment problem</span>.</p>
</div>
<div style="font-size: 70%;">
<span class="math display">\[\begin{align*}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\iin} b^k_{n_i}(t) s^k_{n_i}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_i}(t) \leq 1, \; \forall \, \iin \\
        &amp; \quad \sum\limits_{\iin} s^k_{n_i}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_i}(t) \in \{0, 1\}, \; \forall \, \kin, \; \iin
\end{align*}\]</span>
</div>
<div style="font-size: 60%; text-align: center">
<span class="math display">\[\begin{equation*}
\mc{I}_n \triangleq \{1, 2, ..., \sum_{\jin} L_{n_j}\}, \; \mc{I}_{n_j} \triangleq \{1 + \sum^{j - 1}_{\ell = 1} L_{n_\ell}, ..., \sum^{j}_{\ell = 1} L_{n_\ell}\}
\end{equation*}
\\\]</span>
<p>If <span class="math inline">\(i \in \mc{I}_{n_j}\)</span>, then <span class="math inline">\(b^k_{n_i}(t) = b^k_{n_j}(t)\)</span> and <span class="math inline">\(s^k_{n_i}(t) = s^k_{n_j}(t)\)</span>.</p>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Now recall the assumption we made in our model that every data object has the same size.</li>
<li>Using that assumption, we can think of each cache tier as made up of several “cache slots” that can each take one object. The number of these per tier depend on the total capacity of that tier. These slots have the same read rate and cost parameters as the tier they belong in.</li>
<li>Now, also recall the cache exclusivity constraint of the original problem. We can easily see that exclusivity across tiers directly translates to exclusivity across these cache slots.</li>
<li>Using these facts we can rewrite the problem again, this time in the form of a linear assignment problem.</li>
<li>Luckily, there are methods that can solve this problem in polynomial time. We specifically rely on a modification of the Jonker-Volgenant algorithm.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-3" class="slide level2" data-visibility="uncounted">
<h2>Lemma: Caching Solution</h2>
<div style="font-size: 80%;">
<p>Objects are equally sized; decide variables for each one-object <span class="body-highlight">cache slot</span>; obtain equivalent <span class="body-highlight">linear assignment problem</span>.</p>
<ul>
<li>Variety of polynomial time algorithms exist; mostly variants of the Hungarian method.</li>
<li>We use one such variant<sup>1</sup> with worst case complexity of <span class="math inline">\(O(L^2_{tot}K)\)</span>, where <span class="math inline">\(L_{tot} = \sum_{\jin} L_{n_j}\)</span>.</li>
</ul>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn8"><p>“On implementing 2D rectangular assignment algorithms”, Crouse, D. F., IEEE Transactions on Aerospace and Electronic Systems 2016</p></li></ol></aside></section>
<section id="virtual-plane-algorithm-2" class="slide level2">
<h2>Virtual Plane Algorithm</h2>
<p>Perform <span class="body-highlight">forwarding</span> by choosing <span class="math inline">\(\mu^k_{ab}(t)\)</span> for each <span class="math inline">\(\kin\)</span> and <span class="math inline">\(\abin^k\)</span> to:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{align*}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\bin} \mu^k_{nb}(t) (V\knt - V^k_b(t)) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} \mu^k_{nb}(t) \leq C_{bn}, \; \forall \; (n,b) \in \mc{L} \\
        &amp; \quad \mu^k_{nb}(t) \geq 0, \; \forall \; (n,b) \in \mc{L}, \; \forall \; \kin \\
        &amp; \quad \mu^k_{nb}(t) = 0, \; \forall \; (n,b) \not \in \mc{L}^k, \; \forall \; \kin
\end{align*}\]</span>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(C_{ab}\)</span>: Capacity of link <span class="math inline">\((a,b)\)</span>.</p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(\mc{L}^k\)</span>: Set of links allowed to transmit VIPs of <span class="math inline">\(k\)</span>, determined by routing policy.</p>
</div></div>
<div class="footer">
<p>Optimization Framework</p>
</div>
</section>
<section id="virtual-plane-forwarding" class="slide level2">
<h2>Virtual Plane Forwarding</h2>
<p>Optimal solution to <span class="body-highlight">forwarding</span> problem is obtained by choosing <span class="math inline">\(\mu^k_{ab}(t)\)</span> as follows.</p>
<div style="font-size: 75%;">
<span class="math display">\[\begin{equation*}
   \mu^k_{ab}(t) =
   \left\{ \begin{array}{ll}
      C_{ba}, &amp; \text{if} \; k = k^*_{ab}(t) \; \text{and} \; W^k_{ab}(t) &gt; 0 \\
      0, &amp; \text{otherwise}
   \end{array} \right.
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
\begin{split}
   W^k_{ab}(t) &amp; \triangleq V^k_a(t) - V^k_b(t), \\
   k^*_{ab}(t) &amp; \triangleq \argmax\limits_{\{k: \abin^k\}} W^k_{ab}(t)
\end{split}
\end{equation*}\]</span>
</div>
<p>This is the well-known <em>backpressure</em> solution, also used in Yeh et al.&nbsp;(2014) <span class="citation" data-cites="yeh2014vip"><a href="#/references" role="doc-biblioref" onclick="">[10]</a></span>.</p>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>And here’s the forwarding step. The neat thing about our extension here is that we don’t actually need to alter the results for forwarding from the original VIP paper, which were based on the backpressure technique.</li>
<li>The intuition here again comes from thinking of VIP counts as potential representing unsatisfied demand. So with the forwarding step, we’re making sure VIP flows follow large differences in potential, essentially steering interests toward sinks, meaning sources or caches.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="theorem-trade-off" class="slide level2 smaller">
<h2>Theorem: Trade-off</h2>
<p>For arrival rate vector <span class="math inline">\(\boldsymbol{\lambda}\)</span>, if there exists <span class="math inline">\(\boldsymbol{\epsilon}\)</span> such that <span class="math inline">\(\boldsymbol{\lambda} + \boldsymbol{\epsilon} \in \Lambda\)</span>, then the proposed algorithm achieves the following:</p>
<div style="font-size: 90%;">
<span class="math display">\[\begin{equation*}
    \lim\limits_{t \rightarrow \infty} \frac{1}{t} \sum\limits^{t}_{\tau=1} \sum\limits_{\nin, \kin} \mathbb{E}[V^k_n(\tau)] \leq \frac{B}{\epsilon} + \omega \frac{\bar{P}(\boldsymbol{\lambda})}{\epsilon}
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
    \lim\limits_{t \rightarrow \infty} \frac{1}{t}\sum\limits^{t}_{\tau=1} \mathbb{E}[P(\tau)] \leq \frac{B}{\omega} + \bar{P}(\boldsymbol{\lambda})
\end{equation*}\]</span>
</div>
<hr>
<div style="font-size: 85%; text-align: center">
<span class="math display">\[\begin{equation*}
    B = \sum_{\nin} \bigg( \sum_{\kin}A^k_{n,max} + \sum_{\ain}C_{an} + \sum_{\bin}C_{nb} + \sum_{\jin} L_{n_j} r_{n_j} \bigg)^2
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
\epsilon = \textstyle \min_{\nin,\kin} \epsilon^k_n
\end{equation*}\]</span>
<p><span class="math inline">\(\bar{P}(\boldsymbol{\lambda})\)</span>: Minimum expected time-average sum penalty achievable by feasible stabilizing policy.</p>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The second step of our analysis is what actually shows the guarantees that our algorithm can provide. Here, we use the definition of the stability region, which is why we needed the previous step.</li>
<li>These two expressions define the upper bounds for time average VIP queue sizes and accumulated penalty in the virtual plane network.</li>
<li>The essential observation here is the trade-off between the bounds. As you can see, the omega value controls which bound we wish to prioritize, because setting it small means lower average queue sizes which translates to better performance, but at the cost of potentially much larger penalties. Setting it large is the inverse of that situation.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="data-plane-strategy" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Data Plane Strategy</h1>
<aside class="notes">
<ul>
<li>So there are several things about applying this virtual plane algorithm within the mechanics of the data plane</li>
<li>Most obvious is that virtual plane decisions are made in discrete time slots, but of course the data plane decisions have to be reactive and continuous</li>
<li>(Next slide)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="transition-to-data-plane" class="slide level2">
<h2>Transition to Data Plane</h2>
<div style="font-size: 90%;">
<p>Considerations for mapping virtual plane algorithm to data plane policies:</p>
<ul>
<li>Data plane requires a <em>caching policy</em> and a <em>forwarding policy</em> operating in real time.</li>
<li>We do not have immediate access to objects for caching purposes in the data plane.</li>
<li>VIP counters only updated each virtual plane time slot and oscillate.</li>
</ul>
<p>We will use virtual plane trends to guide data plane policies.</p>
</div>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>But there is another major consideration</li>
<li>Because VIP counts change frequently and drastically, cache states also tend to change quickly. Basing caching on this behavior directly is impractical in the data plane, especially given that we’re now working with slower caches and considering costs, so we’re trying to be conservative in the replacements we make.</li>
<li>So we adapt this cache score metric from the VIP paper, which is basically a measurement of demand for a certain object over a window of time, based on the VIP counts.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-caching" class="slide level2 smaller">
<h2>Data Plane Caching</h2>
<p>Define virtual plane <span class="body-highlight">incoming VIP flow</span>, averaged over sliding window of <span class="math inline">\(T\)</span> slots:</p>
<span class="math display">\[\begin{equation*}
    \bar{F}_{n,in}^k(t) \triangleq \frac{1}{T} \sum^t_{t' = t - T + 1} \Big( A\knt + \sum_{(a,n) \in \mc{L}^k} F^k_{an}(t') \Big)
\end{equation*}\]</span>
<p>Define <span class="body-highlight">cache benefit</span> metric as follows:</p>
<span class="math display">\[\begin{gather*}
CB^k_{n_j}(\tau) = \begin{cases}
\begin{aligned}
r_{n_j} \bar{F}_{n,in}^k(t) &amp;- \omega c^a_{n_j}, &amp;\text{if } |\mc{K}_{n_j}(\tau)| &lt; L_{n_j} \\
r_{n_j}(\bar{F}_{n,in}^k(t) - \bar{F}_{n,in}^{k^{min}_{n_j}}(t)) &amp;- \omega(c^a_{n_j} + c^e_{n_j}), &amp;\text{otherwise,}
\end{aligned}
\end{cases}
\end{gather*}\]</span>
<hr>
<div style="font-size: 90%;">
<p><span class="math inline">\(\mc{K}_{n_j}(\tau)\)</span>: Set of objects cached in <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> during instance <span class="math inline">\(\tau \in [t,t+1)\)</span> in the data plane.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="math inline">\(F^k_{an}(t)\)</span>: VIPs for <span class="math inline">\(k\)</span> transmitted over <span class="math inline">\((a,n)\)</span> during <span class="math inline">\(t\)</span>.</p>
</div><div class="column" style="width:50%;">
<p><span class="math inline">\(k^{min}_{n_j} = \argmin_{k \in \mc{K}_{n_j}(\tau)} \; \bar{F}_{n,in}^k(t)\)</span></p>
</div></div>
</div>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
</section>
<section id="data-plane-caching-1" class="slide level2">
<h2>Data Plane Caching</h2>
<p>When data for <span class="math inline">\(k \not \in \bigcup_{\jin} \mc{K}_{n_j}(\tau)\)</span> arrives at <span class="math inline">\(n\)</span> at instance <span class="math inline">\(\tau\)</span>, <span class="body-highlight">data plane caching policy</span> at <span class="math inline">\(n\)</span> behaves as follows:</p>
<div style="font-size: 90%;">
<div class="pseudocode-container quarto-float" data-line-number="true" data-caption-prefix="Algorithm:">
<div class="pseudocode">
\begin{algorithm} \caption{Data Plane Caching Policy} \begin{algorithmic} \State Find $j^* = \argmax_{\jin} CB^k_{n_j}(\tau)$. \If{$CB^k_{n_{j^*}}(\tau) &gt; 0$ and $|\mc{K}_{n_{j^*}}(\tau)| &lt; L_{n_{j^*}}$} \State Admit $k$ into $j^*$. \ElsIf{$CB^k_{n_{j^*}}(\tau) &gt; 0$} \State Replace $k^{min}_{n_{j^*}}$ with $k$ and update $\mc{K}_{n_{j^*}}(\tau)$. \State Restart procedure with $k \gets k^{min}_{n_{j^*}}$. \EndIf \end{algorithmic} \end{algorithm}
</div>
</div>
</div>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>Now, to state the exact data plane policy</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-forwarding" class="slide level2">
<h2>Data Plane Forwarding</h2>
<p>Define virtual plane <span class="body-highlight">outgoing VIP flow</span> average:</p>
<span class="math display">\[\begin{equation*}
    \bar{F}_{nb}^k(t) \triangleq \frac{1}{T} \sum\limits^t_{t'=t-T+1} F^k_{nb}(t').
\end{equation*}\]</span>
<p>When request for <span class="math inline">\(k \not \in \bigcup_{\jin} \mc{K}_{n_j}(\tau)\)</span> arrives at <span class="math inline">\(n\)</span> at instance <span class="math inline">\(\tau\)</span>, <span class="body-highlight">data plane forwarding policy</span> forwards it to<sup>1</sup>:</p>
<span class="math display">\[\begin{equation*}
    b^k_n(\tau) \triangleq \argmax_{b:(n,b) \in \mc{L}^k} \bar{F}_{nb}^k(t)
\end{equation*}\]</span>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>As for the forwarding, again this doesn’t need to be altered.</li>
<li>We can directly use this policy from the VIP paper, that also relies on a sliding window average, but this time on outgoing VIP flows.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn9"><p>This follows from Yeh et al.&nbsp;(2014) <span class="citation" data-cites="yeh2014vip"><a href="#/references" role="doc-biblioref" onclick="">[10]</a></span>.</p></li></ol></aside></section>
<section id="chunk-level-decisions" class="slide level2">
<h2>Chunk-level Decisions</h2>
<p>At chunk-level in data plane, we observe the following principles:</p>
<ul>
<li>If a data object is admitted to (evicted from) a cache tier, all its chunks must be admitted to (evicted from) that tier.</li>
<li>Forwarding decision is made upon receiving request for a first chunk. Requests for subsequent chunks are forwarded to the same node.</li>
</ul>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>As a final note, recall that our model and approach is at the object level, but in the real world, the data plane operates at a chunk (or packet) level</li>
<li>So here are the two principles we would observe when applying our approach at the chunk level</li>
<li>(Talk about bullet points)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="experiments" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Experiments</h1>
<aside class="notes">
<ul>
<li>Alright, so how does our strategy fare in experimental evaluations</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="setup" class="slide level2 smaller">
<h2>Setup</h2>
<div>
<ul>
<li class="fragment"><strong>Content Sources:</strong> <span class="math inline">\(\mc{S}(k)\)</span> are selected uniformly at random.</li>
<li class="fragment"><strong>Routing:</strong> <em>Any</em> shortest path (in number of hops) between <span class="math inline">\(n\)</span> and <span class="math inline">\(\mc{S}(k)\)</span>.</li>
<li class="fragment"><strong>Cache Tiers:</strong> Fixed two cache tiers at every node, fast and slow.</li>
<li class="fragment"><strong>Requests:</strong> Requests generated for 100 simulation seconds, run terminates when all requests are resolved.
<ul>
<li class="fragment">Poisson arrivals with rate <span class="math inline">\(\lambda\)</span> at each node; popularity distribution is Zipf with parameter <span class="math inline">\(\gamma\)</span>.</li>
</ul></li>
<li class="fragment"><strong>Baselines:</strong> Leave Copy Everywhere admission, Least Response Time forwarding, adapted replacements:
<ul>
<li class="fragment">Least Recently Used (LRU), First-In-First-Out (FIFO), Uniform Random (UNIF), Least Frequently Used (LFU).</li>
<li class="fragment">Penalty Aware LFU (PA-LFU) for trade-off baseline; uses <em>cache benefit</em> metric with frequency.</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="topologies" class="slide level2 smaller">
<h2>Topologies</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div>

</div>
<div class="quarto-layout-panel" data-layout="[[-1],[-1],[1]]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/abilene.svg"></p>
<figcaption>Abilene (11 nodes)</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/geant.svg"></p>
<figcaption>GEANT (34 nodes)</figcaption>
</figure>
</div>
</div></div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Alright, so when it comes to experiment settings, I first have to stress that the experimentation space for this work is enormous</li>
<li>So the results I’ll show here are those that I think most succinctly show that our approach can deliver on our goals</li>
<li>To start off, these are the four topologies I conducted experiments over</li>
<li>On the left are Abilene and Geant which are real network topologies, and on the right are two stylized graphs</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="parameter-reference-table" class="slide level2 smaller">
<h2>Parameter Reference Table</h2>
<table class="caption-top">
<caption>Common parameters for all scenarios</caption>
<colgroup>
<col style="width: 85%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Number of objects in catalog <span class="math inline">\(\mc{K}\)</span></td>
<td style="text-align: center;">2000</td>
</tr>
<tr class="even">
<td style="text-align: center;">Bandwidth of each link <span class="math inline">\(\abin\)</span>, in objects</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Read rate of tier 1 at each <span class="math inline">\(n\)</span>, in objects/sec</td>
<td style="text-align: center;">25</td>
</tr>
<tr class="even">
<td style="text-align: center;">Admission and eviction costs of tier 1 at each <span class="math inline">\(n\)</span></td>
<td style="text-align: center;">4, 2</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Read rate of tier 2 at each <span class="math inline">\(n\)</span>, in objects/sec</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="even">
<td style="text-align: center;">Admission and eviction costs of tier 2 at each <span class="math inline">\(n\)</span></td>
<td style="text-align: center;">2, 1</td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>As I said, there are a great number of parameters for these experiments and I’m not going to cover each one in the interest of time, but we have this table for reference if needed</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cache-capacity" class="slide level2">
<h2>Cache Capacity</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_abilene_075_15_delay.svg"></p>
<figcaption>VIP/MVIP vs.&nbsp;LFU</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_baselines_abilene_075_15_delay.svg"></p>
<figcaption>Other baselines</figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Delay with increasing cache capacities. Abilene, <span class="math inline">\(\gamma=0.75\)</span>, <span class="math inline">\(\lambda=15\)</span>.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="cache-capacity-1" class="slide level2">
<h2>Cache Capacity</h2>
<div class="columns">
<div class="column" style="width:47%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_abilene_075_15_hits.svg"></p>
<figcaption>Cache hits</figcaption>
</figure>
</div>
</div><div class="column" style="width:53%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_abilene_075_15_hit_delays.svg"></p>
<figcaption>Cache read delays</figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Cache hits and delay due to cache reads. Abilene, <span class="math inline">\(\gamma=0.75\)</span>, <span class="math inline">\(\lambda=15\)</span>.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="cache-capacity-2" class="slide level2">
<h2>Cache Capacity</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_geant_all_075_15.svg" style="width:55.0%;height:55.0%"></p>
<figcaption>VIP/MVIP vs.&nbsp;LFU</figcaption>
</figure>
</div>
<div style="font-size: 80%; text-align: center">
<p>Delay with increasing cache capacities. Geant, <span class="math inline">\(\gamma=0.75\)</span>, <span class="math inline">\(\lambda=15\)</span>.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="cache-capacity-3" class="slide level2">
<h2>Cache Capacity</h2>
<div class="columns">
<div class="column" style="width:47%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_geant_075_15_hits.svg"></p>
<figcaption>Cache hits</figcaption>
</figure>
</div>
</div><div class="column" style="width:53%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_geant_075_15_hit_delays.svg"></p>
<figcaption>Cache read delays</figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Cache hits and delay due to cache reads. Geant, <span class="math inline">\(\gamma=0.75\)</span>, <span class="math inline">\(\lambda=15\)</span>.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="request-pattern-parameters" class="slide level2">
<h2>Request Pattern Parameters</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_req_geant_delay.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.75\)</span></figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/zipf_geant_15_delay.svg"></p>
<figcaption><span class="math inline">\(\lambda=15\)</span></figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Delay with increasing <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\gamma\)</span>. Geant topology. <span class="math inline">\(L_{n_2}\)</span> chosen based on minimum delay points for two tier cases.</p>
</div>
</section>
<section id="more-topologies" class="slide level2 smaller">
<h2>More Topologies</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/alltops_075_15.svg" style="width:70.0%;height:70.0%"></p>
<figcaption>Placeholder.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/alltops_075_15_table.svg" style="width:70.0%;height:70.0%"></p>
<figcaption>Placeholder.</figcaption>
</figure>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="delay-penalty-trade-off" class="slide level2">
<h2>Delay-Penalty Trade-off</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_pen_abilene_15_075.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.75\)</span></figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_pen_abilene_15_05.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.5\)</span></figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Delay vs.&nbsp;penalty curves for MVIP and PA-LFU policies. Abilene, <span class="math inline">\(\lambda=15\)</span>. <span class="math inline">\(\omega\)</span> decreases to the right.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="delay-penalty-trade-off-1" class="slide level2">
<h2>Delay-Penalty Trade-off</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_pen_geant_15_075.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.75\)</span></figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_pen_geant_15_05.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.5\)</span></figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Delay vs.&nbsp;penalty curves for MVIP and PA-LFU policies. Geant, <span class="math inline">\(\lambda=15\)</span>. <span class="math inline">\(\omega\)</span> decreases to the right.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="interest-aggregation" class="slide level2">
<h2>Interest Aggregation</h2>
<p>Placeholder.</p>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="interest-aggregation-1" class="slide level2">
<h2>Interest Aggregation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_req_ia_vip_geant_delay.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.75\)</span></figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/zipf_ia_geant_delay.svg"></p>
<figcaption><span class="math inline">\(\lambda=30\)</span></figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>VIP vs.&nbsp;MVIP, with and without interest aggregation. Geant, <span class="math inline">\(L_{n_1}=5\)</span>, <span class="math inline">\(L_{n_2}=200\)</span> for MVIP and <span class="math inline">\(L_{n_1}=13\)</span> for VIP.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="interest-aggregation-2" class="slide level2">
<h2>Interest Aggregation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_ia_geant_075_50_delay.svg"></p>
<figcaption>VIP/MVIP vs.&nbsp;LFU</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_ia_geant_075_50_baselines_delay.svg"></p>
<figcaption>Other baselines</figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Delay with increasing cache capacities under interest aggregation. Geant, <span class="math inline">\(\gamma=0.75\)</span>, <span class="math inline">\(\lambda=50\)</span>.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="interest-aggregation-3" class="slide level2">
<h2>Interest Aggregation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_ia_geant_075_50_hits.svg"></p>
<figcaption>Cache hits</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/size_comp_ia_geant_075_50_hits_reads_tier2.svg"></p>
<figcaption>Second tier hits vs.&nbsp;reads</figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Number of cache hits and cache reads issued under interest aggregation. Geant topology, <span class="math inline">\(\lambda=50\)</span>, <span class="math inline">\(\gamma=0.75\)</span>.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section>
<section id="interest-aggregation-4" class="slide level2">
<h2>Interest Aggregation</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_pen_ia_geant_30_075.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.75\)</span></figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/mt_pen_ia_geant_30_05.svg"></p>
<figcaption><span class="math inline">\(\gamma=0.5\)</span></figcaption>
</figure>
</div>
</div></div>
<div style="font-size: 80%; text-align: center">
<p>Delay vs.&nbsp;penalty curves, MVIP vs.&nbsp;PA-LFU with and without interest aggregation. Geant, <span class="math inline">\(\lambda=30\)</span>. <span class="math inline">\(\omega\)</span> decreases to the right.</p>
</div>
<div class="footer">
<p>Experiments</p>
</div>
</section></section>
<section>
<section id="virtual-plane-cache-read-rate-control" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Virtual Plane Cache Read Rate Control</h1>

</section>
<section id="overview-1" class="slide level2">
<h2>Overview</h2>
<ul>
<li><strong>Premise:</strong> Initial model assumes cache read rate is constant across objects in virtual plane each slot.</li>
</ul>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation*}
    \color{#808080}{V^k_n(t+1) \leq \Big(V^k_n(t) - \sum_{\jin}} \color{#C8102E}{\boldsymbol{r_{n_j}}} \color{#808080}{s\knjt - \sum\limits_{\bin}\mu^k_{nb}(t)  \Big)^+ + A^k_n(t) + \sum\limits_{\ain}\mu^k_{an}(t)}    
\end{equation*}\]</span>
</div>
<ul>
<li><strong>Hypothesis:</strong> We can control read rate allocations in the virtual plane for better performance.</li>
</ul>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation*}
    \color{#808080}{V^k_n(t+1) \leq \Big(V^k_n(t) - \sum_{\jin}} \color{#C8102E}{\boldsymbol{r\knjt}} \color{#808080}{s\knjt - \sum\limits_{\bin}\mu^k_{nb}(t)  \Big)^+ + A^k_n(t) + \sum\limits_{\ain}\mu^k_{an}(t)}    
\end{equation*}\]</span>
</div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
<aside class="notes">
<ul>
<li>The way we’ll do that is by enforcing a cache read bandwidth constraint</li>
<li>Additional control action each time slot, in product form with another control action</li>
<li>Stability region and its analysis changes significantly</li>
<li>Complexity of caching problem solution reduces</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="overview-2" class="slide level2">
<h2>Overview</h2>
<div style="font-size: 100%;">
<ul>
<li><strong>Reasoning:</strong> Objects in cache receive different hit rates in the data plane.</li>
<li><strong>Penalties:</strong> We omit the weight of caching penalties to study read rate allocation in isolation.</li>
<li><strong>Algorithm:</strong> Should guarantee stability of all VIP queues, minimize total backlog.
<ul>
<li>Consider new control variables and <span class="body-highlight">cache bandwidth constraints</span>, i.e.&nbsp;<span class="math inline">\(\sum_{\kin} r\knjt \leq R_{n_j}\)</span>.</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="theorem-stability-region-1" class="slide level2">
<h2>Theorem: Stability Region</h2>
<p><span class="body-highlight">VIP stability region</span> <span class="math inline">\(\Lambda\)</span> under <em>cache bandwidth constraints</em> consists of all arrival rates <span class="math inline">\(\boldsymbol{\lambda} = (\lambda^k_n)_{\kin,\nin}\)</span> such that:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{equation*}
\lambda^k_n \; \leq \; \sum_{\bin} f^k_{nb} - \sum_{\ain} f^k_{an} + \betasum f^k_{n,i}
\end{equation*}\]</span>
</div>
<hr>
<div style="font-size: 70%; text-align: center">

</div>
<div class="columns">
<div class="column" style="font-size: 70%;">
<p><span class="math inline">\(f^k_{ab}\)</span>: Time-average VIP flow for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span>.</p>
<p><span class="math inline">\(\mc{B}_{n,i}\)</span>: i-th among all <span class="math inline">\(\sigma_n\)</span> possible cache placement sets at <span class="math inline">\(n\)</span>; if <span class="math inline">\((k,j) \in \mc{B}_{n,i}\)</span> during <span class="math inline">\(t\)</span>, <span class="math inline">\(s^k_{n_j}(t)\)</span> = 1.</p>
</div><div class="column" style="font-size: 70%;">
<p><span class="math inline">\(f^k_{n,i}\)</span>: Average VIPs of <span class="math inline">\(k\)</span> removed via caching under placement <span class="math inline">\(\mc{B}_{n,i}\)</span>.</p>
<p><span class="math inline">\(\beta_{n,i}\)</span>: Fraction of time objects at <span class="math inline">\(n\)</span> are placed according to <span class="math inline">\(\mc{B}_{n,i}\)</span>; <span class="math inline">\(0 \leq \beta_{n,i} \leq 1\)</span> and <span class="math inline">\(\sum^{\sigma_n}_{i=1} \beta_{n,i} = 1\)</span>.</p>
</div></div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="virtual-plane-caching" class="slide level2">
<h2>Virtual Plane Caching</h2>
<p>Perform <span class="body-highlight">caching</span> by choosing <span class="math inline">\(r\knjt\)</span> and <span class="math inline">\(s\knjt\)</span> for each <span class="math inline">\(\kin\)</span> and <span class="math inline">\(j \in \mathcal{J}_n\)</span> to:</p>
<div style="font-size: 75%;">
<span class="math display">\[\begin{align*}
    \text{maximize}
        &amp; \quad \sum_{\kin} \sum_{\jin} r\knjt s\knjt V\knt \\
    \text{subject to}
        &amp; \quad \sum_{\kin} s\knjt \leq L_{n_j}, \; \forall \jin \\
        &amp; \quad \sum_{\jin} s\knjt \leq 1, \; \forall \kin \\
        &amp; \quad s\knjt \in \{0,1\}, \; \forall \kin, \, \jin \\
        &amp; \quad \color{#C8102E}{\sum_{\kin} r\knjt \leq R_{n_j}, \; \forall \jin}
\end{align*}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Placeholder</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-4" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<div style="font-size: 80%;">
<p>Given <span class="math inline">\(k_1, k_2, \cdots, k_{J_n}\)</span> such that <span class="math inline">\(V^{k_1}_n(t) \geq V^{k_2}_n(t) \geq ... \geq V^{k_{J_n}}_n(t)\)</span>, optimal solution to revised <span class="body-highlight">caching problem</span> is obtained by choosing <span class="math inline">\(r\knjt\)</span> and <span class="math inline">\(s\knjt\)</span> for each <span class="math inline">\(\jin\)</span> as follows.</p>
<span class="math display">\[\begin{equation*}
    r\knjt =
    \left \{ \begin{array}{ll}
        R_{n_j}, &amp; \text{if} \; k = k_j \; \text{and} \; V\knt &gt; 0 \\
        0, &amp; \text{otherwise}
    \end{array} \right.
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
    s\knjt =
    \left\{ \begin{array}{ll}
        1, &amp; \text{if} \; k = k_j \; \text{and} \; V\knt &gt; 0 \\
        0, &amp; \text{otherwise}
    \end{array} \right.
\end{equation*}\]</span>
<p>This is like the <em>backpressure</em> solution for forwarding.</p>
</div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="theorem-throughput-optimality" class="slide level2">
<h2>Theorem: Throughput Optimality</h2>
<div style="font-size: 80%;">
<p>For arrival rate vector <span class="math inline">\(\boldsymbol{\lambda}\)</span>, if there exists <span class="math inline">\(\boldsymbol{\epsilon}\)</span> such that <span class="math inline">\(\boldsymbol{\lambda} + \boldsymbol{\epsilon} \in \Lambda\)</span>, then:</p>
<span class="math display">\[\begin{equation*}
    \lim\limits_{t \rightarrow \infty} \frac{1}{t} \sum\limits^{t}_{\tau=1} \sum\limits_{\nin, \kin} \mathbb{E}[V^k_n(\tau)] \leq \frac{B}{\epsilon}
\end{equation*}\]</span>
<p>where</p>
<span class="math display">\[\begin{equation*}
\epsilon = \min_{\nin,\kin} ((\epsilon^k_n)_{\nin,\kin})
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
    B = \sum_{\nin} \bigg( \sum_{\kin}A^k_{n,max} + \sum_{\ain}C_{an} + \sum_{\bin}C_{nb} + \sum_{\jin} R_{n_j} \bigg)^2
\end{equation*}\]</span>
</div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="data-plane-application" class="slide level2 smaller">
<h2>Data Plane Application</h2>
<p>When data for <span class="math inline">\(k \not \in \bigcup_{\jin} \mc{K}_{n_j}(\tau)\)</span> arrives at <span class="math inline">\(n\)</span> at instance <span class="math inline">\(\tau \in [t,t+1)\)</span>, <span class="body-highlight">data plane caching policy</span> at <span class="math inline">\(n\)</span> behaves as follows:</p>
<div style="font-size: 75%;">
<div class="pseudocode-container quarto-float" data-line-number="true" data-caption-prefix="Algorithm:">
<div class="pseudocode">
\begin{algorithm} \caption{Data Plane Caching w/ Virtual Plane Cache Read Rate Control} \begin{algorithmic} \State Find cache tier $j^* = \argmax_{\jin} \bar{F}^k_{n_j}(t)$. \If{$\bar{F}^k_{n_{j^*}}(t) \geq \max_{\{ b:(n,b) \in \mc{L}^k \}} \bar{F}_{nb}^k(t)$} \If{$\bar{F}_{n,in}^k(t) &gt; 0$ and $|\mc{K}_{n_{j^*}}(\tau)| &lt; L_{n_{j^*}}$} \State Admit $k$ into $j^*$. \Else \State Find $k_{min} = \argmin_{k \in \mc{K}_{n_{j^*}}(\tau)} \bar{F}_{n,in}^k(t)$. \If{$\bar{F}_{n,in}^k(t) &gt; \bar{F}_{n,in}^{k_{min}}(t)$} \State Replace $k_{min}$ with $k$, and restart procedure for $k_{min}$. \EndIf \EndIf \EndIf \end{algorithmic} \end{algorithm}
</div>
</div>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(F\knjt\)</span>: Actual amount of VIPs of <span class="math inline">\(k\)</span> removed via tier <span class="math inline">\(j\)</span> read rate allocation in slot <span class="math inline">\(t\)</span>.</p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(\bar{F}^k_{n_j}(t) \triangleq \frac{1}{T} \sum^t_{t'=t-T+1} F^k_{n_j}(t')\)</span>.</p>
</div></div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="policy-performance" class="slide level2 smaller">
<h2>Policy Performance</h2>
<ul>
<li>This approach yields poor performance in the data plane.
<ul>
<li><em>Significant underutilization</em> of slow tier.</li>
</ul></li>
<li>We attribute this outcome to virtual plane <em>queue underflows</em>.
<ul>
<li>Data plane policies are not fed actionable flow information for many objects in a timely manner.</li>
</ul></li>
<li>Allocation problem under <em>“no-underflow”</em> constraints is difficult to solve <sup>1</sup>.
<ul>
<li>Backpressure solution no longer optimal.</li>
<li>All control variables must be optimized in combination.</li>
<li>Non-convex problem with integer variables.</li>
</ul></li>
</ul>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
<aside><ol class="aside-footnotes"><li id="fn10"><p>“Utility optimal scheduling in processing networks”, Huang, L., &amp; Neely, M. J., Performance Evaluation, 2011 <span class="citation" data-cites="huang2011utility"><a href="#/references" role="doc-biblioref" onclick="">[14]</a></span></p></li></ol></aside></section>
<section id="greedy-approach" class="slide level2">
<h2>Greedy Approach</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 45%;">
<div class="pseudocode-container quarto-float" data-line-number="true" data-caption-prefix="Procedure:">
<div class="pseudocode">
\begin{algorithm} \caption{Virtual Plane Caching} \begin{algorithmic} \State Find $k_1, k_2, ..., k_K$ with $V^{k_1}_n(t) \geq V^{k_2}_n(t) \geq ... V^{k_{K}}_n(t)$. \State Initialize $i \gets 1$. \While{$\sum_{\kin} s\knjt &lt; L_{n_j}, \;\; \sum_{\kin} r\knjt &lt; R_{n_j}, \; \exists \, \jin$ $\hspace{35pt}$ and $V^{k_i}_n(t) &gt; 0$ and $i \leq K$} \State $j^* \gets \argmax\limits_{\jin : \sum\limits_{\kin} s\knjt &lt; L_{n_j}} \left(R_{n_j} - \sum\limits_{\kin} s\knjt r\knjt \right) V^{k_i}_n(t)$. \State $s^{k_i}_{n_{j^*}}(t) \gets 1$, $r^{k_i}_{n_{j^*}}(t) \gets \min\left( \big(R_{n_j} - \sum_{\kin} s\knjt r\knjt \big), V^{k_i}_n(t)\right)$. \State $i \gets i+1$ \EndWhile \end{algorithmic} \end{algorithm}
</div>
</div>
<div class="pseudocode-container quarto-float" data-line-number="true" data-caption-prefix="Procedure:">
<div class="pseudocode">
\begin{algorithm} \caption{Virtual Plane Forwarding} \begin{algorithmic} \State Initialize set $X_n \gets \{(b, k): \bin, \kin, (n,b) \in \mc{L}^k \}$ \While{$\sum_{\kin} \mu^k_{nb}(t) &lt; C_{bn}, \; \exists \, \nbin$ and $X_n \not = \varnothing$ \\ $\hspace{35pt}$ and $V^{k^*}_n(t) - V^{k^*}_{b^*}(t) &gt; 0$} \State $(b^*,k^*) \gets \argmax_{(b,k) \in X_n} \left( V^k_n(t) - V^k_b(t) \right)$ \State $\mu^{k^*}_{nb^*}(t) \gets \min \Big( \big( C_{bn} - \sum_{\kin} \mu^k_{nb}(t) \big),$ \\ $\big( V^{k^*}_n(t) - \sum_{\jin} s^{k^*}_{n_j}(t) r^{k^*}_{n_j}(t) - \sum_{\nbin^{k^*}} \mu^{k^*}_{nb}(t) \big) \Big)$ \State $X_n \gets X_n \setminus \{ (b^*,k^*) \}$ \EndWhile \end{algorithmic} \end{algorithm}
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="font-size: 60%;">
<p>We propose a greedy iterative algorithm:</p>
<ul>
<li>First allocate cache space and read rate to highest backlog objects.
<ul>
<li>Time complexity dominated by sorting, worst case order of <span class="math inline">\(O(K \log K)\)</span>.</li>
</ul></li>
<li>Then allocate link bandwidth to largest backlog differential objects.
<ul>
<li>Complexity of <span class="math inline">\(O(DK \log DK)\)</span> where <span class="math inline">\(D\)</span> is a given node’s degree.</li>
</ul></li>
<li>Does not allocate more service than existing backlog; terminates when:
<ul>
<li>All cache capacity / bandwidth and all link bandwidth is allocated, or</li>
<li>All backlog is met by allocated service.</li>
</ul></li>
</ul>
</div>
</div></div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="greedy-approach-properties" class="slide level2">
<h2>Greedy Approach: Properties</h2>
<div style="font-size: 75%;">
<ul>
<li>Under <em>heavy congestion</em> where <span class="math inline">\(V\knt \geq \sum_{\nbin^k} C_{bn} + \max\limits_{\jin} R_{n_j}\)</span>, for all <span class="math inline">\(t \geq 1, \nin, \kin\)</span>, greedy algorithm is equivalent to <em>backpressure</em> solution.</li>
<li><em>In general</em>, given backlog state <span class="math inline">\(\mathbf{V}(t)\)</span>, following holds.</li>
</ul>
<span class="math display">\[\begin{equation*}
\begin{split}
    &amp; \sum_{\kin,\jin} \hat{F}\knjt V\knt +
    \sum_{\nbin, \kin} \hat{F}^k_{nb}(t) \big(V^k_n(t) - V^k_b(t) \big) \\
    \geq &amp; \sum_{\kin,\jin} F\knjt V\knt +
    \sum_{\nbin, \kin} F^k_{nb}(t) \big(V^k_n(t) - V^k_b(t) \big)
\end{split}
\end{equation*}\]</span>
<p>where <span class="math inline">\(\hat{F}\knjt\)</span> and <span class="math inline">\(\hat{F}^k_{nb}(t)\)</span> denote actual VIP flows under greedy algorithm allocations.</p>
</div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="experimental-results" class="slide level2">
<h2>Experimental Results</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div>

</div>
<div class="quarto-layout-panel" data-layout="[[-1],[1]]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sbw_comp_abilene_075_30_vip-pit-sums.png" style="width:85.0%;height:85.0%"></p>
<figcaption>Sum of backlogs, Abilene topology, <span class="math inline">\(\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div><div class="column" style="font-size: 75%">
<ul>
<li>Data plane policy supported by initial approach: MVIP-RR; by greedy algorithm MVIP-RR+.</li>
<li>Data plane backlog represented by PIT queue sizes.
<ul>
<li>Sampled along with VIPs at each virtual plane time slot.</li>
<li>Denote samples as <span class="math inline">\(Q\knt\)</span>.</li>
</ul></li>
<li>Greedy algorithm maintains much smaller total VIP backlog.</li>
</ul>
</div></div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="experimental-results-1" class="slide level2">
<h2>Experimental Results</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div>

</div>
<div class="quarto-layout-panel" data-layout="[[-1],[1]]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sbw_comp_abilene_075_30_vip-pit-norms.png" style="width:85.0%;height:85.0%"></p>
<figcaption>Backlog gap, Abilene topology, <span class="math inline">\(\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div><div class="column" style="font-size: 75%">
<ul>
<li>Data plane policy supported by initial approach: MVIP-RR; by greedy algorithm MVIP-RR+.</li>
<li>Data plane backlog represented by PIT queue sizes.
<ul>
<li>Sampled along with VIPs at each virtual plane time slot.</li>
<li>Denote samples as <span class="math inline">\(Q\knt\)</span>.</li>
</ul></li>
<li>Greedy algorithm maintains smaller virtual-data plane backlog <em>“gap”</em>.
<ul>
<li>Distance measure: <span class="math inline">\(\frac{1}{|\mc{N}|} \sum_{\nin} \lVert \mathbf{V}_n(t) - \mathbf{Q}_n(t) \rVert_2\)</span></li>
</ul></li>
</ul>
</div></div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="experimental-results-2" class="slide level2">
<h2>Experimental Results</h2>
<div style="font-size: 75%">
<p>Data plane metrics show:</p>
<ul>
<li>Poor utilization of larger cache tier and resulting performance for MVIP-RR.</li>
<li>Improved delay performance along with great reduction in replacements for MVIP-RR+.</li>
</ul>
</div>
<hr>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sbw_comp_abilene_075_30.png" style="width:90.0%;height:90.0%"></p>
<figcaption>Data plane metrics normalized to MVIP, Abilene topology, <span class="math inline">\(\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150\)</span></figcaption>
</figure>
</div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section>
<section id="experimental-results-3" class="slide level2">
<h2>Experimental Results</h2>
<div style="font-size: 75%">
<p>Data plane metrics show:</p>
<ul>
<li>Poor utilization of larger cache tier and resulting performance for MVIP-RR.</li>
<li>Comparable delay performance along with great reduction in replacements for MVIP-RR+.</li>
</ul>
</div>
<hr>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/sbw_comp_geant_075_30.png" style="width:90.0%;height:90.0%"></p>
<figcaption>Data plane metrics normalized to MVIP, Geant topology, <span class="math inline">\(\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150\)</span></figcaption>
</figure>
</div>
<div class="footer">
<p>Virtual Plane Cache Read Rate Control</p>
</div>
</section></section>
<section>
<section id="simulator" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Simulator</h1>

</section>
<section id="simulator-1" class="slide level2">
<h2>Simulator</h2>
<ul>
<li><strong>Motivation</strong>: Lack of existing simulators with combination of requirements.
<ul>
<li>Support for multi-tiered caches with parameters of interest.</li>
<li>Queuing mechanisms for caches that contribute to delay.</li>
<li>High level of abstraction enabling quick development iteration.</li>
</ul></li>
</ul>
<div class="footer">
<p>Simulator</p>
</div>
</section>
<section id="simulator-2" class="slide level2">
<h2>Simulator</h2>
<div style="font-size: 80%;">
<ul>
<li><strong>Implementation</strong>: Built using Python and the SimPy library for discrete event simulation.
<ul>
<li>Lightweight object-oriented design for easy extensibility.</li>
<li>Single-threaded due to DES; supports simultaneous simulations via <em>multiprocessing</em>.</li>
<li>Suitable for quickly prototyping object-level policies; we abstract several aspects:
<ul>
<li>Object-level simulation.</li>
<li>Unbounded queues and lossless operation.</li>
<li>Generic ICN architecture.</li>
<li>Approximated storage and memory mechanisms.<br>
</li>
</ul></li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Simulator</p>
</div>
</section>
<section id="structure" class="slide level2 smaller">
<h2>Structure</h2>
<ul>
<li><strong>Components</strong>: <span class="code">Packet, Request, Link, Cache, Node, Network</span></li>
<li><span class="code">Request</span> stores metadata.
<ul>
<li>Object identifier, unique request token, statistics etc.</li>
</ul></li>
<li><span class="code">Packet</span> encapsulates <span class="code">Request</span>.
<ul>
<li>Binary direction flag; carries request uplink, response downlink.</li>
</ul></li>
<li><span class="code">Link</span> is a FIFO queue connecting two nodes.
<ul>
<li>Delays <span class="code">Packet</span> delivery based on bandwidth in response direction.</li>
</ul></li>
</ul>
<div class="footer">
<p>Simulator</p>
</div>
</section>
<section id="structure-1" class="slide level2 smaller" data-visibility="uncounted">
<h2>Structure</h2>
<ul>
<li><strong>Components</strong>: <span class="code">Packet, Request, Link, Cache, Node, Network</span></li>
<li><span class="code">Cache</span> is operated by a SimPy process controlling a <em>task queue</em>.
<ul>
<li>Read and write tasks processed based on transfer rate.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/simcache.svg" class="quarto-figure quarto-figure-center" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="footer">
<p>Simulator</p>
</div>
</section>
<section id="structure-2" class="slide level2 smaller" data-visibility="uncounted">
<h2>Structure</h2>
<ul>
<li><strong>Components</strong>: <span class="code">Packet, Request, Link, Cache, Node, Network</span></li>
<li><span class="code">Node</span> encapsulates <span class="code">Cache</span>s, FIB and PIT
<ul>
<li>Implements caching and forwarding policies.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/simnode.svg" class="quarto-figure quarto-figure-center" style="width:60.0%;height:60.0%"></p>
</figure>
</div>
<div class="footer">
<p>Simulator</p>
</div>
</section>
<section id="structure-3" class="slide level2 smaller" data-visibility="uncounted">
<h2>Structure</h2>
<ul>
<li><strong>Components</strong>: <span class="code">Packet, Request, Link, Cache, Node, Network</span></li>
<li><span class="code">Network</span> encapsulates <span class="code">Node</span>s.
<ul>
<li>Initializes configuration and monitors events.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/simnet.svg" class="quarto-figure quarto-figure-center" style="width:65.0%;height:65.0%"></p>
</figure>
</div>
<div class="footer">
<p>Simulator</p>
</div>
</section>
<section id="features" class="slide level2 smaller">
<h2>Features</h2>
<p>Codebase has many features for <em>ease of use</em>.</p>
<ul>
<li>Experiment config and data output in JSON format.
<ul>
<li>Specify parameter sweeps and combinations for multiprocess execution.</li>
<li>Each config set has unique hash; easy to query existing database.</li>
</ul></li>
<li>Library of functions to analyze data tailored to output schema.</li>
<li>Docker container for easy deployment.</li>
<li>GitHub Action to quickly run experiments.</li>
</ul>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>request_rate_config.json</strong></pre>
</div>
<div class="sourceCode" id="cb1" data-filename="request_rate_config.json"><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb1-1"><a href=""></a><span class="fu">{</span></span>
<span id="cb1-2"><a href=""></a>    <span class="dt">"fwd_pol"</span>                <span class="fu">:</span> <span class="ot">[</span><span class="st">"lrt"</span><span class="ot">,</span><span class="st">"vip"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb1-3"><a href=""></a>    <span class="dt">"cache_pol"</span>              <span class="fu">:</span> <span class="ot">[</span><span class="st">"lfu"</span><span class="ot">,</span><span class="st">"lru"</span><span class="ot">,</span><span class="st">"fifo"</span><span class="ot">,</span><span class="st">"unif"</span><span class="ot">,</span><span class="st">"mvip"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb1-4"><a href=""></a>    <span class="er">...</span> <span class="er">more</span> <span class="er">parameters</span> <span class="er">...</span></span>
<span id="cb1-5"><a href=""></a>    <span class="dt">"request_rate"</span>           <span class="fu">:</span> <span class="ot">[</span><span class="dv">10</span><span class="ot">,</span><span class="fl">12.5</span><span class="ot">,</span><span class="dv">15</span><span class="ot">,</span><span class="fl">17.5</span><span class="ot">,</span><span class="dv">20</span><span class="ot">,</span><span class="fl">22.5</span><span class="ot">,</span><span class="dv">25</span><span class="ot">,</span><span class="fl">27.5</span><span class="ot">,</span><span class="dv">30</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb1-6"><a href=""></a>    <span class="dt">"request_dist_param"</span>     <span class="fu">:</span> <span class="ot">[</span><span class="dv">0</span><span class="er">.</span><span class="dv">25</span><span class="ot">,</span><span class="dv">0</span><span class="er">.</span><span class="dv">5</span><span class="ot">,</span><span class="dv">0</span><span class="er">.</span><span class="dv">75</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb1-7"><a href=""></a>    <span class="dt">"cache_capacities"</span>       <span class="fu">:</span> <span class="ot">[[</span><span class="dv">5</span><span class="ot">,</span><span class="dv">100</span><span class="ot">],[</span><span class="dv">5</span><span class="ot">,</span><span class="dv">125</span><span class="ot">],[</span><span class="dv">5</span><span class="ot">,</span><span class="dv">150</span><span class="ot">]]</span><span class="fu">,</span></span>
<span id="cb1-8"><a href=""></a>    <span class="er">...</span> <span class="er">more</span> <span class="er">parameters</span> <span class="er">...</span></span>
<span id="cb1-9"><a href=""></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="footer">
<p>Simulator</p>
</div>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<div>
<ul>
<li class="fragment">We address a critical and practical problem in scaling high-throughput caching networks</li>
<li class="fragment">Our proposed model and approach achieves our goals and performs decently, but has shortcomings</li>
<li class="fragment">Some improvements can be made by reiterating on technical details, further fine tuning requires experimentation</li>
</ul>
</div>
<div class="footer">
<p>Summary</p>
</div>
<aside class="notes">
<ul>
<li>I should also note that we submitted a paper on this to MobiHoc last year which was rejected</li>
<li>We’re currently revising the paper for the upcoming ICC</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="power-caching-in-wireless-hetnets" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Power &amp; Caching in Wireless HetNets</h1>

</section>
<section id="power-caching-in-wireless-hetnets-1" class="slide level2">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<ul>
<li>Delay minimization in multi-hop wireless HetNets via caching and power control (led by Derya Malak)</li>
</ul>
<p><img src="images/hetnet.svg" style="display: block; margin-left: auto; margin-right: auto; width: 40%; height: 40%;"></p>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-2" class="slide level2">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<ul>
<li>Delay minimization in multi-hop wireless HetNets via caching and power control</li>
<li>Contributed with:
<ul>
<li>Joint convexity analysis of optimization problem</li>
<li>Projected subgradient method algorithm for finding local minima</li>
<li>Simulator built in Julia, numerical experiments using said simulator</li>
</ul></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-3" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Model</strong>: Arbitrary multi-hop wireless heterogenous network (HetNet) topology:</p>
<ul>
<li>MCs, SCs, and users; MCs and SCs have wireline backhaul connections</li>
<li>All wireless transmissions share channel, i.e.&nbsp;no interference management</li>
<li>All nodes can be equipped with caches</li>
<li>Pre-determined shortest path (in hops) routing</li>
</ul>
<p><strong>Goal</strong>: Minimize delay in network by controlling power and caching allocation</p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/hetnet.svg"></p>
<figcaption>HetNet illustration</figcaption>
</figure>
</div>
</div></div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-4" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p>
<span class="math display">\[\begin{equation}
\text{SINR}_{vu}(S)=\frac{ G_{vu}s_{vu}}{N_u+  \sum\limits_{j\in V\backslash v}G_{ju}\sum\limits_{w}s_{jw}+G_{vu}\sum\limits_{w\neq u}s_{vw}}
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
f(\text{SINR}_{vu}(S)) = \frac{1}{\log_2(1+\text{SINR}_{vu}(S))}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-5" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p>
<span class="math display">\[\begin{equation}
D_{(i,p)}^o(X,S)=\sum\limits_{k=1}^{|p|-1}f(\text{SINR}_{p_{k+1}p_k}(S))\prod\limits_{l=1}^k (1-x_{p_l i})
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
D^o(X,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)}{D_{(i,p)}^o(X,S)}}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-6" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p></li>
<li><p>Convex relaxation on these leads to reduced-complexity formulation (RCF)</p>
<span class="math display">\[\begin{equation}
D_{(i,p)}(Y,S)={\sum\limits_{k=1}^{|p|-1}f(\text{SINR}_{p_{k+1}p_k}(S)) g_{p_k i}(Y) }
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
g_{p_k i}(Y)=1-\min\Big\{1,\sum\limits_{l=1}^k y_{p_l i}\Big\},\,\quad\forall\, y_{p_li}\in [0, 1]
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
D(Y,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)} D_{(i,p)}(Y,S)}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-7" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p></li>
<li><p>Convex relaxation on these leads to reduced-complexity formulation (RCF)</p>
<span class="math display">\[\begin{equation}
D(Y,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)} D_{(i,p)}(Y,S)}
\end{equation}\]</span></li>
<li><p>RCF is not jointly convex in power and caching</p></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="subgradient-projection-algorithm" class="slide level2 smaller">
<h2>Subgradient Projection Algorithm</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 90%;">
<div class="pseudocode-container quarto-float" data-line-number="true" data-caption-prefix="Algorithm:">
<div class="pseudocode">
\begin{algorithm} \caption{Subgradient Projection} \begin{algorithmic} \State{Choose $S^{0}$, $Y^{0}$, small scalar $\epsilon &gt; 0$ and let $t=0$.} \While{$D^t - D^{t-1} &gt; \epsilon \;$} \State{Compute subgradients $d^t_S, d^t_Y$.} \State{Determine step sizes $\xi^t_Y$, $\xi^t_S $.} \State{Compute projected variables $\bar{S}^t$, ${\bar{Y}}^t$.} \State{$t \gets t+1, S^{t+1} \gets \bar{S}^t, Y^{t+1} \gets \bar{Y}^t$.} \EndWhile \State{$(Y^{*}_{sub},S^{*}_{sub}) \gets (Y^{t},S^{t})$.} \State{Perform pipage rounding on $(Y^{*}_{sub},S^{*}_{sub})$.} \end{algorithmic} \end{algorithm}
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="font-size: 80%;">
<span class="math display">\[\begin{equation*}
\begin{split}
    &amp; \quad d_S^t = \nabla_S D(Y^t,S^t), \; d^t_{Y} \in \partial_{Y}D(Y^t,S^t) \\
    &amp; \quad \xi^t_{Y} = \frac{D^t - \hat{D}^t}{\norm{d_{Y}^t}}, \; \xi_S^t = \frac{D^t - \hat{D}^t}{\norm{d_S^t}} \\
    &amp; \quad \bar{S}^t = \mc{P}_{\mc{D}_S}(S^t - \xi_{S}^t d_{S}^t), \; \bar{Y}^t = \mc{P}_{\mc{D}_Y}(Y^t - \xi^t_{Y} d^t_{Y})
\end{split}
\end{equation*}\]</span>
</div>
</div></div>
<div class="footer">
<p>Power &amp; Caching in Wireless HetNets</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-8" class="slide level2 smaller" data-visibility="uncounted">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/hetnet_result1.svg" style="width:55.0%;height:55.0%"></p>
<figcaption>     Power budget</figcaption>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-9" class="slide level2 smaller" data-visibility="uncounted">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/hetnet_result3.svg" style="width:55.0%;height:55.0%"></p>
<figcaption>     SC cache capacity</figcaption>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-10" class="slide level2 smaller" data-visibility="uncounted">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/hetnet_result2.svg" style="width:55.0%;height:55.0%"></p>
<figcaption>     Zipf parameter</figcaption>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section></section>
<section>
<section id="appendices" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Appendices</h1>

</section>
<section id="appendix-a" class="slide level2">
<h2>Appendix A</h2>
<ul>
<li>Placeholder</li>
</ul>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-wu2022ndise" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Y. Wu <em>et al.</em>, <span>“<span class="nocase">N-DISE: NDN-based data distribution for large-scale data-intensive science</span>,”</span> in <em>Proceedings of the 9th ACM conference on information-centric networking</em>, in ICN ’22. New York, NY, USA: Association for Computing Machinery, 2022, pp. 103–113. doi: <a href="https://doi.org/10.1145/3517212.3558087">10.1145/3517212.3558087</a>.</div>
</div>
<div id="ref-shi2020ndn" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">J. Shi, D. Pesavento, and L. Benmohamed, <span>“<span class="nocase">NDN-DPDK: NDN forwarding at 100 Gbps on commodity hardware</span>,”</span> in <em>Proceedings of the 7th ACM conference on information-centric networking</em>, 2020, pp. 30–40.</div>
</div>
<div id="ref-perino2011reality" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">D. Perino and M. Varvello, <span>“A reality check for content centric networking,”</span> in <em>Proceedings of the ACM SIGCOMM workshop on information-centric networking</em>, 2011, pp. 44–49.</div>
</div>
<div id="ref-rossini2014multi" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">G. Rossini, D. Rossi, M. Garetto, and E. Leonardi, <span>“Multi-terabyte and multi-gbps information centric routers,”</span> in <em>IEEE INFOCOM 2014 - IEEE conference on computer communications</em>, 2014, pp. 181–189. doi: <a href="https://doi.org/10.1109/INFOCOM.2014.6847938">10.1109/INFOCOM.2014.6847938</a>.</div>
</div>
<div id="ref-mansilha2015hierarchical" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">R. B. Mansilha <em>et al.</em>, <span>“Hierarchical content stores in high-speed ICN routers: Emulation and prototype implementation,”</span> in <em>Proceedings of the 2nd ACM conference on information-centric networking</em>, 2015, pp. 59–68.</div>
</div>
<div id="ref-mansilha2017exploiting" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">R. B. Mansilha, M. P. Barcellos, E. Leonardi, and D. Rossi, <span>“Exploiting parallelism in hierarchical content stores for high-speed ICN routers,”</span> <em>Computer Networks</em>, vol. 125, pp. 132–145, 2017.</div>
</div>
<div id="ref-so2014toward" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">W. So, T. Chung, H. Yuan, D. Oran, and M. Stapp, <span>“Toward terabyte-scale caching with SSD in a named data networking router,”</span> in <em>Proceedings of the tenth ACM/IEEE symposium on architectures for networking and communications systems</em>, in ANCS ’14. New York, NY, USA: Association for Computing Machinery, 2014, pp. 241–242.</div>
</div>
<div id="ref-pan2021nb" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">T. Pan <em>et al.</em>, <span>“Nb-cache: Non-blocking in-network caching for high-performance content routers,”</span> <em>IEEE/ACM Transactions on Networking</em>, vol. 29, no. 5, pp. 1976–1989, 2021.</div>
</div>
<div id="ref-shukla2016designing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">S. Shukla and A. A. Abouzeid, <span>“On designing optimal memory damage aware caching policies for content-centric networks,”</span> in <em>2016 14th international symposium on modeling and optimization in mobile, ad hoc, and wireless networks (WiOpt)</em>, IEEE, 2016, pp. 1–8.</div>
</div>
<div id="ref-yeh2014vip" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">E. Yeh, T. Ho, Y. Cui, M. Burd, R. Liu, and D. Leong, <span>“VIP: A framework for joint dynamic forwarding and caching in named data networks,”</span> in <em>Proceedings of the 1st ACM conference on information-centric networking</em>, 2014, pp. 117–126.</div>
</div>
<div id="ref-ioannidis2017jointly" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">S. Ioannidis and E. Yeh, <span>“Jointly optimal routing and caching for arbitrary network topologies,”</span> in <em>Proceedings of the 4th ACM conference on information-centric networking</em>, 2017, pp. 77–87.</div>
</div>
<div id="ref-mahdian2017mindelay" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">M. Mahdian and E. Yeh, <span>“Mindelay: <span class="nocase">Low-latency</span> forwarding and caching algorithms for information-centric networks,”</span> <em>arXiv preprint arXiv:1710.05130</em>, 2017.</div>
</div>
<div id="ref-neely2022stochastic" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">M. Neely, <em>Stochastic network optimization with application to communication and queueing systems</em>. Springer Nature, 2022.</div>
</div>
<div id="ref-huang2011utility" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">L. Huang and M. J. Neely, <span>“Utility optimal scheduling in processing networks,”</span> <em>Performance Evaluation</em>, vol. 68, no. 11, pp. 1002–1021, 2011.</div>
</div>
</div>
<div class="quarto-auto-generated-content">
<p><img src="images/neu_logo.svg" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section></section>

    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="index_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="index_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="index_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="index_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="index_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="index_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
        <script type="text/javascript">
        (function(d) {
          d.querySelectorAll(".pseudocode-container").forEach(function(el) {
            let pseudocodeOptions = {
              indentSize: el.dataset.indentSize || "1.2em",
              commentDelimiter: el.dataset.commentDelimiter || "//",
              lineNumber: el.dataset.lineNumber === "true" ? true : false,
              lineNumberPunc: el.dataset.lineNumberPunc || ":",
              noEnd: el.dataset.noEnd === "true" ? true : false,
              titlePrefix: el.dataset.captionPrefix || "Algorithm"
            };
            pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
          });
        })(document);
        (function(d) {
          d.querySelectorAll(".pseudocode-container").forEach(function(el) {
            let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
            if (captionSpan !== null) {
              let captionPrefix = el.dataset.captionPrefix + " ";
              let captionNumber = "";
              if (el.dataset.pseudocodeNumber) {
                captionNumber = el.dataset.pseudocodeNumber + " ";
                if (el.dataset.chapterLevel) {
                  captionNumber = el.dataset.chapterLevel + "." + captionNumber;
                }
              }
              captionSpan.innerHTML = captionPrefix + captionNumber;
            }
          });
        })(document);
        </script>
      
    

</body></html>