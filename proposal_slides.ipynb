{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Placeholder Title\"\n",
        "subtitle: \"Faruk Volkan Mutlu - PhD Proposal Review\"\n",
        "author: \"Research Advisor: Edmund Yeh<br>Committee Members: Elif Uysal, Stratis Ioannidis\"\n",
        "format:\n",
        "  revealjs:\n",
        "    slide-number: true\n",
        "    theme: white\n",
        "    logo: images/neu_logo.svg\n",
        "    css: styles/logo.css\n",
        "---"
      ],
      "id": "d3ffce48"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outline {.smaller}\n",
        "\n",
        "The outline of this presentation is as follows:\n",
        "\n",
        "1. General Context\n",
        "2. Joint Caching and Forwarding in Networks with Hybrid Storage Systems\n",
        "   - Motivation\n",
        "   - Related Work\n",
        "   - Contributions\n",
        "   - Proposed Work\n",
        "3. Other Contributions\n",
        "   - Joint Power Control and Caching in Wireless HetNets\n",
        "   - NDN for Data Intensive Science Experiments*\n",
        "4. Conclusion and Acknowledgements\n",
        "\n",
        "::: {.footer}\n",
        "Outline\n",
        ":::\n",
        "\n",
        "::: {.notes}\n",
        "- We'll first go over the general context in which my research fits\n",
        "- We'll then cover two major research directions I've pursued and am pursuing\n",
        "- The first one makes up the bulk of the content of this presentation since it is work that I am heading\n",
        "- I will also take an aside while discussing that, to mention a more implementation-oriented project that I am part of, which originated the purpose of my work on the first topic\n",
        "- The second one is work which I played a major role in building, but was originally proposed by Derya Malak, who was a postdoc in our lab during my first year and a current collaborator \n",
        "- The proposed work section will focus on the first of these topics and introduce extensions I plan on pursuing for the remainder of my dissertation work\n",
        "- Then of course there will be a brief conclusion\n",
        ":::\n",
        "\n",
        "::: {.hidden}\n",
        "$$\n",
        "\\newcommand{\\mc}[1]{\\mathcal{#1}}\n",
        "\\newcommand{\\mb}[1]{\\mathbf{#1}}\n",
        "\\newcommand{\\nin}{n \\in \\mc{N}}\n",
        "\\newcommand{\\kin}{k \\in \\mc{K}}\n",
        "\\newcommand{\\jin}{j \\in \\mc{J}_n}\n",
        "\\newcommand{\\kjin}{(k,j) \\in \\mc{B}_{n,i}}\n",
        "\\newcommand{\\iin}{i \\in \\mc{I}_n}\n",
        "\\newcommand{\\ain}{a \\in \\mc{N}}\n",
        "\\newcommand{\\bin}{b \\in \\mc{N}}\n",
        "\\newcommand{\\abin}{(a,b) \\in \\mc{L}}\n",
        "\\newcommand{\\about}{(a,b) \\not\\in \\mc{L}^k}\n",
        "\\newcommand{\\betasum}{\\sum\\limits ^{\\sigma}_{i=1} \\beta_{n,i}}\n",
        "\\newcommand{\\betasumnl}{\\sum ^{\\sigma}_{i=1} \\beta_{n,i}}\n",
        "\\newcommand{\\betasumind}{\\sum\\limits ^{\\sigma}_{i=1} \\beta_{n,i}\\mathbf{1}_{[\\kjin]}}\n",
        "\\newcommand{\\minpen}{\\Psi(\\boldsymbol{\\lambda})}\n",
        "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
        "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
        "$$\n",
        ":::\n",
        "\n",
        "# Context\n",
        "\n",
        "## Information Centric Networking\n",
        "\n",
        "- **Motivation**: The Internet is primarily a data distribution network, yet its principles are those of a communication network\n",
        "- **Premise**: Make uniquely named data the primary entity of the network, instead of endpoints\n",
        "- **Advantages**: Improve efficiency and scalability by decoupling data from location and session\n",
        "\n",
        "::: {.footer}\n",
        "Context\n",
        ":::\n",
        "\n",
        "## In-network Caching\n",
        "\n",
        "- **Motivation**: Current caching infrastructure is mostly proprietary and centralized\n",
        "- **Premise**: Enable every router in the network to maintain its own cache\n",
        "- **Advantages**: Caching becomes decentralized, reducing network congestion and improving scalability\n",
        "\n",
        "::: {.footer}\n",
        "Context\n",
        ":::\n",
        "\n",
        "## Wireless Edge & HetNets\n",
        "\n",
        "- Interface between local devices and wider network infrastructure\n",
        "- Many edge devices are connected wirelessly and through various access technologies (HetNet)\n",
        "- **Importance**: Edge-computing is gaining prevalance, driving more computation towards the network edge\n",
        "\n",
        "::: {.footer}\n",
        "Context\n",
        ":::\n",
        "\n",
        "# Research Topic I\n",
        "<h3>Joint Caching and Forwarding in Networks with Hybrid Storage Systems</h3>\n",
        "\n",
        "## Overview {.smaller .incremental}\n",
        "\n",
        "-  Data volume is growing exponentially, but capacities of in-network caches are stagnant\n",
        "-  Enabling larger caches in a cost-effective way is not trivial\n",
        "-  We consider the following:\n",
        "   -  How beneficial are larger caches?\n",
        "   -  Are slower and larger storage elements viable as caches?\n",
        "   -  What are the costs of operating large caches?\n",
        "   -  How can we get the most out of caches in the network?\n",
        "-  We develop a joint caching and forwarding strategy that incorporates these considerations\n",
        "\n",
        "## Toy Example {.smaller}\n",
        "\n",
        "![](images/toynet.svg){width=60% height=60% fig-align=\"center\"}\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "| Notation | Definition |\n",
        "|:-:|:---------------|\n",
        "|$C_{ab}$|Capacity of link $(a,b)$|\n",
        "|$\\mathcal{N}_c$|Set of consumer nodes|\n",
        "|$\\mathcal{K}$|Set of data objects|\n",
        "|$\\alpha$|Zipf's law parameter|\n",
        "|$L_{a}$|Cache size (in packets) at node $a$|\n",
        "|$\\lambda$|Total incoming request rate at forwarder|\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "-  Catalog of $|\\mathcal{K}|=1000$ single-packet objects, ranked in popularity according to Zipf's law with parameter $\\alpha=0.75$\n",
        "-  Consumer nodes send requests to the forwarder node, which either responds from its cache or forwards them upstream to server\n",
        "-  Caching at the forwarder is clairvoyant, i.e. most popular $L_{f}$ objects are cached\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.footer}\n",
        "Motivation\n",
        ":::\n",
        "\n",
        "## Case for Larger Caches {.smaller}\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/zipf_1k.svg)\n",
        "\n",
        "::: {.fragment}\n",
        "-  Most popular 10% of objects make up half of all requests\n",
        "-  Most popular 1% of objects make up one fifth of all requests\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/cache_size.svg){.fragment}\n",
        "\n",
        "::: {.fragment}\n",
        "-  Increasing cache sizes can help reduce delay significantly\n",
        "-  Note that the gain from size increase has diminishing returns\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.footer}\n",
        "Motivation\n",
        ":::\n",
        "\n",
        "## Core Challenge I {.incremental}\n",
        "-  DRAM is the primary cache device since it is fast, i.e. can operate at *line rate*\n",
        "-  However, DRAM offers small cache sizes at a high and exponentially increasing cost ($3 to $12 / GB)\n",
        "-  Next best storage element is the NVMe SSD, offering large cache sizes at significantly lower costs ($0.1 / GB)\n",
        "-  NVMe SSDs can be an order of magnitude slower than DRAM\n",
        "\n",
        "::: {.footer}\n",
        "Motivation\n",
        ":::\n",
        "\n",
        "## Extended Toy Example {.smaller}\n",
        "\n",
        "![](images/toynet_cache.svg){width=75% height=75% fig-align=\"center\"}\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "| Notation | Definition |\n",
        "|:-:|:---------------|\n",
        "|$r_{n_j}$|Read rate of tier $j$ at $n$|\n",
        "|$L_{n_j}$|Cache size of tier $j$ at $n$|\n",
        "\n",
        "Numbered nodes connected by green edges represent potential cache tiers\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "-  Same catalog and popularity distribution, three possible cache tiers\n",
        "-  Objects are cached in order of popularity, starting from tier 1 and moving onto next tier when current one is full\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.footer}\n",
        "Motivation\n",
        ":::\n",
        "\n",
        "## Case for Additional, Slower Caches {.incremental .smaller}\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/two_tiers.svg){.fragment}\n",
        "\n",
        "::: {.fragment}\n",
        "-  Although second tier operates slower than line rate, it improves delay at high request rates\n",
        "-  This is due to the diminishing returns emerging from Zipf's law\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/three_tiers.svg){.fragment}\n",
        "\n",
        "::: {.fragment}\n",
        "-  Addition of the third tier impacts performance negatively\n",
        "-  **Lesson**: Cache tiers need to outpace their own *hit rate*\n",
        ":::\n",
        ":::\n",
        ":::\n",
        "\n",
        "::: {.footer}\n",
        "Motivation\n",
        ":::\n",
        "\n",
        "## Core Challenge II {.incremental}\n",
        "\n",
        "-  Caches are not free to use, every admission and replacement has a cost\n",
        "-  With SSDs, these are more pronounced:\n",
        "   -  They wear out over time\n",
        "   -  Due to their slower speed, cache state transitions take longer\n",
        "   -  Their per-replacement power consumption is larger*\n",
        "\n",
        "## Core Challenge III {.incremental}\n",
        "\n",
        "-  (Talk about joint caching and forwarding)\n",
        "\n",
        "## Goal {.incremental}\n",
        "-  We want a caching policy suitable for systems with a combination of storage elements with different performance and cost paremeters as caches\n",
        "-  This policy needs to:\n",
        "   -  Balance frequency of requests served by cache tiers based on their transfer rates\n",
        "   -  Be adaptable to changing traffic patterns in the network\n",
        "   -  Offer a distributed implementation\n",
        "\n",
        "::: {.footer}\n",
        "Motivation\n",
        ":::\n",
        "\n",
        "## Related Work {.incremental .smaller}\n",
        "\n",
        "-  *\"Multi-Terabyte and multi-Gbps information centric routers\"*, G. Rossini, D. Rossi, M. Garetto, E. Leonardi, INFOCOM 2014\n",
        "   -  Two-layer cache (SSD masked behind DRAM), utilizes \"prefetching\", trace-driven and synthetic simulation results\n",
        "-  *\"Hierarchical Content Stores in High-Speed ICN Routers: Emulation and Prototype Implementation\"*, R. B. Mansilha, L. Saino, M. Barcellos, M. Gallo, E. Leonardi, D. Perino, D. Rossi, ICN 2015\n",
        "   -  Follow-up to above work, prototype implementation\n",
        "-  *\"Exploiting parallelism in hierarchical content stores for high-speed ICN routers\"*, R. B. Mansilha, M. Barcellos, E. Leonardi, D. Rossi, COMNET 2017\n",
        "   -  Follow-up to above works, integrates HCS design with NDN Forwarding Daemon (NFD)\n",
        "\n",
        "## Related Work {.incremental .smaller}\n",
        "-  *\"Toward terabyte-scale caching with SSD in a named data networking router\"*, W. So, T. Chung, H. Yuan, D. Oran, M. Stapp, ANCS 2014\n",
        "\n",
        "::: {.footer}\n",
        "Related Work\n",
        ":::\n",
        "\n",
        "::: {.notes}\n",
        "-  (Talk about how these are systems papers dealing with implementation details at a low level, and not strategy)\n",
        ":::\n",
        "\n",
        "## Related Work\n",
        "\n",
        "-  *\"VIP: a framework for joint dynamic forwarding and caching in named data networks\"*, Edmund M. Yeh, Tracey Ho, Ying Cui, Michael Burd, Ran Liu, Derek Leong, ACM ICN 2014\n",
        "-  (Talk about VIP in detail)\n",
        "\n",
        "## System Model\n",
        "\n",
        "-  (Give an overview and list assumptions)\n",
        "\n",
        "## System Model {.smaller .scrollable}\n",
        "\n",
        "| Notation | Definition |\n",
        "|:--:|:--------|\n",
        "|$\\mathcal{G}$|Directed graph representing the network topology|\n",
        "|$(\\mathcal{N},\\mathcal{L})$|Set of nodes and links in $\\mathcal{G}$|\n",
        "|$C_{ab}$|Transmission capacity (in objects/sec) of link $(a,b)$|\n",
        "|$\\mathcal{K}$|Set of data objects in the network|\n",
        "|$\\mc{S}(k)$|Content source node for $k \\in \\mathcal{K}$|\n",
        "|$\\mathcal{J}_n$ | Set of cache tiers at node $n \\in \\mathcal{N}$|\n",
        "|$L_{n_j}$ | Size (in objects) of cache tier $j \\in \\mathcal{J}_n$ at $n$|\n",
        "|$r_{n_j}$ | Read rate of tier $j$ at node $n$|\n",
        "|$c^a_{n_j}$| Admission cost of tier $j$ at node $n$|\n",
        "|$c^e_{n_j}$| Eviction cost of tier $j$ at node $n$|\n",
        "|$t$|Time slot referring to interval $[t, t+1)$|\n",
        "|$V^k_n(t)$|VIP count for $k$ at $n$ during $t$|\n",
        "|$A^k_n(t)$|Number of exogenous requests for $k$ at $n$ during $t$|\n",
        "|$\\lambda^k_n$|Exogenous VIP arrival rate for $k$ at $n$|\n",
        "|$\\mu^k_{ab}(t)$|Allocated rate of VIPs for $k$ over $(a,b)$ during $t$|\n",
        "|$s^k_{n_j}(t)$ | Caching state of $k$ in tier $j$ at $n$ at the beginning of $t$|\n",
        "|$p^k_{n_j}(t)$ | Penalty incurred by the choice of $s^k_{n_j}(t)$|\n",
        ": Table of Notations {tbl-colwidths=\"[20,80]\"}\n",
        "\n",
        "::: {.footer}\n",
        "Contributions\n",
        ":::\n",
        "\n",
        "## Queue Dynamics\n",
        "The VIP queue evolution for object $k$ at node $n$ can be described with the following, where $(x)^+ = max(x,0)$:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "    V^k_n(t+1) \\leq & \\Bigg(\\Big(V^k_n(t) - \\sum\\limits_{b \\in \\mathcal{N}}\\mu^k_{nb}(t)\\Big)^+ + A^k_n(t) \\\\ \n",
        "    & + \\sum\\limits_{a \\in \\mathcal{N}}\\mu^k_{an}(t) - \\sum\\limits_{j \\in \\mathcal{J}_n} r_{n_j} s^k_{n_j}(t) \\Bigg)^+    \n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "## Virtual Plane Algorithm {.smaller}\n",
        "At the beginning of each time slot $t$, at each node $n$, observe queueues $(V^k_n(t))_{k \\in \\mathcal{K}, n \\in \\mathcal{N}}$ then perform caching and forwarding as follows:\n",
        "\n",
        "-  **Caching**: Choose $s^k_{n_j}(t)$ for each $\\kin$ and $j \\in \\mathcal{J}_n$ to:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{align}\n",
        "    \\text{maximize}\n",
        "        & \\quad \\sum\\limits_{\\kin} \\sum\\limits_{\\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - p^k_{n_j}(t) \\\\\n",
        "    \\text{subject to}\n",
        "        & \\quad \\sum\\limits_{\\kin} s^k_{n_j}(t) \\leq L_{n_j}, \\; \\jin \\\\\n",
        "        & \\quad \\sum\\limits_{\\jin} s^k_{n_j}(t) \\leq 1, \\; \\kin \\\\\n",
        "        & \\quad s^k_{n_j}(t) \\in \\{0, 1\\}, \\; \\kin, \\; \\jin\n",
        "\\end{align}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    p^k_{n_j}(t) \\triangleq \n",
        "    \\left\\{ \\begin{array}{ll}\n",
        "        c^a_{n_j}, & \\text{if} \\; s^k_{n_j}(t) - s^k_{n_j}(t-1) = 1 \\\\\n",
        "        c^e_{n_j}, & \\text{if} \\; s^k_{n_j}(t) - s^k_{n_j}(t-1) = -1 \\\\\n",
        "       0, & \\text{otherwise}\n",
        "   \\end{array} \\right.\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "## Virtual Plane Algorithm {.smaller}\n",
        "At the beginning of each time slot $t$, at each node $n$, observe queueues $(V^k_n(t))_{k \\in \\mathcal{K}, n \\in \\mathcal{N}}$ then perform caching and forwarding as follows:\n",
        "\n",
        "-  **Caching**: Choose $s^k_{n_j}(t)$ for each $\\kin$ and $j \\in \\mathcal{J}_n$ to:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{align}\n",
        "    \\text{maximize}\n",
        "        & \\quad \\sum\\limits_{\\kin} \\sum\\limits_{\\jin} b^k_{n_j}(t) s^k_{n_j}(t) \\\\\n",
        "    \\text{subject to}\n",
        "        & \\quad \\sum\\limits_{\\kin} s^k_{n_j}(t) \\leq L_{n_j}, \\; \\jin \\\\\n",
        "        & \\quad \\sum\\limits_{\\jin} s^k_{n_j}(t) \\leq 1, \\; \\kin \\\\\n",
        "        & \\quad s^k_{n_j}(t) \\in \\{0, 1\\}, \\; \\kin, \\; \\jin\n",
        "\\end{align}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    b^k_{n_j}(t) \\triangleq \\left\\{ \\begin{array}{ll}\n",
        "        r_{n_j} V^k_n(t) - \\omega c^a_{n_j}, & \\text{if} \\; s^k_{n_j}(t-1) = 0 \\\\\n",
        "        r_{n_j} V^k_n(t) + \\omega c^e_{n_j}, & \\text{if} \\; s^k_{n_j}(t-1) = 1\n",
        "    \\end{array} \\right.\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "## Virtual Plane Algorithm {.smaller}\n",
        "At the beginning of each time slot $t$, at each node $n$, observe queueues $(V^k_n(t))_{k \\in \\mathcal{K}, n \\in \\mathcal{N}}$ then perform caching and forwarding as follows:\n",
        "\n",
        "-  **Forwarding**: Let $\\mc{L}^k$ be the set of links which are allowed to transmit VIPs of object k, determined by a routing policy. For each $\\kin$ and $\\abin^k$, choose:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "   \\mu^k_{ab}(t) =\n",
        "   \\left\\{ \\begin{array}{ll}\n",
        "      C_{ba}, & \\text{if} \\; k = k^*_{ab}(t) \\; \\text{and} \\; W^k_{ab}(t) > 0 \\\\\n",
        "      0, & \\text{otherwise}\n",
        "   \\end{array} \\right.\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "   W^k_{ab}(t) & \\triangleq V^k_a(t) - V^k_b(t), \\\\\n",
        "   k^*_{ab}(t) & \\triangleq \\argmax\\limits_{\\{k: \\abin^k\\}} W^k_{ab}(t)\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "## Analysis {.smaller}\n",
        "\n",
        "| Notation | Definition |\n",
        "|:--:|:--------|\n",
        "|$f^k_{ab}$|Time-average VIP flow for $k$ over $(a,b)$|\n",
        "|$F^k_{ab}(t)$|Number of VIPs of $k$ sent over $(a,b)$ during slot $t$|\n",
        "\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "f^k_{ab} = \\sum^{t}_{\\tau=1} F^k_{ab}(\\tau)/t\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "$F^k_{ab}(t)$ satisfy the following for all $t \\geq 1$:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    F^k_{ab}(t) \\geq 0, F^k_{nn}(t) = 0, F^k_{\\mc{S}(k)n}(t) = 0, \\; \\forall a,b,n \\in \\mc{N}, \\kin,\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    F^k_{ab}(t) = 0, \\; \\forall a,b \\in \\mc{N}, \\kin, (a,b) \\not \\in \\mc{L}^k\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    F^k_{ab}(t) \\leq C_{ba}, \\; \\forall \\abin\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "## Analysis {.smaller}\n",
        "\n",
        "| Notation | Definition |\n",
        "|:--:|:--------|\n",
        "|$\\mc{B}_{n,i}$|i-th among all $\\sigma$ cache placement sets at $n$|\n",
        "|$\\beta_{n,i}$|Fraction of time objects at $n$ are placed according to $\\mc{B}_{n,i}$|\n",
        "\n",
        "The elements of set $\\mc{B}_{n,i}$ are pairs in the form of $(k,j)$, such that if $(k,j) \\in \\mc{B}_{n,i}$, object $k$ is cached in tier $j$. $\\beta_{n,i}$ satisfy the following:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    0 \\leq \\beta_{n,i} \\leq 1, \\quad i = 1,\\cdots,\\sigma, \\quad \\nin\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    \\betasum = 1, \\quad \\forall \\nin\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Analysis\n",
        "\n",
        "**Stability Region**: The VIP stability region $\\Lambda$ of the network $\\mc{G} = (\\mc{N},\\mc{L})$, is the set $\\Lambda$ consisting of all VIP arrival rates $\\boldsymbol{\\lambda} = (\\lambda^k_n)_{\\kin,\\nin}$ such that the following holds:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "    \\lambda^k_n \\leq \\sum\\limits_{\\bin} f^k_{nb} & - \\sum\\limits_{\\ain} f^k_{an} + \\sum\\limits_{\\jin} r_{n_j} \\betasumind, \\\\\n",
        "    & \\forall \\nin, \\; \\kin, \\; n \\not = \\mc{S}(k)\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "When all exogenous request arrival rates abide by the bound described above, there is a feasible forwarding and caching policy in the virtual plane that can stabilize all VIP queues.\n",
        "\n",
        "## Analysis {.smaller}\n",
        "\n",
        "| Notation | Definition |\n",
        "|:--:|:--------|\n",
        "|$\\Psi(\\boldsymbol{\\lambda})$|(description pending)|\n",
        "|$N$|Number of nodes in the network, i.e. $N = |\\mc{N}|$|\n",
        "|$A^k_{n,max}$| Finite value such that $A^k_n(t) \\leq A^k_{n,max}$ for all $t$|\n",
        "|$A_{n,max}$| Maximum total exogenous arrivals at node $n$ during $t$ across all $\\kin$, i.e. $A_{n,max} \\triangleq \\sum_{\\kin}A^k_{n,max}$|\n",
        "|$\\mu^{out}_{n,max}$| Maximum total allocated transmission rate for VIPs across all $(n,b) \\in \\mc{L}$, i.e. $\\mu^{out}_{n,max} \\triangleq \\sum_{\\bin}C_{nb}$|\n",
        "|$\\mu^{in}_{n,max}$| Maximum total allocated transmission rate for VIPs across all $(a,n) \\in \\mc{L}$, i.e. $\\mu^{in}_{n,max} \\triangleq \\sum_{\\bin}C_{an}$|\n",
        "|$r_{n,max}$| Maximum total rate that can be served by all cache tiers at $n$, i.e. (pending)|\n",
        "\n",
        "## Analysis {.smaller}\n",
        "\n",
        "**VIP Backlog/Penalty Bounds**: Given VIP arrival rate vector $\\boldsymbol{\\lambda} = (\\lambda^k_n)_{\\kin,\\nin}$, if there exists $\\boldsymbol{\\epsilon} = (\\epsilon^k_n)_{\\nin, \\kin} \\succ \\mathbf{0}$ such that $\\boldsymbol{\\lambda} + \\boldsymbol{\\epsilon} \\in \\Lambda$, then the network of VIP queues under the proposed algorithm satisfies the following bounds:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    \\lim\\limits_{T \\rightarrow \\infty} \\frac{1}{T} \\sum\\limits^{T-1}_{t=0} \\sum\\limits_{\\nin, \\kin} \\mathbb{E}[V^k_n(t)] \\leq \\frac{NB}{\\epsilon} + \\frac{\\omega}{2\\epsilon} \\minpen\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    \\lim\\limits_{T \\rightarrow \\infty} \\frac{1}{T}\\sum\\limits^{T-1}_{t=0} \\mathbb{E}[p(t)] \\leq \\frac{2NB}{\\omega} + \\minpen\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    B \\triangleq \\frac{1}{2N} \\sum_{\\nin} \\bigg((\\mu^{out}_{n,max})^2 + 2(\\mu^{out}_{n,max})r_{n,max} + \\big(\\textstyle \\sum_{\\kin}A^k_{n,max} + \\mu^{in}_{n,max} + r_{n,max})^2 \\bigg)\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "**Interpretation**: We can pick a large $\\omega$ to push the time average penalty close to $\\Psi(\\boldsymbol{\\lambda})$ at the cost of significantly increasing the average queue backlog and vice-versa.\n",
        "\n",
        "## Transition to Data Plane\n",
        "\n",
        "There are several considerations when applying our approach in the data plane:\n",
        "\n",
        "-  Per-packet forwarding and caching decisions need to be made\n",
        "-  Assumption that we have immediate access to any object for caching purposes does not hold \n",
        "-  Algorithm can lead to oscillatory behavior for caching decisions\n",
        "\n",
        "## Data Plane Strategy {.smaller}\n",
        "\n",
        "| Notation | Definition |\n",
        "|:--:|:--------|\n",
        "|$\\mc{v}^k_{ab}$|Actual number of VIPs for $k$ transmitted over $(a,b)$ during $t$|\n",
        "|T|Size of a sliding window of time slots|\n",
        "|$\\mc{K}_{n_j}$|Set of objects currently cached in tier $j$ at $n$|\n",
        "\n",
        "Define the *cache score* metric as follows:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    CS^k_n(t) \\triangleq \\frac{1}{T} \\sum^t_{\\tau = t - T + 1} \\sum_{(a,n) \\in \\mc{L}^k} v^k_{an}(\\tau)\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "Define the *eviction target* for tier $j$ at node $n$ as follows:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "   k'_{n_j} = \\argmin_{\\{k \\in \\mc{K}_{n_j}\\}} CS^k_n(t)\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "## Data Plane Strategy {.smaller}\n",
        "\n",
        "Define the *cache benefit* metric as follows:\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    CB^k_{n_j}(t) = \\begin{cases}\n",
        "        \\begin{array}{l}\n",
        "             r_{n_j}(CS^k_n(t) - CS^{k'_{n_j}}_n(t)) - \\omega(c^a_{n_j} + c^e_{n_j}), \\text{if} \\, j \\, \\text{is full} \\\\\n",
        "             r_{n_j} CS^k_n(t) - \\omega c^a_{n_j}, \\; \\text{otherwise}\n",
        "        \\end{array}\n",
        "    \\end{cases} \n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "**Data Plane Caching**: When a data object $k \\not \\in \\mc{K}_{n_j}$ arrives at $n$ during slot $t$, caching policy at $n$ behaves as follows.\n",
        "\n",
        "-  Determine the cache tier which offers the highest cache benefit, i.e. $j^* = \\argmax_{\\{ \\jin \\}} CB^k_{n_j}(t)$\n",
        "-  If $CB^k_{n_{j^*}}(t) > 0$, admit object into tier $j^*$\n",
        "   -  If $j^*$ is full, i.e. $|\\mc{K}_{n_{j^*}}| = L_{n_{j^*}}$, $k$ replaces $k'_{n_{j^*}}$\n",
        "-  If a replacement happened in $j^* < |\\mc{J}_n|$, set $k = k'_{n_{j^*}}$, then start the process over\n",
        "\n",
        "## Data Plane Strategy\n",
        "\n",
        "**Data Plane Forwarding**: When a request for object $k \\not \\in \\mc{K}_{n_j}, \\; \\forall \\jin$, arrives at $n$, the request is forwarded to the following node.\n",
        "\n",
        "\n",
        "```{=tex}\n",
        "\\begin{equation}\n",
        "    b^k_n(t) = \\argmax_{\\{ b:(n,b) \\in \\mc{L}^k \\}} \\frac{1}{T} \\sum\\limits^t_{t'=t-T+1} v^k_{nb}(t)\n",
        "\\end{equation}\n",
        "```\n",
        "\n",
        "\n",
        "## Simulation Setup\n",
        "\n",
        "-  Object-level simulation environment built with Python using the SimPy library\n",
        "-  Modular, object-oriented design to allow future extension\n",
        "-  Multi-threading allowing for thread-per-experiment execution\n",
        "-  Experiment parameters and output in JSON format for easy parsing\n",
        "\n",
        "## Simulation Setup {.smaller}\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "### Node\n"
      ],
      "id": "c302eaa8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "class Node(object):\n",
        "    def __init__(self, env, node_id):\n",
        "\n",
        "    def addOutputLink(self, remote_id, link, ctrl_link):\n",
        "\n",
        "    def addInputLink(self, remote_id, link, ctrl_link):\n",
        "\n",
        "    def addPermastore(self, permastore):\n",
        "\n",
        "    def addCache(self, cache):\n",
        "    \n",
        "    def addFIB(self, fib, dist_diff=None):\n",
        "\n",
        "    def packetReceiver(self, remote_id):\n",
        "\n",
        "    def packetProcessor(self):\n",
        "\n",
        "    def receiveInterest(self, remote_id, request):\n",
        "\n",
        "    def respondWithLocal(self, request, object_location):\n",
        "\n",
        "    def receiveData(self, request):\n",
        "\n",
        "    def sendInterestPacket(self, remote_id, request):\n",
        "    \n",
        "    def sendDataPacket(self, remote_id, request):\n",
        "\n",
        "    def requestGenerator(self, intervals, object_ids):\n",
        "\n",
        "    def locateObject(self, object_id):\n",
        "\n",
        "    def forwardInterest(self, request):\n",
        "\n",
        "    def decideCaching(self, object_id):\n",
        "\n",
        "    def updateStats(self):\n",
        "    \n",
        "    def getStats(self):"
      ],
      "id": "ab3c2238",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cache\n",
        "\n",
        "::: {.incremental}\n",
        "-  A\n",
        "-  B\n",
        "-  C\n",
        ":::\n",
        "\n",
        "### Link\n",
        "\n",
        "Content for \n",
        "\n",
        ":::\n",
        "\n",
        "## Experiment Setting I\n",
        "\n",
        "## Results I {.smaller}\n",
        "Total delay, as fraction of total delay without any caching\n",
        "\n",
        "![](images/tops_delay_v3.svg){width=75% height=75% fig-align=\"center\"}\n",
        "\n",
        "Cache hits, percentage of hits in the first tier on the left, total number of hits on the right\n",
        "\n",
        "![](images/tops_hits_v3.svg){width=75% height=75% fig-align=\"center\"}\n",
        "\n",
        "## Experiment Setting II\n",
        "\n",
        "## Results II\n",
        "\n",
        "## Results {.smaller}\n",
        "Delay vs. penalty\n",
        "\n",
        "::: columns\n",
        "::: {.column width=\"33%\"}\n",
        "![](images/pen_vs_delay_abilene_v2.svg)\n",
        ":::\n",
        "::: {.column width=\"33%\"}\n",
        "![](images/pen_vs_delay_grid_v2.svg)\n",
        ":::\n",
        "::: {.column width=\"33%\"}\n",
        "![](images/pen_vs_delay_regular_v2.svg)\n",
        ":::\n",
        ":::\n",
        "\n",
        "## Room for Improvement\n",
        "\n",
        "## Proposed Work"
      ],
      "id": "fd46754a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}