## Overview

- We seek an algorithm that can:
    - Guarantee stability of all VIP queues.
    - Maintain total VIP queue backlog small.
    - Keep cache-related costs minimal.
- What does this accomplish for the data plane policy?

::: {.footer}
Optimization Framework
:::

## Theorem: Stability Region

VIP [stability region]{.body-highlight} $\Lambda$ consists of all arrival rates $\boldsymbol{\lambda} = (\lambda^k_n)_{\kin,\nin}$ such that:

::: {style="font-size: 80%;"}
```{=tex}
\begin{equation*}
    \lambda^k_n \leq \sum\limits_{\bin} f^k_{nb} - \sum\limits_{\ain} f^k_{an} +  \betasum \sum\limits_{\jin} r_{n_j}
\end{equation*}
```
:::
<hr>

::: {style="font-size: 70%; text-align: center"}
$f^k_{ab}$: Time-average actual VIP flow for $k$ over $(a,b)$
:::

::: columns
::: {.column width="50%" style="font-size: 70%;"}
$\mc{B}_{n,i}$: i-th among all $\sigma_n$ possible cache placement sets at $n$; if $(k,j) \in \mc{B}_{n,i}$ during $t$, $s^k_{n_j}(t)$ = 1
:::
::: {.column width="50%" style="font-size: 70%;"}
$\beta_{n,i}$: Fraction of time objects at $n$ are placed according to $\mc{B}_{n,i}$; $0 \leq \beta_{n,i} \leq 1$ and $\sum^{\sigma_n}_{i=1} \beta_{n,i} = 1$
:::
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- The analysis of our approach comes in two steps. We're following the structure of Lyapunov drift-based analysis here, so we first define the stability region of the virtual plane network.
- The inequality on the screen essentially defines the boundary of that stability region, relating the arrival rates that can be satisfied to the long term average VIP flow over links, as well as VIPs removed via cache tiers.
:::

## Virtual Plane Penalties

Data plane costs reflected into virtual plane framework; admissions and evictions in virtual plane incur [penalties]{.body-highlight}:

::: {style="font-size: 75%;"}
```{=tex}
\begin{equation*}
    p^k_{n_j}(t) \triangleq 
    \left\{ \begin{array}{ll}
        c^a_{n_j}, & \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = 1 \\
        c^e_{n_j}, & \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = -1 \\
       0, & \text{otherwise}
   \end{array} \right.
\end{equation*}
```
Sum penalty during $t$: $P(t) = \sum_{\kin, \nin, \jin} p^k_{n_j}(t)$
:::

<hr>

::: columns
::: {.column width="50%" style="font-size: 75%;"}
$s^k_{n_j}(t)$: Caching state of $k$ in tier $j$ at $n$ at the beginning of $t$
:::
::: {.column width="50%" style="font-size: 75%;"}
$c^a_{n_j}$: Admission cost of tier $j$ at node $n$
$c^e_{n_j}$: Eviction cost of tier $j$ at node $n$
:::
:::



::: {.footer}
Optimization Framework
:::

::: {.notes}
- The multi-tiered caching model that I propose, which incorporates cache utilization costs, extends the virtual plane model.
- Each cache admission and eviction in virtual plane incurs a penalty, and a configurable weight parameter, $\omega$, lets the network determine the importance of penalties in its overall objective
- This definition shows how caching actions translate to penalties incurred
- (Fragment in) We'll also be concerned with the sum penalty across the network
:::

## Optimization Goal

Minimize upper bound of [drift-plus-penalty]{.body-highlight}[^dpp] expression:
```{=tex}
\begin{equation*}
    \drift + \omega \pen
\end{equation*}
```
where $\omega \geq 0$ is the [penalty importance weight]{.body-highlight} and
```{=tex}
\begin{equation*}
    \drift \triangleq \mathbb{E}[\mathcal{L}(\mathbf{V}(t+1))-\mc{L}(\mathbf{V}(t))|\mathbf{V}(t)]
\end{equation*}
```
```{=tex}
\begin{equation*}
    \mc{L}(\mathbf{V}(t)) \frac{1}{2} \triangleq \sum\limits_{\nin, \kin} (V^k_n(t))^2
\end{equation*}
```

[^dpp]: "Energy optimal control for time-varying wireless networks.", M. J. Neely, IEEE Trans. Inf. Theory, 2006.

::: {.footer}
Optimization Framework
:::

::: {.notes}
- The goal of our optimization in the virtual plane, is to operate as close as possible to the boundary of the stability region of the network of VIP queues, which we will define formally in a bit, while keeping penalties accumulated small.
- (Fragment in) In particular, we're trying to minimize the upper bound on this drift-plus-penalty expression you see on screen, which is based on an extension to Lyapunov optimization devised by Neely.
- So in this way, we're not necessarily trying to make a precisely optimal decision each time slot, but trying to minimize the expected value of an upper bound.
:::

## Virtual Plane Algorithm

- Placeholder.

::: {.footer}
Optimization Framework
:::

::: {.notes}
- And here's how we tackle this optimization. We devise an algorithm that's made of two steps (caching and forwarding), which chooses the respective variables every time slot, to optimize a certain objective based on the VIP counts. We're looking at the caching step right now.
- Obviously there is a lot of math to get to this expression for the objective function, but I'll give you the intuition briefly.
- Because we want to remove as many VIPs from the network as fast as possible, we want to cache the higher VIP count objects in the faster tiers, which is why the read rate multiplies the VIP count here.
- However, we also want to make sure that our choices in caching actions do not add large penalties that outweigh the benefits. Of course the importance of that is determined by omega.
- And of course we have the cache tier capacity constraints and the cache exclusivity constraints
:::

## Virtual Plane Algorithm
Perform [caching]{.body-highlight} by choosing $s^k_{n_j}(t)$ for each $\kin$ and $j \in \mathcal{J}_n$ to:

::: {style="font-size: 80%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum\limits_{\kin} \sum\limits_{\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - \omega p^k_{n_j}(t) \\
    \text{subject to}
        & \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        & \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        & \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align*}
```
:::

## Lemma: Caching Solution

::: {style="font-size: 85%;"}
We can rewrite [caching]{.body-highlight} step optimization problem as *multiple knapsack problem*.
:::

::: {style="font-size: 75%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum\limits_{\kin} \sum\limits_{\jin} b^k_{n_j}(t) s^k_{n_j}(t) \\
    \text{subject to}
        & \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        & \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        & \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align*}
```
```{=tex}
\begin{equation*}
    b^k_{n_j}(t) \triangleq \left\{ \begin{array}{ll}
        r_{n_j} V^k_n(t) - \omega c^a_{n_j}, & \text{if} \; s^k_{n_j}(t-1) = 0 \\
        r_{n_j} V^k_n(t) + \omega c^e_{n_j}, & \text{if} \; s^k_{n_j}(t-1) = 1
    \end{array} \right.
\end{equation*}
```
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- Now of course, the validity of our approach hinges on whether we can solve the optimization problem from the caching step.
- To do so, we will first rewrite it to clean up this unpleasant form we've shown before. And to do that, we will use a two-step transformation of variables.
- The first step here is defining an auxiliary "benefit" term and using that to simplify the objective function.
- You'll notice that the problem now looks to be in the form of a generalized assignment problem.
:::

## Lemma: Caching Solution

::: {style="font-size: 80%;"}
Use equal object sizes, decide variables for each one-object [cache slot]{.body-highlight}; obtain equivalent [linear assignment problem]{.body-highlight}.
:::

![](images/transform.svg){width="75%" height="75%" fig-align="center"}

::: {.footer}
Optimization Framework
:::

::: {.notes}
- Placeholder.
:::

## Lemma: Caching Solution

::: {style="font-size: 80%;"}
Use equal object sizes, decide variables for each one-object [cache slot]{.body-highlight}; obtain equivalent [linear assignment problem]{.body-highlight}.
:::

::: {style="font-size: 70%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum\limits_{\kin} \sum\limits_{\iin} b^k_{n_i}(t) s^k_{n_i}(t) \\
    \text{subject to} 
        & \quad \sum\limits_{\kin} s^k_{n_i}(t) \leq 1, \; \forall \, \iin \\
        & \quad \sum\limits_{\iin} s^k_{n_i}(t) \leq 1, \; \forall \, \kin \\
        & \quad s^k_{n_i}(t) \in \{0, 1\}, \; \forall \, \kin, \; \iin
\end{align*}
```
:::

::: {style="font-size: 60%; text-align: center"}
```{=tex}
\begin{equation*}
\mc{I}_n \triangleq \{1, 2, ..., \sum_{\jin} L_{n_j}\}, \; \mc{I}_{n_j} \triangleq \{1 + \sum^{j - 1}_{\ell = 1} L_{n_\ell}, ..., \sum^{j}_{\ell = 1} L_{n_\ell}\}
\end{equation*}
\\
```
If $i \in \mc{I}_{n_j}$, then $b^k_{n_i}(t) = b^k_{n_j}(t)$ and $s^k_{n_i}(t) = s^k_{n_j}(t)$.
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- Now recall the assumption we made in our model that every data object has the same size.
- Using that assumption, we can think of each cache tier as made up of several "cache slots" that can each take one object. The number of these per tier depend on the total capacity of that tier. These slots have the same read rate and cost parameters as the tier they belong in.
- Now, also recall the cache exclusivity constraint of the original problem. We can easily see that exclusivity across tiers directly translates to exclusivity across these cache slots.
- Using these facts we can rewrite the problem again, this time in the form of a linear assignment problem.
- Luckily, there are methods that can solve this problem in polynomial time. We specifically rely on a modification of the Jonker-Volgenant algorithm.
:::

## Caching Solution

::: {style="font-size: 80%;"}
Use equal object sizes, decide variables for each one-object [cache slot]{.body-highlight}; obtain equivalent [linear assignment problem]{.body-highlight}.

- Variety of polynomial time algorithms exist; mostly variants of the Hungarian method.
- We use one such variant[^crouse2d] with worst case complexity of $O(L^2_{tot}K)$, where $L_{tot} = \sum_{\jin} L_{n_j}$.
:::

[^crouse2d]: "On implementing 2D rectangular assignment algorithms", Crouse, D. F., IEEE Transactions on Aerospace and Electronic Systems 2016

::: {.footer}
Optimization Framework
:::

## Virtual Plane Algorithm
Perform [forwarding]{.body-highlight} by choosing $\mu^k_{ab}(t)$ for each $\kin$ and $\abin^k$ to:

::: {style="font-size: 80%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum\limits_{\kin} \sum\limits_{\bin} \mu^k_{nb}(t) (V\knt - V^k_b(t)) \\
    \text{subject to}
        & \quad \sum\limits_{\kin} \mu^k_{nb}(t) \leq C_{bn}, \; \forall \; (n,b) \in \mc{L} \\
        & \quad \mu^k_{nb}(t) \geq 0, \; \forall \; (n,b) \in \mc{L}, \; \forall \; \kin \\
        & \quad \mu^k_{nb}(t) = 0, \; \forall \; (n,b) \not \in \mc{L}^k, \; \forall \; \kin
\end{align*}
```
:::
<hr>

::: columns
::: {.column width="50%" style="font-size: 75%;"}
$C_{ab}$: Capacity of link $(a,b)$
:::
::: {.column width="50%" style="font-size: 75%;"}
$\mc{L}^k$: Set of links allowed to transmit VIPs of $k$, determined by routing policy
:::
:::

::: {.footer}
Optimization Framework
:::

## Virtual Plane Forwarding
Optimal solution to forwarding problem is obtained by choosing $\mu^k_{ab}(t)$ as follows.

::: {style="font-size: 70%;"}
```{=tex}
\begin{equation*}
   \mu^k_{ab}(t) =
   \left\{ \begin{array}{ll}
      C_{ba}, & \text{if} \; k = k^*_{ab}(t) \; \text{and} \; W^k_{ab}(t) > 0 \\
      0, & \text{otherwise}
   \end{array} \right.
\end{equation*}
```
```{=tex}
\begin{equation*}
\begin{split}
   W^k_{ab}(t) & \triangleq V^k_a(t) - V^k_b(t), \\
   k^*_{ab}(t) & \triangleq \argmax\limits_{\{k: \abin^k\}} W^k_{ab}(t)
\end{split}
\end{equation*}
```
:::

This is the well-known *backpressure* solution, used in[^vipog].

[^vipog]: "VIP: A framework for joint dynamic forwarding and caching in named data networks", Yeh, E., Ho, T., Cui, Y., Burd, M., Liu, R., & Leong, D., ACM ICN 2014

::: {.footer}
Optimization Framework
:::

::: {.notes}
- And here's the forwarding step. The neat thing about our extension here is that we don't actually need to alter the results for forwarding from the original VIP paper, which were based on the backpressure technique.
- The intuition here again comes from thinking of VIP counts as potential representing unsatisfied demand. So with the forwarding step, we're making sure VIP flows follow large differences in potential, essentially steering interests toward sinks, meaning sources or caches.
:::

## Theorem: Trade-off {.smaller}

For arrival rate vector $\boldsymbol{\lambda}$, if there exists $\boldsymbol{\epsilon}$ such that $\boldsymbol{\lambda} + \boldsymbol{\epsilon} \in \Lambda$, then the proposed algorithm achieves the following:

::: {style="font-size: 90%;"}
```{=tex}
\begin{equation*}
    \lim\limits_{T \rightarrow \infty} \frac{1}{T} \sum\limits^{T}_{t=1} \sum\limits_{\nin, \kin} \mathbb{E}[V^k_n(t)] \leq \frac{B}{\epsilon} + \omega \frac{\bar{P}(\boldsymbol{\lambda})}{\epsilon}
\end{equation*}*
```
```{=tex}
\begin{equation*}
    \lim\limits_{T \rightarrow \infty} \frac{1}{T}\sum\limits^{T-1}_{t=0} \mathbb{E}[P(t)] \leq \frac{B}{\omega} + \bar{P}(\boldsymbol{\lambda})
\end{equation*}
```
:::

<hr>

::: {style="font-size: 85%; text-align: center"}
```{=tex}
\begin{equation*}
    B = \sum_{\nin} \bigg( \sum_{\kin}A^k_{n,max} + \sum_{\ain}C_{an} + \sum_{\bin}C_{nb} + \sum_{\jin} L_{n_j} r_{n_j} \bigg)^2
\end{equation*}
```
```{=tex}
\begin{equation*}
\epsilon = \textstyle \min_{\nin,\kin} \epsilon^k_n
\end{equation*}
```

$\bar{P}(\boldsymbol{\lambda})$: Minimum expected time-average sum penalty achievable by feasible stabilizing policy.
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- The second step of our analysis is what actually shows the guarantees that our algorithm can provide. Here, we use the definition of the stability region, which is why we needed the previous step.
- These two expressions define the upper bounds for time average VIP queue sizes and accumulated penalty in the virtual plane network.
- The essential observation here is the trade-off between the bounds. As you can see, the omega value controls which bound we wish to prioritize, because setting it small means lower average queue sizes which translates to better performance, but at the cost of potentially much larger penalties. Setting it large is the inverse of that situation.
:::