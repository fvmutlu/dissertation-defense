## Optimization Overview {.smaller}

::: {style="font-size:110%"}
**Goals:** Guarantee stability of all VIP queues, maintain total VIP queue backlog small, *keep cache utilization costs minimal*.
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- In the virtual plane, we're interested in stabilizing the VIP queues, maintain their backlogs small and keep caching related penalties to a minimum.
:::

## Optimization Overview {.smaller visibility="uncounted"}

::: {style="font-size:110%"}
**Goals:** Guarantee stability of all VIP queues, maintain total VIP queue backlog small, *keep cache utilization costs minimal*.

**Approach:** Minimize upper bound of [drift-plus-penalty]{.body-highlight}[^dpp] expression:
```{=tex}
\begin{equation*}
    \drift + \omega \pen
\end{equation*}
```
where $\omega \geq 0$ is the [penalty importance weight]{.body-highlight} and
```{=tex}
\begin{equation*}
    \drift \triangleq \mathbb{E}[\mathcal{L}(\mathbf{V}(t+1))-\mc{L}(\mathbf{V}(t))|\mathbf{V}(t)]
\end{equation*}
```
```{=tex}
\begin{equation*}
    \mc{L}(\mathbf{V}(t)) \triangleq \frac{1}{2} \sum\limits_{\nin, \kin} (V^k_n(t))^2
\end{equation*}
```
:::

[^dpp]: "Stochastic network optimization with application to communication and queueing systems.", M. J. Neely, Springer Nature, 2022 @neely2022stochastic.

::: {.footer}
Optimization Framework
:::

::: {.notes}
- The way we tackle this is to minimize the bound on what's called the drift-plus-penalty expression.
- Here the drift represents the expected growth of queue backlogs, and it is combined with a penalty term that's weighed by what we call the penalty importance weight.
- So this is an altered objective compared to the original VIP work where only the drift is targeted.
:::

## Optimization Overview {.smaller visibility="uncounted"}

::: {style="font-size:110%"}
**Goals:** Guarantee stability of all VIP queues, maintain total VIP queue backlog small, *keep cache utilization costs minimal*.

**Approach:** Minimize upper bound of [drift-plus-penalty]{.body-highlight}[^dpp] expression.

Distributed algorithm performed at the beginning of each slot:

- Observes local and neighbor VIP queue states.
- Chooses cache placement variables.
- Chooses forwarding rate allocations.
- Updates queue states.
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- We conduct this minimization via a distributed algorithm which is operated separately at each node.
- As we stated before, the algorithm first requires exchanging VIP queue states with neighboring nodes.
- Then it will solve for the cache placement and forwarding rate allocations via two subproblems.
- Using these allocations it will remove and forward VIPs, then update queue states.
:::

## Virtual Plane Caching

::: {style="font-size: 100%;"}
[Caching.]{.body-highlight} Choose $s^k_{n_j}(t)$ for each $\kin$ and $j \in \mathcal{J}_n$ to:
:::

::: {style="font-size: 75%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum\limits_{\kin} \sum\limits_{\jin} b^k_{n_j}(t) s^k_{n_j}(t) \\
    \text{subject to}
        & \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        & \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        & \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align*}
```
```{=tex}
\begin{equation*}
    b^k_{n_j}(t) \triangleq \left\{ \begin{array}{ll}
        r_{n_j} V^k_n(t) - \omega c^a_{n_j}, & \text{if} \; s^k_{n_j}(t-1) = 0 \\
        r_{n_j} V^k_n(t) + \omega c^e_{n_j}, & \text{if} \; s^k_{n_j}(t-1) = 1
    \end{array} \right.
\end{equation*}
```
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- So, in view of the multi-tier model we're proposing, the caching step for the algorithm comes in the form of this multiple knapsack problem.
- In general, such a problem is known to be NP-hard, but we actually have a special case of the problem.
:::

## Virtual Plane Caching

::: {style="font-size: 80%;"}
Objects are equally sized; decide variables for each one-object [cache slot]{.body-highlight}, obtain equivalent [linear assignment problem]{.body-highlight}.
:::

![](images/transform.svg){width="75%" height="75%" fig-align="center"}

::: {.footer}
Optimization Framework
:::

::: {.notes}
- Because each data object in our model is of the same unit size, we can think of each cache tier as made up of several "cache slots" that can each take one object.
- Using this, we can construct an equivalent problem that's in the form of a linear assignment.
:::

## Virtual Plane Caching {visibility="uncounted"}

::: {style="font-size: 80%;"}
Objects are equally sized; decide variables for each one-object [cache slot]{.body-highlight}, obtain equivalent [linear assignment problem]{.body-highlight}.
:::

::: {style="font-size: 70%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum\limits_{\kin} \sum\limits_{\iin} b^k_{n_i}(t) s^k_{n_i}(t) \\
    \text{subject to} 
        & \quad \sum\limits_{\kin} s^k_{n_i}(t) \leq 1, \; \forall \, \iin \\
        & \quad \sum\limits_{\iin} s^k_{n_i}(t) \leq 1, \; \forall \, \kin \\
        & \quad s^k_{n_i}(t) \in \{0, 1\}, \; \forall \, \kin, \; \iin
\end{align*}
```
:::

::: {style="font-size: 60%; text-align: center"}
```{=tex}
\begin{equation*}
\mc{I}_n \triangleq \{1, 2, ..., \sum_{\jin} L_{n_j}\}, \; \mc{I}_{n_j} \triangleq \{1 + \sum^{j - 1}_{\ell = 1} L_{n_\ell}, ..., \sum^{j}_{\ell = 1} L_{n_\ell}\}
\end{equation*}
\\
```
If $i \in \mc{I}_{n_j}$, then $b^k_{n_i}(t) = b^k_{n_j}(t)$ and $s^k_{n_i}(t) = s^k_{n_j}(t)$.
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- Here, each cache slot inherits the benefit values from its corresponding tier and the constraints of linear assignment naturally translate to cache capacity and exclusivity constraints.
- Therefore, we're able to construct a solution to our original problem by solving this simpler problem instead.
:::

## Virtual Plane Caching {.smaller visibility="uncounted"}

::: {style="font-size: 120%;"}
Objects are equally sized; decide variables for each one-object [cache slot]{.body-highlight}, obtain equivalent [linear assignment problem]{.body-highlight}.

- Can be solved exactly in polynomial time with worst case complexity of $O(L^2_{tot}K)$[^crouse2d], where $L_{tot} = \sum_{\jin} L_{n_j}$.
:::

::: {layout="[[1,1]]"}
![Scaling in cache capacity](images/vip_caching_comp_time_wrt_cache.svg){width=350 fig-align="center"}

![Scaling in catalog size](images/vip_caching_comp_time_wrt_objects.svg){width=350 fig-align="center"}
:::

[^crouse2d]: "On implementing 2D rectangular assignment algorithms", Crouse, D. F., IEEE Transactions on Aerospace and Electronic Systems, 2016 @crouse2016implementing.

::: {.footer}
Optimization Framework
:::

::: {.notes}
- There are many efficient algorithms that can solve the linear assignment.
- We're using one such method widely available in software implementations, with a complexity that scales quadratically with cache capacity and linearly with catalog size.
- This is a favorable characteristic that we've observed in experimentation as well and it leads to reasonable computation times.
:::

## Virtual Plane Forwarding {.smaller}

[Forwarding.]{.body-highlight} Choose $\mu^k_{ab}(t)$ for each $\kin$ and $\abin^k$ to:

::: {style="font-size: 80%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum\limits_{\kin} \sum\limits_{\bin} \mu^k_{nb}(t) (V\knt - V^k_b(t)) \\
    \text{subject to}
        & \quad \sum\limits_{\kin} \mu^k_{nb}(t) \leq C_{bn}, \; \forall \; (n,b) \in \mc{L} \\
        & \quad \mu^k_{nb}(t) \geq 0, \; \forall \; (n,b) \in \mc{L}, \; \forall \; \kin \\
        & \quad \mu^k_{nb}(t) = 0, \; \forall \; (n,b) \not \in \mc{L}^k, \; \forall \; \kin
\end{align*}
```
:::

Optimal solution via ***backpressure***, i.e. choosing $\mu^k_{ab}(t)$ as follows.

::: {style="font-size: 75%;"}
```{=tex}
\begin{equation*}
   \mu^k_{ab}(t) =
   \left\{ \begin{array}{ll}
      C_{ba}, & \text{if} \; k = k^*_{ab}(t) \; \text{and} \; V^k_a(t) > V^k_b(t) \\
      0, & \text{otherwise}
   \end{array} \right.
\end{equation*}
```
```{=tex}
\begin{equation*}
   k^*_{ab}(t) \triangleq \argmax\limits_{k: \abin^k} \left(V^k_a(t) - V^k_b(t)\right)
\end{equation*}
```
:::

<hr>

::: {style="font-size: 75%;"}

::: columns
::: {.column width="30%"}
$C_{ab}$: Capacity of link $(a,b)$.
:::
::: {.column width="70%"}
$\mc{L}^k$: Set of links allowed to transmit VIPs of $k$ as per routing policy.
:::
:::

:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- The forwarding step is resolved by using the well-known backpressure solution as was done in the original VIP work.
:::

## Stability Region

VIP [stability region]{.body-highlight} $\Lambda$ consists of all arrival rates $\boldsymbol{\lambda} = (\lambda^k_n)_{\kin,\nin}$ such that:

::: {style="font-size: 80%;"}
```{=tex}
\begin{equation*}
    \lambda^k_n \leq \sum\limits_{\bin} f^k_{nb} - \sum\limits_{\ain} f^k_{an} +  \betasum \sum\limits_{\jin} r_{n_j} \multind
\end{equation*}
```
:::
<hr>

::: {style="font-size: 70%; text-align: center"}
$f^k_{ab}$: Time-average actual VIP flow for $k$ over $(a,b)$
:::

::: columns
::: {.column width="50%" style="font-size: 70%;"}
$\mc{B}_{n,i}$: i-th among all $\sigma_n$ possible cache placement sets at $n$; if $(k,j) \in \mc{B}_{n,i}$ during $t$, $s^k_{n_j}(t)$ = 1.
:::
::: {.column width="50%" style="font-size: 70%;"}
$\beta_{n,i}$: Fraction of time objects at $n$ are placed according to $\mc{B}_{n,i}$; $0 \leq \beta_{n,i} \leq 1$ and $\sum^{\sigma_n}_{i=1} \beta_{n,i} = 1$.
:::
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- So using this algorithm, we can ensure the stability of the VIP queues as long as the request arrivals are contained in what's called the stability region, bounds of which are depicted here.
:::

## Bound Trade-off {.smaller}

::: {style="font-size: 100%;"}
[Backlog-penalty trade-off]{.body-highlight} for arrival rate vector $\boldsymbol{\lambda} + \boldsymbol{\epsilon} \in \Lambda$, with $\boldsymbol{\epsilon} > \boldsymbol{0}$:
:::

::: {style="font-size: 90%;"}
```{=tex}
\begin{equation*}
    \lim\limits_{t \rightarrow \infty} \frac{1}{t} \sum\limits^{t}_{\tau=1} \sum\limits_{\nin, \kin} \mathbb{E}[V^k_n(\tau)] \leq \frac{B}{\epsilon} + \omega \frac{\bar{P}(\boldsymbol{\lambda})}{\epsilon}
\end{equation*}
```
```{=tex}
\begin{equation*}
    \lim\limits_{t \rightarrow \infty} \frac{1}{t}\sum\limits^{t}_{\tau=1} \mathbb{E}[P(\tau)] \leq \frac{B}{\omega} + \bar{P}(\boldsymbol{\lambda})
\end{equation*}
```
:::

<hr>

::: {style="font-size: 85%; text-align: center"}
```{=tex}
\begin{equation*}
    B = \sum_{\nin} \bigg( \sum_{\kin}A^k_{n,max} + \sum_{\ain}C_{an} + \sum_{\bin}C_{nb} + \sum_{\jin} L_{n_j} r_{n_j} \bigg)^2
\end{equation*}
```
```{=tex}
\begin{equation*}
\epsilon = \textstyle \min_{\nin,\kin} \epsilon^k_n
\end{equation*}
```

$\bar{P}(\boldsymbol{\lambda})$: Minimum expected time-average sum penalty achievable by a feasible stabilizing policy.
:::

::: {.footer}
Optimization Framework
:::

::: {.notes}
- Furthermore, given arrivals within that stability region, we're able to achieve an optimal trade-off between the time average upper bounds for VIP backlogs and accumulated penalty in the virtual plane network.
- The trade-off factor is based on the importance weight mentioned before.
- If that weight is small, that means lower average queue sizes which translates to better performance, but at the cost of potentially much larger penalties. Setting it large is the inverse of that.
:::