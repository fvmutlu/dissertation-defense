## Overview

- **Premise:** Initial model assumes cache read rate is constant across objects in virtual plane each slot.

::: {style="font-size: 70%;"}
```{=tex}
\begin{equation*}
    \color{#808080}{V^k_n(t+1) \leq \Big(V^k_n(t) - \sum_{\jin}} \color{#C8102E}{\boldsymbol{r_{n_j}}} \color{#808080}{s\knjt - \sum\limits_{\bin}\mu^k_{nb}(t)  \Big)^+ + A^k_n(t) + \sum\limits_{\ain}\mu^k_{an}(t)}    
\end{equation*}
```
:::

- **Hypothesis:** We can control read rate allocations in the virtual plane for better performance.

::: {style="font-size: 70%;"}
```{=tex}
\begin{equation*}
    \color{#808080}{V^k_n(t+1) \leq \Big(V^k_n(t) - \sum_{\jin}} \color{#C8102E}{\boldsymbol{r\knjt}} \color{#808080}{s\knjt - \sum\limits_{\bin}\mu^k_{nb}(t)  \Big)^+ + A^k_n(t) + \sum\limits_{\ain}\mu^k_{an}(t)}    
\end{equation*}
```
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

::: {.notes}
- The way we'll do that is by enforcing a cache read bandwidth constraint
- Additional control action each time slot, in product form with another control action
- Stability region and its analysis changes significantly
- Complexity of caching problem solution reduces
:::

## Overview

::: {style="font-size: 100%;"}
- **Reasoning:** Objects in cache receive different hit rates in the data plane.
- **Penalties:** We omit the weight of caching penalties to study read rate allocation in isolation.
- **Algorithm:** Should guarantee stability of all VIP queues, minimize total backlog.
    - Consider new control variables and [cache bandwidth constraints]{.body-highlight}, i.e. $\sum_{\kin} r\knjt \leq R_{n_j}$.
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::


## Theorem: Stability Region

[VIP stability region]{.body-highlight} $\Lambda$ under *cache bandwidth constraints* consists of all arrival rates $\boldsymbol{\lambda} = (\lambda^k_n)_{\kin,\nin}$ such that:

::: {style="font-size: 80%;"}
```{=tex}
\begin{equation*}
\lambda^k_n \; \leq \; \sum_{\bin} f^k_{nb} - \sum_{\ain} f^k_{an} + \betasum f^k_{n,i}
\end{equation*}
```
:::
<hr>

::: {style="font-size: 70%; text-align: center"}

:::

::: columns
::: {.column width="50%" style="font-size: 70%;"}
$f^k_{ab}$: Time-average VIP flow for $k$ over $(a,b)$.

$\mc{B}_{n,i}$: i-th among all $\sigma_n$ possible cache placement sets at $n$; if $(k,j) \in \mc{B}_{n,i}$ during $t$, $s^k_{n_j}(t)$ = 1.
:::
::: {.column width="50%" style="font-size: 70%;"}
$f^k_{n,i}$: Average VIPs of $k$ removed via caching under placement $\mc{B}_{n,i}$.

$\beta_{n,i}$: Fraction of time objects at $n$ are placed according to $\mc{B}_{n,i}$; $0 \leq \beta_{n,i} \leq 1$ and $\sum^{\sigma_n}_{i=1} \beta_{n,i} = 1$.
:::
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Virtual Plane Caching

Perform [caching]{.body-highlight} by choosing $r\knjt$ and $s\knjt$ for each $\kin$ and $j \in \mathcal{J}_n$ to:

::: {style="font-size: 75%;"}
```{=tex}
\begin{align*}
    \text{maximize}
        & \quad \sum_{\kin} \sum_{\jin} {\color{#C8102E}{r\knjt}} s\knjt V\knt \\
    \text{subject to} 
        & \quad \sum_{\kin} s\knjt \leq L_{n_j}, \; \forall \jin \\
        & \quad \sum_{\jin} s\knjt \leq 1, \; \forall \kin \\
        & \quad s\knjt \in \{0,1\}, \; \forall \kin, \, \jin \\
        & \quad \color{#C8102E}{\sum_{\kin} r\knjt \leq R_{n_j}, \; \forall \jin} 
\end{align*}
```
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

::: {.notes}
- Placeholder
:::

## Lemma: Caching Solution

::: {style="font-size: 80%;"}
Given $k_1, k_2, \cdots, k_{J_n}$ such that $V^{k_1}_n(t) \geq V^{k_2}_n(t) \geq ... \geq V^{k_{J_n}}_n(t)$, optimal solution to [revised caching problem]{.body-highlight} is obtained by *greedily* choosing $r\knjt$ and $s\knjt$ for each $\jin$ as follows.

```{=tex}
\begin{equation*}
    r\knjt =
    \left \{ \begin{array}{ll}
        R_{n_j}, & \text{if} \; k = k_j \; \text{and} \; V\knt > 0 \\
        0, & \text{otherwise}
    \end{array} \right.
\end{equation*}
```
```{=tex}
\begin{equation*}
    s\knjt =
    \left\{ \begin{array}{ll}
        1, & \text{if} \; k = k_j \; \text{and} \; V\knt > 0 \\
        0, & \text{otherwise}
    \end{array} \right.
\end{equation*}
```
:::

::: {style="font-size: 90%;"}
This is the *max-weight* solution.
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Theorem: Throughput Optimality

::: {style="font-size: 80%;"}
For arrival rate vector $\boldsymbol{\lambda} \in \textup{int}(\Lambda)$, algorithm achieves:

```{=tex}
\begin{equation*}
    \lim\limits_{t \rightarrow \infty} \frac{1}{t} \sum\limits^{t}_{\tau=1} \sum\limits_{\nin, \kin} \mathbb{E}[V^k_n(\tau)] \leq \frac{B}{\epsilon}
\end{equation*}
```

where

```{=tex}
\begin{equation*}
\epsilon = \min_{\nin,\kin} ((\epsilon^k_n)_{\nin,\kin})
\end{equation*}
```
```{=tex}
\begin{equation*}
    B = \sum_{\nin} \bigg( \sum_{\kin}A^k_{n,max} + \sum_{\ain}C_{an} + \sum_{\bin}C_{nb} + \sum_{\jin} R_{n_j} \bigg)^2
\end{equation*}
```
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Data Plane Application {.smaller}

When data for $k \not \in \bigcup_{\jin} \mc{K}_{n_j}(\tau)$ arrives at $n$ at instance $\tau \in [t,t+1)$, [data plane caching policy]{.body-highlight} at $n$ behaves as follows:

::: {style="font-size: 75%;"}
```pseudocode
#| html-line-number: true
\begin{algorithm}
\caption{Data Plane Caching w/ Virtual Plane Cache Read Rate Control}
\begin{algorithmic}
    \State Find cache tier $j^* = \argmax_{\jin} \bar{F}^k_{n_j}(t)$.
    \If{$\bar{F}^k_{n_{j^*}}(t) \geq \max_{ b:(n,b) \in \mc{L}^k } \bar{F}_{nb}^k(t)$}
        \If{$\bar{F}_{n,in}^k(t) > 0$ and $|\mc{K}_{n_{j^*}}(\tau)| < L_{n_{j^*}}$}
            \State Admit $k$ into $j^*$.
        \Else
            \State Find $k_{min} = \argmin_{k \in \mc{K}_{n_{j^*}}(\tau)} \bar{F}_{n,in}^k(t)$.
            \If{$\bar{F}_{n,in}^k(t) > \bar{F}_{n,in}^{k_{min}}(t)$}
                \State Replace $k_{min}$ with $k$, and restart procedure for $k_{min}$.
            \EndIf
        \EndIf
    \EndIf
\end{algorithmic}
\end{algorithm}
```
:::

::: columns
::: {.column width=50% style="font-size: 85%;"}
$F\knjt$: Actual amount of VIPs of $k$ removed in slot $t$ via caching, given tier $j$ read rate allocation $r\knjt$.
:::
::: {.column width=50% style="font-size: 85%;"}
$\bar{F}^k_{n_j}(t) \triangleq \frac{1}{T} \sum^t_{t'=t-T+1} F^k_{n_j}(t')$.
:::
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Policy Performance

::: {.incremental}
- This approach yields poor performance in the data plane.
    - [Significant underutilization]{.body-highlight-red} of slow tier.
- We attribute this outcome to ***queue underflows*** in the virtual plane.
    - Occur when allocated service exceeds backlog, e.g. $r\knjt > V\knt$.
    - Slow to gather actionable flow information for less popular objects.
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Iterative Approach

::: columns
::: {.column width=50%}
::: {style="font-size: 45%;"}
```pseudocode
#| html-line-number: true
#| html-caption-prefix: "Procedure:"
\begin{algorithm}
\caption{Virtual Plane Caching}
\begin{algorithmic}
    \State Find $k_1, k_2, ..., k_K$ with $V^{k_1}_n(t) \geq V^{k_2}_n(t) \geq ... V^{k_{K}}_n(t)$.
    \State Initialize $i \gets 1$.
    \While{$\sum_{\kin} s\knjt < L_{n_j}, \;\; \sum_{\kin} r\knjt < R_{n_j}, \; \exists \, \jin$ $\hspace{35pt}$ and $V^{k_i}_n(t) > 0$ and $i \leq K$}
        \State $j^* \gets \argmax\limits_{\jin : \sum\limits_{\kin} s\knjt < L_{n_j}} \left(R_{n_j} - \sum\limits_{\kin} s\knjt r\knjt \right) V^{k_i}_n(t)$.
        \State $s^{k_i}_{n_{j^*}}(t) \gets 1$, $r^{k_i}_{n_{j^*}}(t) \gets \min\left( \big(R_{n_j} - \sum_{\kin} s\knjt r\knjt \big), V^{k_i}_n(t)\right)$.
        \State $i \gets i+1$
    \EndWhile
\end{algorithmic}
\end{algorithm}
```
```pseudocode
#| html-line-number: true
#| html-caption-prefix: "Procedure:"
\begin{algorithm}
\caption{Virtual Plane Forwarding}
\begin{algorithmic}
    \State Initialize set $X_n \gets \{(b, k): \bin, \kin, (n,b) \in \mc{L}^k \}$
    \While{$\sum_{\kin} \mu^k_{nb}(t) < C_{bn}, \; \exists \, \nbin$ and $X_n \not = \varnothing$ \\ $\hspace{35pt}$ and $V^{k^*}_n(t) - V^{k^*}_{b^*}(t) > 0$}
        \State $(b^*,k^*) \gets \argmax_{(b,k) \in X_n} \left( V^k_n(t) - V^k_b(t) \right)$
        \State $\mu^{k^*}_{nb^*}(t) \gets \min \Big( \big( C_{bn} - \sum_{\kin} \mu^k_{nb}(t) \big),$ \\ $\big( V^{k^*}_n(t) - \sum_{\jin} s^{k^*}_{n_j}(t) r^{k^*}_{n_j}(t) - \sum_{\nbin^{k^*}} \mu^{k^*}_{nb}(t) \big) \Big)$
        \State $X_n \gets X_n \setminus \{ (b^*,k^*) \}$
    \EndWhile
\end{algorithmic}
\end{algorithm}
```
:::
:::
::: {.column width=50%}
::: {style="font-size: 65%;"}
We use an iterative greedy algorithm:

- First allocate cache space and read rate to highest backlog objects.
- Then allocate link bandwidth to largest backlog differential objects.
- Do not allocate more service than existing backlog.
- Terminate when either:
    - All cache capacity / bandwidth and all link bandwidth is allocated, or
    - All backlog is met by allocated service.
:::
:::
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Iterative Approach: Properties {.smaller}

- Under ***heavy congestion*** where $V\knt \geq \sum_{\nbin^k} C_{bn} + \max\limits_{\jin} R_{n_j}$, for all $t \geq 1, \nin, \kin$, reduces to earlier approach.
- Given backlog state $\mathbf{V}(t)$, following holds.
```{=tex}
\begin{equation*}
\begin{split}
    & \sum_{\kin,\jin} \hat{F}\knjt V\knt +
    \sum_{\nbin, \kin} \hat{F}^k_{nb}(t) \big(V^k_n(t) - V^k_b(t) \big) \\
    \geq & \sum_{\kin,\jin} F\knjt V\knt +
    \sum_{\nbin, \kin} F^k_{nb}(t) \big(V^k_n(t) - V^k_b(t) \big)
\end{split}
\end{equation*}
```
- Computational complexity remains the same, dominated by sorting.
    - $O(K \log K)$ for caching, $O(DK \log DK)$ for forwarding.

<hr>

::: {style="font-size: 80%;"}
$F\knjt$, $F^k_{nb}(t)$: Actual VIP flows under *max-weight* caching, *backpressure* forwarding.

$\hat{F}\knjt$, $\hat{F}^k_{nb}(t)$: Those under iterative algorithm.
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Experimental Results

::: columns
::: {.column width=50%}
::: {layout="[[-1],[1]]"}
![Sum of backlogs, Abilene topology, $\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150$.](images/sbw_comp_abilene_075_30_vip-pit-sums.png){width=85% height=85% fig-align="center"}
:::
:::
::: {.column width=50% style="font-size: 75%"}
- Data plane policy supported by initial approach: **MVIP-RR**; by iterative algorithm **MVIP-RR+**.
- Data plane backlog represented by PIT queue sizes.
    - Sampled along with VIPs at each virtual plane time slot.
    - Denote PIT samples as $Q\knt$.
- Iterative algorithm maintains much smaller total VIP backlog.
:::
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Experimental Results {visibility="uncounted"}

::: columns
::: {.column width=50%}
::: {layout="[[-1],[1]]"}
![Backlog gap, Abilene topology, $\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150$.](images/sbw_comp_abilene_075_30_vip-pit-norms.png){width="85%" height="85%"}
:::
:::
::: {.column width=50% style="font-size: 75%"}
- Data plane policy supported by initial approach: **MVIP-RR**; by iterative algorithm **MVIP-RR+**.
- Data plane backlog represented by PIT queue sizes.
    - Sampled along with VIPs at each virtual plane time slot.
    - Denote samples as $Q\knt$.
- Iterative algorithm maintains smaller virtual-data plane backlog *"gap"*.
    - Distance measure: $\frac{1}{|\mc{N}|} \sum_{\nin} \lVert \mathbf{V}_n(t) - \mathbf{Q}_n(t) \rVert_2$
:::
:::

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Experimental Results

::: {style="font-size: 75%"}
Data plane metrics show:

- Poor utilization of larger cache tier and resulting performance for **MVIP-RR**.
- Comparable delay performance along with great reduction in replacements for **MVIP-RR+**.
:::

<hr>

![Data plane metrics normalized to MVIP, Geant topology, $\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150$](images/sbw_comp_geant_075_30.png){width=90% height=90% fig-align="center"}

::: {.footer}
Virtual Plane Cache Read Rate Control
:::

## Experimental Results {visibility="uncounted"}

::: {style="font-size: 75%"}
Data plane metrics show:

- Poor utilization of larger cache tier and resulting performance for **MVIP-RR**.
- Improved delay performance along with great reduction in replacements for **MVIP-RR+**.
:::

<hr>

![Data plane metrics normalized to MVIP, Abilene topology, $\lambda=30, \gamma=0.75, L_{n_1}=7, L_{n_2}=150$](images/sbw_comp_abilene_075_30.png){width=90% height=90% fig-align="center"}

::: {.footer}
Virtual Plane Cache Read Rate Control
:::