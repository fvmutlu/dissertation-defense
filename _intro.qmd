## Motivation: Data-Intensive Science {.smaller}

::: columns
::: {.column width="50%"}
![](images/lhcopen_data.svg)
:::
::: {.column width="50%"}

- **Problem:** Distribution of massive data for data-intensive science experiments.
- **Solution:** N-DISE: high-performance NDN-based data delivery system.
- **Cache capacity issue:** 20 GB of DRAM space allocated at each node.
    - DRAM is fast but small and expensive; NVMe is cheap and large but slow.
    - Logical next step: use both!
    - **Challenge:** "Novel multi-tier caching algorithms are required."[^ndndpdk]
:::
:::

[^ndndpdk]: "NDN-DPDK: NDN forwarding at 100 Gbps on commodity hardware", Shi, J., Pesavento, D., & Benmohamed, L., ACM ICN 2020 @shi2020ndn.

::: {.footer}
Introduction
:::

## Challenges & Goals

::: {style="font-size: 90%;"}
We consider the following challenges:

- Slow caches can become a [bottleneck]{.body-highlight-red} if directed large traffic.
- Caches are not free to use; each operation has an [energy]{.body-highlight-red} cost, and flash [wears out]{.body-highlight-red}.

We aim for policies that utilize diverse cache tiers effectively:

-   Ensure caches are receiving [sustainable hit rates]{.body-highlight} and traffic is balanced between links and cache tiers.
-   Make [high-value]{.body-highlight} replacement decisions to minimize costs.
:::

::: {.footer}
Introduction
:::

## Related Work

::: {style="font-size: 90%;"}
- Literature regarding adoption of *flash* in ICN:
    - *Hierarchical Content Store*, SSD prefetch layer masked behing DRAM @rossini2014multi, @mansilha2015hierarchical, @mansilha2017exploiting.
    - Non-blocking caching I/O @so2014toward, @pan2021nb.
    - Flash damage aware caching @shukla2016designing.
- Joint caching and forwarding policies @yeh2014vip, @ioannidis2017jointly, @mahdian2017mindelay.
    - VIP framework @yeh2014vip: congestion-aware, incorporates cache read rates.
:::

::: {.footer}
Related Work
:::