<!DOCTYPE html>
<html lang="en"><head>
<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/tabby.min.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="index_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.56">

  <meta name="author" content="Research Advisor: Edmund Yeh Committee Members: Elif Uysal, Stratis Ioannidis">
  <title>Cost-aware Joint Caching and Forwarding in Networks with Diverse Cache Resources</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="index_files/libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="styles/styles.css">
  <link href="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="index_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script>
  MathJax = {
    loader: {
      load: ['[tex]/boldsymbol']
    },
    tex: {
      tags: "all",
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true,
      packages: {
        '[+]': ['boldsymbol']
      }
    }
  };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Cost-aware Joint Caching and Forwarding in Networks with Diverse Cache Resources</h1>
  <p class="subtitle">Faruk Volkan Mutlu - PhD Dissertation Defense Presentation</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Research Advisor: Edmund Yeh<br>Committee Members: Elif Uysal, Stratis Ioannidis 
</div>
</div>
</div>

</section>
<section id="outline" class="slide level2">
<h2>Outline</h2>
<ul>
<li>Primary Contribution
<ul>
<li><strong>Introduction</strong>: Motivation, Challenges, Related Work</li>
<li><strong>Technical</strong>: System Model, Optimization Framework</li>
<li><strong>Practical</strong>: Strategy, Experiments, Results</li>
<li><strong>Proposed Work</strong></li>
</ul></li>
<li>Other Contributions</li>
<li>Conclusion and Acknowledgements</li>
</ul>
<div class="footer">
<p>Outline</p>
</div>
<div class="hidden">
<p><span class="math display">\[
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\nin}{n \in \mc{N}}
\newcommand{\kin}{k \in \mc{K}}
\newcommand{\jin}{j \in \mc{J}_n}
\newcommand{\kjin}{(k,j) \in \mc{B}_{n,i}}
\newcommand{\iin}{i \in \mc{I}_n}
\newcommand{\ain}{a \in \mc{N}}
\newcommand{\bin}{b \in \mc{N}}
\newcommand{\abin}{(a,b) \in \mc{L}}
\newcommand{\about}{(a,b) \not\in \mc{L}^k}
\newcommand{\betasum}{\sum\limits ^{\sigma_n}_{i=1} \beta_{n,i}}
\newcommand{\betasumnl}{\sum ^{\sigma_n}_{i=1} \beta_{n,i}}
\newcommand{\betasumind}{\sum\limits ^{\sigma_n}_{i=1} \beta_{n,i}\mathbf{1}_{[\kjin]}}
\newcommand{\minpen}{\Psi(\boldsymbol{\lambda})}
\newcommand{\drift}{\Delta(\mathbf{V}(t))}
\newcommand{\norm}[1]{\lVert{#1}\rVert^2_2}
\newcommand{\pen}{\mathbb{E}[p(t)|\mathbf{V}(t)]}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\definecolor{neured}{RGB}{200, 16, 46}
\]</span></p>
</div>
</section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>

</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<div>
<ul>
<li class="fragment"><strong>Context</strong>: Information-centric networking (ICN), in-network caching, content delivery networks (CDNs)</li>
<li class="fragment"><strong>Motivation</strong>: Data volume grows exponentially, cache capacities are stagnant</li>
<li class="fragment"><strong>Challenge</strong>: Operating larger caches in a efficiently is difficult
<ul>
<li class="fragment">Are slower storage elements viable as caches?</li>
<li class="fragment">What are the costs of operating large caches?</li>
<li class="fragment">How can we get the most out of caches in the network?</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To begin, here’s a brief overview of my primary research that I will present today.</li>
<li>First off, for context, my work is based on the Information-centric Networking paradigm.</li>
<li>In particular, I’m targeting a core functionality of ICNs called in-network caching, which lets every router in the network maintain its own cache, making caching decentralized and more scalable.</li>
<li>However, my work is also applicable within today’s Internet, especially for systems like CDNs, where it could be used as an overlay.</li>
<li>The main motivation for my work is simply that the volume of data continuously grows, but the capacities of our caches are somewhat stagnant.</li>
<li>Of course there are many obstacles in the way of scaling cache capacities. We’ll specifically look at three considerations: (1) are slower storage elements viable as caches? (2) what are the costs of operating large caches? (3) how can we get the most out of caches in the network?</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="overview-1" class="slide level2">
<h2>Overview</h2>
<ul>
<li><strong>Context</strong>: Information-centric networking (ICN), in-network caching, content delivery networks (CDNs)</li>
<li><strong>Motivation</strong>: Data volume grows exponentially, cache capacities are stagnant</li>
<li><strong>Challenge</strong>: Operating larger caches in a efficiently is difficult</li>
<li><strong>Goal</strong>: Caching policy that addresses these considerations</li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>By the end, our goal is to come up with a policy that addresses these considerations</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation-data-intensive-science" class="slide level2 smaller">
<h2>Motivation: Data-Intensive Science</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/data_plot.svg"></p>
<ul>
<li>Data-intensive science experiments process huge amounts of data</li>
<li>Data growth predictions keep moving the bar up</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/lhcopen_data.svg"></p>
<ul>
<li>Data is continuously distributed across the world for research</li>
<li>In one year of LHC running, over an exabyte of data is accessed</li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To expand on my motivation, I’ll first talk about the use case that initially inspired my work.</li>
<li>As you know, large science programs in fields like high-energy physics, genomics etc. deal with experiments that produce huge amounts of data.</li>
<li>For instance, for the LHC, in one year, over an exabyte of data is accessed.</li>
<li>This data also has to constantly be distributed across the world for research, which is a significant networking challenge.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation-data-intensive-science-1" class="slide level2 smaller">
<h2>Motivation: Data-Intensive Science</h2>
<p><em>N-DISE: NDN-based Data Distribution for Large-Scale Data-Intensive Science</em>:</p>
<div>
<ul>
<li class="fragment">First high-performance NDN-based data delivery system for large-scale data-intensive science experiments.</li>
<li class="fragment">Integration of state-of-the-art NDN forwarder, intelligent caching and forwarding, high-performance consumer/producer applications.</li>
<li class="fragment">Extensive testing over wide-area network testbed spanning 5 US campuses using data from the Compact Muon Solenoid (CMS) experiment.</li>
<li class="fragment">Individual contributions:
<ul>
<li class="fragment">Built local testbed for prototyping</li>
<li class="fragment">Supported WAN deployment and testing</li>
<li class="fragment">Supported demonstrations during SC21 and SC22</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>To address this, our lab led an effort to build a state-of-the-art, Named Data Networking based data distribution system, which you can read about in the paper we published in ICN 2022.</li>
<li>The point here is, even in this state-of-the-art prototype, we were only able to allocate a small amount of cache space at each router. As you can see it is a drop in the bucket compared to the volumes we expect to be working with.</li>
<li>I also want to briefly mention that, in a separate paper that describes a core technology that enabled the N-DISE system (the NDN-DPDK forwarder), the problem of scaling cache capacities and the need for specialized policies for operating larger caches was specifically outlined as part of future outlook.</li>
<li>So there’s a gap here that motivated my work.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation-data-intensive-science-2" class="slide level2 smaller">
<h2>Motivation: Data-Intensive Science</h2>
<p><strong>Cache capacity challenge:</strong> 20 GB of DRAM cache space allocated at each node</p>
<div>
<ul>
<li class="fragment">DRAM is the standard cache device due its speed; but is expensive and has limited capacity</li>
<li class="fragment">Next best option is NVMe SSD; is cheap and has large capacity, but much slower than DRAM</li>
<li class="fragment">Logical next step: use both!</li>
<li class="fragment">Open problem: “Expanding capacities with persistent memory or NVMe disk storage require novel multi-tier caching algorithms”<sup>1</sup></li>
</ul>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Placeholder.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn1"><p>“NDN-DPDK: NDN forwarding at 100 Gbps on commodity hardware”, J. Shi, D. Pesavento, L. Benmohamed, ACM ICN 2020</p></li></ol></aside></section>
<section id="toy-example" class="slide level2 smaller">
<h2>Toy Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/toynet_cache.svg" class="quarto-figure quarto-figure-center" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(C_{ab}\)</span></td>
<td style="text-align: left;">Capacity of link <span class="math inline">\((a,b)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mathcal{N}_c\)</span></td>
<td style="text-align: left;">Set of consumer nodes</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(r_{n_j}\)</span></td>
<td style="text-align: left;">Read rate of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(L_{n_j}\)</span></td>
<td style="text-align: left;">Cache size of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:50%;">
<ul>
<li>Catalog of 1000 objects, ranked in popularity by <span class="body-highlight">Zipf’s law</span></li>
<li>Objects cached by rank:
<ul>
<li>Tier 1: 1-10</li>
<li>Tier 2: 11-50 (100)</li>
</ul></li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now, to both illustrate the capacity challenge more precisely, and to underline how slower caches may help us here, I brought in a toy example.</li>
<li>Here we’re looking at a simple network with a catalog of objects, all hosted by one server.</li>
<li>We assume the popularity distribution of these objects are governed by Zipf’s law. We have a set of consumers making requests for these objects, which go through a forwarder.</li>
<li>The forwarder has three potential tiers of cache, with the first being a fast and small tier, the middling being a lot larger but slower, then the last one being even larger but much slower.</li>
<li>If the forwarder can respond to a request from one its cache tiers, it does so instead of forwarding it to the server. There is a fixed caching policy at the forwarder, according to a priori knowledge of object popularities, as you can see on the screen.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="case-for-additional-slower-caches" class="slide level2 smaller">
<h2>Case for Additional, Slower Caches</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/zipf_1k.svg"></p>
<ul>
<li>Most popular 1% of objects make up one fifth of all requests</li>
<li>Most popular 10% of objects make up half of all requests</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/small_tiers.svg"></p>
<ul>
<li>Second tier operates slower but improves delay for high request rates</li>
<li>Part of uplink traffic shifted to second tier reducing congestion</li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>First off, on the left hand side, we see the CDF for Zipf’s law. The key observation there is that, in this network, roughly one fifth of all requests will be for the most popular 1% of objects, and half of all requests will be for the most popular 10%.</li>
<li>Now, on the right hand side, we see how adding the middling tier on top of the first tier impacts the total delay in the network. Even though the second tier is slower, it improves delay when there’s more traffic.</li>
<li>This can be linked directly to our observation from Zipf’s law, because even though the second tier has a larger amount of objects cached, the frequency of requests that hit the second tier does not exceed its read capacity, since those objects are less popular.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="case-for-additional-slower-caches-1" class="slide level2 smaller">
<h2>Case for Additional, Slower Caches</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="images/zipf_1k.svg"></p>
<ul>
<li>Most popular 1% of objects make up one fifth of all requests</li>
<li>Most popular 10% of objects make up half of all requests</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="images/all_tiers.svg"></p>
<ul>
<li>Addition of second tier capacity impacts performance negatively</li>
<li>Diverted traffic approaches rate limit of second tier, making it a bottleneck</li>
</ul>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>However, adding the last tier, even though it expands our total cache capacity, impacts delay negatively</li>
<li>Because what I just explained does not hold for the third tier since its much larger and much slower</li>
<li>So we end up trading the delay that would occur on the server link with worse read delay on the third tier.</li>
<li>In summary, larger and slower caches are viable, but we have to be careful in managing them.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-cost-challenge" class="slide level2">
<h2>The Cost Challenge</h2>
<ul>
<li>Caches are not free to use: admissions, replacements, even idle operation has an energy cost</li>
</ul>
<div class="columns">
<div class="column" style="width:42%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>DRAM power consumption</figcaption>
<p><img data-src="images/dram_power.png"></p>
</figure>
</div>
</div><div class="column" style="width:58%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>NVMe power consumption</figcaption>
<p><img data-src="images/ssd_power.png"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now of course the capacity challenge is not the only obstacle in our way. There’s another major consideration which is operational costs.</li>
<li>Caches are not free to use, each admission and replacement, and even idle operation has a real cost in energy so if we’re adding even more cache devices we have to be mindful of this cost.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-cost-challenge-1" class="slide level2">
<h2>The Cost Challenge</h2>
<ul>
<li>Caches are not free to use: admissions, replacements, even idle operation has an energy cost</li>
<li>SSDs also wear out over time as they’re written</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>NVMe Endurance</figcaption>
<p><img data-src="images/ssd_endurance.png" style="width:70.0%;height:70.0%"></p>
</figure>
</div>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>And on top of that, SSDs also wear out as they’re written, which, although modern SSDs are very durable, is still a significant consideration because dynamic caching operates at a small time scale so storage will be rewritten quite frequently</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="coupling-caching-with-forwarding" class="slide level2">
<h2>Coupling Caching with Forwarding</h2>
<ul>
<li>Benefits of caching more pronounced when caching and forwarding decisions are tightly coupled<sup>1</sup>.</li>
<li>This is even more critical with larger, slower caches: traffic should be diverted intelligently so congestion is balanced.</li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Finally, we look at the question of how can we make sure we’re actually making the most of caches in the network?</li>
<li>Because, now that we’re adding larger caches that are difficult to operate, and also adding costs into the equation, we really want to make sure we’re getting the benefits.</li>
<li>This is where the act of tying caching and forwarding together comes in.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn2"><p>“<em>Coupling caching and forwarding: benefits, analysis, and implementation</em>”, G. Rossini, D. Rossi, ICN 2014</p></li></ol></aside></section>
<section id="goal" class="slide level2">
<h2>Goal</h2>
<p>Develop a joint forwarding and caching policy that:</p>
<ul>
<li>Tracks user demand for objects as basis for decisions</li>
<li>Utilizes diverse cache resources effectively:
<ul>
<li>Ensures devices are receiving <span class="body-highlight">sustainable hit rates</span></li>
<li>Makes <span class="body-highlight">high-value</span> replacement decisions</li>
</ul></li>
<li>Utilizes bandwidth resources effectively:
<ul>
<li>Steers requests toward caching points</li>
<li>Forwards requests avoiding congestion</li>
</ul></li>
</ul>
<div class="footer">
<p>Introduction</p>
</div>
<aside class="notes">
<ul>
<li>Now, having looked at these considerations, let’s make our goal more explicit.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="related-work-icn" class="slide level2">
<h2>Related Work: ICN</h2>
<ul>
<li><em>“Multi-Terabyte and multi-Gbps information centric routers”</em>, G. Rossini, D. Rossi, M. Garetto, E. Leonardi, INFOCOM 2014</li>
<li><em>“Hierarchical Content Stores in High-Speed ICN Routers: Emulation and Prototype Implementation”</em>, R. B. Mansilha, L. Saino, M. Barcellos, M. Gallo, E. Leonardi, D. Perino, D. Rossi, ICN 2015</li>
<li><em>“Exploiting parallelism in hierarchical content stores for high-speed ICN routers”</em>, R. B. Mansilha, M. Barcellos, E. Leonardi, D. Rossi, COMNET 2017</li>
</ul>
<div class="footer">
<p>Related Work</p>
</div>
<aside class="notes">
<ul>
<li>Now, to conclude the introduction, I want to point out some related work.</li>
<li>This connected series of papers you see on the screen, which come from the same group that authored the one about coupling caching and forwarding that I just discussed, is the closest related work in my opinion.</li>
<li>These papers lay out similar concerns about cache capacities and the relevant challenges.</li>
<li>However, their work targets the system layer. They deal with lower level implementation details of how to integrate SSDs into the actual data structures that make up the caches in ICNs.</li>
<li>In these works, while the authors rely on traditional cache admission and replacement policies, they also point out that specialized policies may result in better performant systems.</li>
<li>They also do not consider the coupling of forwarding decisions.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="related-work-more-icn" class="slide level2 smaller">
<h2>Related Work: More ICN</h2>
<ul>
<li><em>“A reality check for content centric networking”</em>, D. Perino, M. Varvello, SIGCOMM 2011</li>
<li><em>“Toward terabyte-scale caching with SSD in a named data networking router”</em>, W. So, et al., ANCS 2014</li>
<li><em>“On Designing Optimal Memory Damage Aware Caching Policies for Content-Centric Networks”</em>, S. Shukla, A. A. Abouzeid, WiOpt 2016</li>
<li><em>“HCaching: High-Speed Caching for Information-Centric Networking”</em>, H. Li, et al., GLOBECOM 2017</li>
<li><em>“A Split Architecture Approach to Terabyte-Scale Caching in a Protocol-Oblivious Forwarding Switch”</em>, L. Ding, et al., ToN 2017</li>
<li><em>“NB-cache: non-blocking in-network caching for high-speed content routers”</em>, T. Pan, et al., IWQoS 2019</li>
</ul>
<div class="footer">
<p>Related Work</p>
</div>
<aside class="notes">
<ul>
<li>Obviously, there are a lot more works that explore similar problems from different angles. I can’t go into everything at the moment, but I still wanted to put these other works from the ICN literature in</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="related-work-hss" class="slide level2">
<h2>Related Work: HSS</h2>
<ul>
<li><em>“AutoTiering: automatic data placement manager in multi-tier all-flash datacenter”</em>, Z. Yang, et al., IPCCC 2017</li>
<li><em>“Sibyl: Adaptive and extensible data placement in hybrid storage systems using online reinforcement learning”</em>, G. Singh, et al., ISCA 2022</li>
</ul>
<div class="footer">
<p>Related Work</p>
</div>
<aside class="notes">
<ul>
<li>As well as these works from the more tangentially related hybrid storage systems literature</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="related-work-vip" class="slide level2">
<h2>Related Work: VIP</h2>
<p><em>“VIP: a framework for joint dynamic forwarding and caching in named data networks”</em>, E. M. Yeh, T. Ho, Y. Cui, M. Burd, R. Liu, D. Leong, ACM ICN 2014</p>
<ul>
<li>Couples caching and forwarding</li>
<li>Models read rate of caches</li>
<li>Virtual and data plane separation makes algorithm simpler to operate</li>
<li>Lyapunov drift analysis integrates easily with costs</li>
</ul>
<div class="footer">
<p>Related Work</p>
</div>
<aside class="notes">
<ul>
<li>Lastly, perhaps the single most important related work to cover here is the VIP paper by Prof.&nbsp;Yeh and co-authors, as my work directly extends this paper.</li>
<li>So let me go over why that is.</li>
<li>Recall the earlier paper I mentioned about coupling caching and forwarding; coincidentally the VIP paper also appeared in the same conference and proposed a strategy that does exactly that, which suits our goals.</li>
<li>Furthermore, this paper includes the read capacities of cache devices in its system model, which is one of the parameters of primary concern to us.</li>
<li>The core feature of this paper is a separation of the data plane mechanisms from the “virtual plane”, where control decisions take place, which we also adopt as it makes building these strategies simpler.</li>
<li>Finally, there is a technical benefit here because the analysis for VIP is based on Lyapunov drift, which has an extension called drift-plus-penalty, that gives us a direct venue for incorporating cache utilization costs.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="system-model" class="title-slide slide level1 center">
<h1>System Model</h1>
<aside class="notes">
<p>That concludes the introduction and leads me into the system model that we’re dealing with.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="system-model-1" class="slide level2">
<h2>System Model</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/system_model.svg" class="quarto-figure quarto-figure-center" style="width:60.0%;height:60.0%"></p>
</figure>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>Here’s a simple illustration of the system model the separation and interaction between the virtual and data planes we’re adopting from the VIP paper.</li>
<li>The data plane is where actual network functionality is performed. The virtual plane uses the request arrival information from the data plane; its where control decisions are made.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-model" class="slide level2">
<h2>Data Plane Model</h2>
<p>Data plane model based on general ICN principles:</p>
<div>
<ul>
<li class="fragment">Unit of content is <em>data object</em>; each object <span class="math inline">\(\kin\)</span> has a unique source <span class="math inline">\(\mc{S}(k)\)</span></li>
<li class="fragment">Any node <span class="math inline">\(n \not = \mc{S}(k)\)</span> can cache <span class="math inline">\(k\)</span></li>
<li class="fragment">Every data object has the <span class="body-highlight">same size</span><br>
</li>
<li class="fragment">Requests can enter network at any node; sources / caching nodes respond to requests with data</li>
<li class="fragment">Data responses follow request path back to requester</li>
</ul>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>The principles of the data plane are based on those of a classical ICN.</li>
<li>We use “data object” as the unit of content in the network and assume that each object has a unique source node.</li>
<li>We particularly assume every object has the same size, which is a crucial assumption we’ll need to remember for later.</li>
<li>Requests can enter network at any node. A request for an object can be met with a data response at the source node for that object or at any node that caches that object.</li>
<li>Those data responses will follow the path of the request back to the requester (inverse of the path, of course)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-model-1" class="slide level2">
<h2>Data Plane Model</h2>
<p><span class="body-highlight">Multi-tiered caching model</span> adds following properties:</p>
<div>
<ul>
<li class="fragment">Any node can have any number of cache tiers</li>
<li class="fragment">A node can cache an object in at most one of its tiers (<span class="body-highlight">cache exclusivity</span>)</li>
<li class="fragment">An object evicted from one tier can <span class="body-highlight">migrate</span> to another tier at the same node</li>
</ul>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>The multi-tiered caching model I propose adds the following properties to those basic mechanisms.</li>
<li>Any node can have cache tiers and can cache any object in one of those tiers unless it already sources that object.</li>
<li>A node can cache an object in at most one of its tiers. This means that we don’t duplicate objects across cache tiers. This is also something critical to keep in mind.</li>
<li>An object evicted from one tier can migrate to another tier at the same node. So an eviction from one tier is not necessarily final for an object.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-model" class="slide level2">
<h2>Virtual Plane Model</h2>
<p>Virtual plane model based on (Yeh, 2014):</p>
<div>
<ul>
<li class="fragment"><em>Virtual interest packets (VIPs)</em> generated alongside exogenous requests</li>
<li class="fragment">Every node keeps a <span class="body-highlight">VIP counter</span> for every object <span class="math inline">\(\kin\)</span></li>
<li class="fragment">VIPs are removed at object sources and caching nodes</li>
<li class="fragment">Discrete time slots <span class="math inline">\(t = \{1,2,...\}\)</span></li>
<li class="fragment">Beginning of each time slot, each node decides where and how to forward its VIPs, as well as how to cache objects</li>
</ul>
</div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>Now, on to the virtual plane model, which is largely based on the original VIP paper. We’ll go over it briefly.</li>
<li>First off, anytime an exogenous request enters the data plane network, a virtual interest packet (VIP for short) is generated in the virtual plane at that node. These VIPs can only be removed at sources or caching points.</li>
<li>Each node maintains a VIP counter for each object in the network. We can interpret these counts as queues that describe unsatisfied demand for objects. Another useful way to think of these counters is as “potential” values, much like electrical potential, where the potential is high at request entry points and low at sources and caching points.</li>
<li>We’re considering discrete time slots in the virtual plane where caching and forwarding decisions for each time slot are made at the beginning of that time slot.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-model-1" class="slide level2">
<h2>Virtual Plane Model</h2>
<p>Virtual plane model expanded with multiple cache tiers and <span class="body-highlight">penalties</span>:</p>
<ul>
<li>Each cache admission and eviction in virtual plane incurs a penalty</li>
<li>Network can configure <span class="body-highlight">weight of penalties</span> via parameter <span class="math inline">\(\omega\)</span></li>
</ul>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>The multi-tiered caching model that I propose, which incorporates cache utilization costs, extends the virtual plane model.</li>
<li>Each cache admission and eviction in virtual plane incurs a penalty, and a configurable weight parameter, <span class="math inline">\(\omega\)</span>, lets the network determine the importance of penalties in its overall objective</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="vip-queue-dynamics" class="slide level2">
<h2>VIP Queue Dynamics</h2>
<p><span class="body-highlight">VIP queue evolution</span> for object <span class="math inline">\(k\)</span> at node <span class="math inline">\(n\)</span>, where <span class="math inline">\((x)^+ = max(x,0)\)</span>:</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation}
    V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
    + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \color{#A4804A}{\sum\limits_{j \in \mathcal{J}_n} r_{n_j} s^k_{n_j}(t)} \Bigg)^+    
\end{equation}\]</span>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(V^k_n(t)\)</span>: VIP count for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></p>
<p><span class="math inline">\(A^k_n(t)\)</span>: Number of exogenous requests for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></p>
<p><span class="math inline">\(\mu^k_{ab}(t)\)</span>: Allocated rate of VIPs for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span> during <span class="math inline">\(t\)</span></p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(\mathcal{J}_n\)</span>: Set of cache tiers at <span class="math inline">\(n\)</span></p>
<p><span class="math inline">\(r_{n_j}\)</span>: Read rate of tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span></p>
<p><span class="math inline">\(s^k_{n_j}(t)\)</span>: Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span></p>
</div></div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>This inequality shows how VIP counts change from slot to slot in the virtual plane</li>
<li>First term is VIPs forwarded away from the node, then we have the exogenous arrivals, then VIPs that arrive from other nodes and finally, VIPs removed due to caching. Notice that this term is dependent on the read rates of cache tiers.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="penalty-accumulation" class="slide level2">
<h2>Penalty Accumulation</h2>
<p>Penalty incurred by caching action <span class="math inline">\(s^k_{n_j}(t)\)</span>:</p>
<span class="math display">\[\begin{equation}
    p^k_{n_j}(t) \triangleq
    \left\{ \begin{array}{ll}
        c^a_{n_j}, &amp; \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = 1 \\
        c^e_{n_j}, &amp; \text{if} \; s^k_{n_j}(t) - s^k_{n_j}(t-1) = -1 \\
       0, &amp; \text{otherwise}
   \end{array} \right.
\end{equation}\]</span>
<span class="fragment">Sum penalty during <span class="math inline">\(t\)</span>: <span class="math inline">\(p(t) = \sum_{\kin, \nin, \jin} p^k_{n_j}(t)\)</span></span>
<hr>
<div class="columns">
<div class="column" style="font-size: 75%;">
<p><span class="math inline">\(s^k_{n_j}(t)\)</span>: Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span></p>
</div><div class="column" style="font-size: 75%;">
<p><span class="math inline">\(c^a_{n_j}\)</span>: Admission cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span> <span class="math inline">\(c^e_{n_j}\)</span>: Eviction cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></p>
</div></div>
<div class="footer">
<p>System Model</p>
</div>
<aside class="notes">
<ul>
<li>This definition shows how caching actions translate to penalties incurred</li>
<li>(Fragment in) We’ll also be concerned with the sum penalty across the network</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="virtual-plane-optimization" class="title-slide slide level1 center">
<h1>Virtual Plane Optimization</h1>
<aside class="notes">
<p>With the system model described, we will now look at our control algorithm in the virtual plane.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="optimization-goal" class="slide level2">
<h2>Optimization Goal</h2>
<p><em>“Operate close to VIP network stability region boundary while keeping sum penalty small.”</em></p>
<div class="fragment" data-fragment-index="1">
<p>Minimize upper bound of <span class="body-highlight">drift-plus-penalty</span><sup>1</sup> expression:</p>
<span class="math display">\[\begin{equation}
    \drift + \omega \pen
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    \drift \triangleq \mathbb{E}[\mathcal{L}(\mathbf{V}(t+1))-\mc{L}(\mathbf{V}(t))|\mathbf{V}(t)]
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    \mc{L}(\mathbf{V}(t)) \triangleq \sum\limits_{\nin, \kin} (V^k_n(t))^2
\end{equation}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The goal of our optimization in the virtual plane, is to operate as close as possible to the boundary of the stability region of the network of VIP queues, which we will define formally in a bit, while keeping penalties accumulated small.</li>
<li>(Fragment in) In particular, we’re trying to minimize the upper bound on this drift-plus-penalty expression you see on screen, which is based on an extension to Lyapunov optimization devised by Neely.</li>
<li>So in this way, we’re not necessarily trying to make a precisely optimal decision each time slot, but trying to minimize the expected value of an upper bound.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn3"><p><span class="fragment" data-fragment-index="1">“Energy optimal control for time-varying wireless networks.”, M. J. Neely, IEEE Trans. Inf. Theory, 2006.</span></p></li></ol></aside></section>
<section id="virtual-plane-caching" class="slide level2">
<h2>Virtual Plane Caching</h2>
<p>Beginning of each slot <span class="math inline">\(t\)</span>, at each node <span class="math inline">\(n\)</span>, observe <span class="math inline">\((V^k_n(t))_{k \in \mathcal{K}, n \in \mathcal{N}}\)</span> and perform <span class="body-highlight">caching</span> by choosing <span class="math inline">\(s^k_{n_j}(t)\)</span> for each <span class="math inline">\(\kin\)</span> and each <span class="math inline">\(j \in \mathcal{J}_n\)</span> with capacity <span class="math inline">\(L_{n_j}\)</span> to:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - \omega p^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>And here’s how we tackle this optimization. We devise an algorithm that’s made of two steps (caching and forwarding), which chooses the respective variables every time slot, to optimize a certain objective based on the VIP counts. We’re looking at the caching step right now.</li>
<li>Obviously there is a lot of math to get to this expression for the objective function, but I’ll give you the intuition briefly.</li>
<li>Because we want to remove as many VIPs from the network as fast as possible, we want to cache the higher VIP count objects in the faster tiers, which is why the read rate multiplies the VIP count here.</li>
<li>However, we also want to make sure that our choices in caching actions do not add large penalties that outweigh the benefits. Of course the importance of that is determined by omega.</li>
<li>And of course we have the cache tier capacity constraints and the cache exclusivity constraints</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane-forwarding" class="slide level2">
<h2>Virtual Plane Forwarding</h2>
<p>Perform <span class="body-highlight">forwarding</span> as in (Yeh, 2014), by choosing <span class="math inline">\(\mu^k_{ab}(t)\)</span> for each <span class="math inline">\(\kin\)</span> and <span class="math inline">\(\abin^k\)</span>:</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation}
   \mu^k_{ab}(t) =
   \left\{ \begin{array}{ll}
      C_{ba}, &amp; \text{if} \; k = k^*_{ab}(t) \; \text{and} \; W^k_{ab}(t) &gt; 0 \\
      0, &amp; \text{otherwise}
   \end{array} \right.
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
\begin{split}
   W^k_{ab}(t) &amp; \triangleq V^k_a(t) - V^k_b(t), \\
   k^*_{ab}(t) &amp; \triangleq \argmax\limits_{\{k: \abin^k\}} W^k_{ab}(t)
\end{split}
\end{equation}\]</span>
</div>
<hr>
<div class="columns">
<div class="column" style="font-size: 70%;">
<p><span class="math inline">\(C_{ab}\)</span>: Capacity of link <span class="math inline">\((a,b)\)</span></p>
</div><div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\mc{L}^k\)</span>: Set of links allowed to transmit VIPs of <span class="math inline">\(k\)</span>, determined by routing policy</p>
</div></div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>And here’s the forwarding step. The neat thing about our extension here is that we don’t actually need to alter the results for forwarding from the original VIP paper, which were based on the backpressure technique.</li>
<li>The intuition here again comes from thinking of VIP counts as potential representing unsatisfied demand. So with the forwarding step, we’re making sure VIP flows follow large differences in potential, essentially steering interests toward sinks, meaning sources or caches.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="theorem-stability-region" class="slide level2">
<h2>Theorem: Stability Region</h2>
<p>VIP <span class="body-highlight">stability region</span> <span class="math inline">\(\Lambda\)</span> consists of all arrival rates <span class="math inline">\(\boldsymbol{\lambda} = (\lambda^k_n)_{\kin,\nin}\)</span> such that:</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{equation}
    \lambda^k_n \leq \sum\limits_{\bin} f^k_{nb} - \sum\limits_{\ain} f^k_{an} + \sum\limits_{\jin} r_{n_j} \betasumind
\end{equation}\]</span>
</div>
<hr>
<div style="font-size: 70%; text-align: center">
<p><span class="math inline">\(f^k_{ab}\)</span>: Time-average VIP flow for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span></p>
</div>
<div class="columns">
<div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\mc{B}_{n,i}\)</span>: i-th among all <span class="math inline">\(\sigma_n\)</span> possible cache placement sets at <span class="math inline">\(n\)</span>; if <span class="math inline">\((k,j) \in \mc{B}_{n,i}\)</span> during <span class="math inline">\(t\)</span>, <span class="math inline">\(s^k_{n_j}(t)\)</span> = 1</p>
</div><div class="column" style="font-size: 70%;">
<p><span class="math inline">\(\beta_{n,i}\)</span>: Fraction of time objects at <span class="math inline">\(n\)</span> are placed according to <span class="math inline">\(\mc{B}_{n,i}\)</span>; <span class="math inline">\(0 \leq \beta_{n,i} \leq 1\)</span> and <span class="math inline">\(\sum^{\sigma_n}_{i=1} \beta_{n,i} = 1\)</span></p>
</div></div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The analysis of our approach comes in two steps. We’re following the structure of Lyapunov drift-based analysis here, so we first define the stability region of the virtual plane network.</li>
<li>The inequality on the screen essentially defines the boundary of that stability region, relating the arrival rates that can be satisfied to the long term average VIP flow over links, as well as VIPs removed via cache tiers.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="theorem-trade-off" class="slide level2 smaller">
<h2>Theorem: Trade-off</h2>
<p>For arrival rate vector <span class="math inline">\(\boldsymbol{\lambda}\)</span>, if there exists <span class="math inline">\(\boldsymbol{\epsilon}\)</span> such that <span class="math inline">\(\boldsymbol{\lambda} + \boldsymbol{\epsilon} \in \Lambda\)</span>, then the network of VIP queues under the proposed algorithm satisfies the following:</p>
<div style="font-size: 110%;">
<span class="math display">\[\begin{equation}
    \lim\limits_{T \rightarrow \infty} \frac{1}{T} \sum\limits^{T-1}_{t=0} \sum\limits_{\nin, \kin} \mathbb{E}[V^k_n(t)] \leq \frac{NB}{\epsilon} + \frac{\omega}{2\epsilon} \minpen
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
    \lim\limits_{T \rightarrow \infty} \frac{1}{T}\sum\limits^{T-1}_{t=0} \mathbb{E}[p(t)] \leq \frac{2NB}{\omega} + \minpen
\end{equation}\]</span>
</div>
<div class="fragment" style="font-size: 80%;">
<span class="math display">\[\begin{equation}
    B \triangleq \frac{1}{2N} \sum_{\nin} \bigg((\mu^{out}_{n,max})^2 + 2(\mu^{out}_{n,max})r_{n,max} + \big(\textstyle \sum_{\kin}A^k_{n,max} + \mu^{in}_{n,max} + r_{n,max})^2 \bigg)
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
\epsilon \triangleq \textstyle \min_{\nin,\kin} \epsilon^k_n
\end{equation}\]</span>
<p><span class="math inline">\(\Psi(\boldsymbol{\lambda})\)</span>: Minimum time-average sum penalty achievable by a feasible and stabilizing randomized policy.</p>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The second step of our analysis is what actually shows the guarantees that our algorithm can provide. Here, we use the definition of the stability region, which is why we needed the previous step.</li>
<li>These two expressions define the upper bounds for time average VIP queue sizes and accumulated penalty in the virtual plane network.</li>
<li>The essential observation here is the trade-off between the bounds. As you can see, the omega value controls which bound we wish to prioritize, because setting it small means lower average queue sizes which translates to better performance, but at the cost of potentially much larger penalties. Setting it large is the inverse of that situation.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<p>We can rewrite <span class="body-highlight">caching</span> step optimization problem.</p>
<div style="font-size: 100%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} r_{n_j} V^k_{n}(t) s^k_{n_j}(t) - \omega p^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Now of course, the validity of our approach hinges on whether we can solve the optimization problem from the caching step.</li>
<li>To do so, we will first rewrite it to clean up this unpleasant form we’ve shown before. And to do that, we will use a two-step transformation of variables.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-1" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<p>We can rewrite <span class="body-highlight">caching</span> step optimization problem.</p>
<div style="font-size: 80%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\jin} b^k_{n_j}(t) s^k_{n_j}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_j}(t) \leq L_{n_j}, \; \forall \, \jin \\
        &amp; \quad \sum\limits_{\jin} s^k_{n_j}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_j}(t) \in \{0, 1\}, \; \forall \, \kin, \; \jin
\end{align}\]</span>
<span class="math display">\[\begin{equation}
    b^k_{n_j}(t) \triangleq \left\{ \begin{array}{ll}
        r_{n_j} V^k_n(t) - \omega c^a_{n_j}, &amp; \text{if} \; s^k_{n_j}(t-1) = 0 \\
        r_{n_j} V^k_n(t) + \omega c^e_{n_j}, &amp; \text{if} \; s^k_{n_j}(t-1) = 1
    \end{array} \right.
\end{equation}\]</span>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>The first step here is defining an auxiliary “benefit” term and using that to simplify the objective function.</li>
<li>You’ll notice that the problem now looks to be in the form of a generalized assignment problem.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lemma-caching-solution-2" class="slide level2">
<h2>Lemma: Caching Solution</h2>
<p>Use equal object sizes, decide variables for each one-object <span class="body-highlight">cache slot</span>. Rewrite problem as <span class="body-highlight">linear assignment problem</span>.</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{align}
    \text{maximize}
        &amp; \quad \sum\limits_{\kin} \sum\limits_{\iin} b^k_{n_i}(t) s^k_{n_i}(t) \\
    \text{subject to}
        &amp; \quad \sum\limits_{\kin} s^k_{n_i}(t) \leq 1, \; \forall \, \iin \\
        &amp; \quad \sum\limits_{\iin} s^k_{n_i}(t) \leq 1, \; \forall \, \kin \\
        &amp; \quad s^k_{n_i}(t) \in \{0, 1\}, \; \forall \, \kin, \; \iin
\end{align}\]</span>
</div>
<div style="font-size: 60%;">
<span class="math display">\[\begin{equation}
\mc{I}_n \triangleq \{1, 2, ..., \sum_{\jin} L_{n_j}\}, \; \mc{I}_{n_j} \triangleq \{1 + \sum^{j - 1}_{\ell = 1} L_{n_\ell}, ..., \sum^{j}_{\ell = 1} L_{n_\ell}\}
\end{equation}\]</span>
<p>If <span class="math inline">\(i \in \mc{I}_{n_j}\)</span>, then <span class="math inline">\(b^k_{n_j}(t) = b^k_{n_i}(t)\)</span> and <span class="math inline">\(s^k_{n_j}(t) = s^k_{n_i}(t)\)</span>.</p>
</div>
<div class="footer">
<p>Optimization Framework</p>
</div>
<aside class="notes">
<ul>
<li>Now recall the assumption we made in our model that every data object has the same size.</li>
<li>Using that assumption, we can think of each cache tier as made up of several “cache slots” that can each take one object. The number of these per tier depend on the total capacity of that tier. These slots have the same read rate and cost parameters as the tier they belong in.</li>
<li>Now, also recall the cache exclusivity constraint of the original problem. We can easily see that exclusivity across tiers directly translates to exclusivity across these cache slots.</li>
<li>Using these facts we can rewrite the problem again, this time in the form of a linear assignment problem.</li>
<li>Luckily, there are methods that can solve this problem in polynomial time. We specifically rely on a modification of the Jonker-Volgenant algorithm.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="data-plane-strategy" class="title-slide slide level1 center">
<h1>Data Plane Strategy</h1>
<aside class="notes">
<ul>
<li>So there are several things about applying this virtual plane algorithm within the mechanics of the data plane</li>
<li>Most obvious is that virtual plane decisions are made in discrete time slots, but of course the data plane decisions have to be reactive and continuous</li>
<li>(Next slide)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-caching" class="slide level2">
<h2>Data Plane Caching</h2>
<p><span class="body-highlight">Oscillatory</span><sup>1</sup> nature of VIP counts impractical for data plane caching. Adapt <span class="body-highlight">cache score</span> metric from (Yeh, 2014), defined over sliding window of <span class="math inline">\(T\)</span> slots:</p>
<span class="math display">\[\begin{equation}
    CS^k_n(t) \triangleq \frac{1}{T} \sum^t_{\tau = t - T + 1} \sum_{(a,n) \in \mc{L}^k} v^k_{an}(\tau)
\end{equation}\]</span>
<p><span class="math inline">\(\mc{v}^k_{ab}\)</span>: Number of VIPs for <span class="math inline">\(k\)</span> transmitted over <span class="math inline">\((a,b)\)</span> during <span class="math inline">\(t\)</span></p>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>But there is another major consideration</li>
<li>Because VIP counts change frequently and drastically, cache states also tend to change quickly. Basing caching on this behavior directly is impractical in the data plane, especially given that we’re now working with slower caches and considering costs, so we’re trying to be conservative in the replacements we make.</li>
<li>So we adapt this cache score metric from the VIP paper, which is basically a measurement of demand for a certain object over a window of time, based on the VIP counts.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside><ol class="aside-footnotes"><li id="fn4"><p>When the VIP count for an object becomes large, we make decisions in the virtual plane that will quickly drive the count down.</p></li></ol></aside></section>
<section id="data-plane-caching-1" class="slide level2">
<h2>Data Plane Caching</h2>
<p>Define the <span class="body-highlight">cache benefit</span> metric as follows:</p>
<div style="font-size: 75%;">
<span class="math display">\[\begin{equation}
    CB^k_{n_j}(t) = \begin{cases}
        \begin{array}{l}
             r_{n_j}(CS^k_n(t) - CS^{k^{min}_{n_j}(t)}_n(t)) - \omega(c^a_{n_j} + c^e_{n_j}), \text{if} \, j \, \text{is full} \\
             r_{n_j} CS^k_n(t) - \omega c^a_{n_j}, \; \text{otherwise}
        \end{array}
    \end{cases}
\end{equation}\]</span>
</div>
<span class="math display">\[\begin{equation}
   k^{min}_{n_j}(t) = \argmin_{\{k \in \mc{K}_{n_j}(t)\}} CS^k_n(t)
\end{equation}\]</span>
<p><span class="math inline">\(\mc{K}_{n_j}(t)\)</span>: Set of objects cached in <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span>, in the data plane</p>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>But then, because we also consider costs, we need a metric that incorporates those.</li>
<li>So we define this cache benefit metric, which includes both the cache score and weighted utilization costs.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-caching-2" class="slide level2">
<h2>Data Plane Caching</h2>
<p>When <span class="math inline">\(k \not \in \mc{K}_{n_j}(t)\)</span> arrives at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span>, <span class="body-highlight">data plane caching policy</span> at <span class="math inline">\(n\)</span> behaves as follows:</p>
<ul>
<li>Find cache tier offering highest cache benefit, i.e.&nbsp;<span class="math inline">\(j^* = \argmax_{\{ \jin \}} CB^k_{n_j}(t)\)</span></li>
<li>If <span class="math inline">\(CB^k_{n_{j^*}}(t) &gt; 0\)</span>, admit object into tier <span class="math inline">\(j^*\)</span>
<ul>
<li>If <span class="math inline">\(j^*\)</span> is full, i.e.&nbsp;<span class="math inline">\(|\mc{K}_{n_{j^*}}(t)| = L_{n_{j^*}}\)</span>, <span class="math inline">\(k\)</span> replaces <span class="math inline">\(k^{min}_{n_{j^*}}\)</span></li>
</ul></li>
<li>If a replacement happened in <span class="math inline">\(j^* &lt; |\mc{J}_n|\)</span>, set <span class="math inline">\(k = k^{min}_{n_{j^*}}\)</span>, then start the process over</li>
</ul>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>Now, to state the exact data plane policy</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-plane-forwarding" class="slide level2">
<h2>Data Plane Forwarding</h2>
<p>Forwarding strategy is as in (Yeh, 2014). When a request for object <span class="math inline">\(k \not \in \mc{K}_{n_j}(t), \; \forall \jin\)</span>, arrives at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span>, the request is forwarded to the following node:</p>
<span class="math display">\[\begin{equation}
    b^k_n(t) = \argmax_{\{ b:(n,b) \in \mc{L}^k \}} \frac{1}{T} \sum\limits^t_{t'=t-T+1} v^k_{nb}(t)
\end{equation}\]</span>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>As for the forwarding, again this doesn’t need to be altered.</li>
<li>We can directly use this policy from the VIP paper, that also relies on a sliding window average, but this time on outgoing VIP flows.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="chunk-level-decisions" class="slide level2">
<h2>Chunk-level Decisions</h2>
<p>At chunk-level in data plane, we observe the following principles:</p>
<ul>
<li>If a data object is admitted to (evicted from) a cache tier, all its chunks must be admitted to (evicted from) that tier.</li>
<li>Forwarding decision is made upon receiving request for a first chunk. Requests for subsequent chunks are forwarded to the same node.</li>
</ul>
<div class="footer">
<p>Data Plane Strategy</p>
</div>
<aside class="notes">
<ul>
<li>As a final note, recall that our model and approach is at the object level, but in the real world, the data plane operates at a chunk (or packet) level</li>
<li>So here are the two principles we would observe when applying our approach at the chunk level</li>
<li>(Talk about bullet points)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="experiments" class="title-slide slide level1 center">
<h1>Experiments</h1>
<aside class="notes">
<ul>
<li>Alright, so how does our strategy fare in experimental evaluations</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simulation-setup" class="slide level2">
<h2>Simulation Setup</h2>
<div>
<ul>
<li class="fragment">Object-level, DES framework built with Python using SimPy library</li>
<li class="fragment">Modular design to allow future extension</li>
<li class="fragment">Thread-per-experiment multi-threading</li>
<li class="fragment">Detailed statistic logging</li>
<li class="fragment">Parameter and output data in JSON format for easy parsing</li>
</ul>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Firstly, when I say experiments here I strictly mean simulation experiments</li>
<li>I built a simulator from scratch for this purpose, which took a bit of time and care</li>
<li>(Talk about bullet points)</li>
<li>I needed to build this because existing simulators didn’t cover what I needed, and modifying them would’ve taken even more time</li>
<li>Of course this is also far from perfect, but I think it turned out to be something very useful and flexible</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="topologies" class="slide level2 smaller">
<h2>Topologies</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Abilene (11 nodes)</figcaption>
<p><img data-src="images/abilene.svg"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>GEANT (34 nodes)</figcaption>
<p><img data-src="images/geant.svg"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>4x4 Grid (16 nodes)</figcaption>
<p><img data-src="images/grid.svg"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>3-Regular (50 nodes)</figcaption>
<p><img data-src="images/3reg.svg"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Alright, so when it comes to experiment settings, I first have to stress that the experimentation space for this work is enormous</li>
<li>So the results I’ll show here are those that I think most succinctly show that our approach can deliver on our goals</li>
<li>To start off, these are the four topologies I conducted experiments over</li>
<li>On the left are Abilene and Geant which are real network topologies, and on the right are two stylized graphs</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="experiment-setting" class="slide level2">
<h2>Experiment Setting</h2>
<div>
<ul>
<li class="fragment"><span class="math inline">\(\mc{S}(k)\)</span> are selected uniformly at random</li>
<li class="fragment">Routing: <em>Any</em> shortest path (in number of hops) between <span class="math inline">\(n\)</span> and <span class="math inline">\(\mc{S}(k)\)</span></li>
<li class="fragment">Two cache tiers at every node</li>
<li class="fragment">Requests generated for 100 simulation seconds, run terminates when all requests are resolved</li>
<li class="fragment">Virtual plane algorithm slot length of 1 second, sliding window of size 100 slots</li>
</ul>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>There are some additional assumptions that pertain to the experiment setting so let’s go over those</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="baselines" class="slide level2">
<h2>Baselines</h2>
<div>
<ul>
<li class="fragment">Adapted replacements: LRU, LFU, FIFO, RANDOM
<ul>
<li class="fragment">LRU, FIFO and RANDOM are cost-unaware, paired with Leave Copy Everywhere admission</li>
<li class="fragment">LFU admission based on frequency
<ul>
<li class="fragment">Cost-aware LFU adaptation uses similar benefit metric</li>
</ul></li>
</ul></li>
<li class="fragment">All baseline caching policies paired with Least Response Time forwarding</li>
</ul>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Because there aren’t really any policies, novel or established, we could directly compare against, we adapted our own baselines from well-known single-cache policies</li>
<li>We adapted LRU, FIFO and RANDOM replacement but for these there isn’t a good metric to incorporate costs, so those are cost-unaware and for admission they’re paired with the basic Leave Copy Everywhere policy</li>
<li>We adapted LFU similarly, but also made a cost-aware LFU adaptation which uses a cache benefit metric similar to the one we devised for our aproach</li>
<li>Least response time forwarding simply chooses the link with smallest delay for last satisfied request</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="parameter-reference-table" class="slide level2 smaller">
<h2>Parameter Reference Table</h2>
<table class="caption-top">
<caption>Common parameters for all scenarios</caption>
<colgroup>
<col style="width: 10%">
<col style="width: 80%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(K\)</span></td>
<td style="text-align: center;">Number of objects in catalog <span class="math inline">\(\mc{K}\)</span></td>
<td style="text-align: center;">1000</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\sum_{\kin} \lambda^k_n\)</span></td>
<td style="text-align: center;">Total request arrival rate at each <span class="math inline">\(n\)</span> in objects/sec</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\alpha\)</span></td>
<td style="text-align: center;">Zipf’s law parameter for object popularity distribution</td>
<td style="text-align: center;">0.75</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(C_{ab}\)</span></td>
<td style="text-align: center;">Capacity of each link <span class="math inline">\(\abin\)</span>, in objects</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(L_{n_1}\)</span></td>
<td style="text-align: center;">Capacity of tier 1 at each <span class="math inline">\(n\)</span>, in objects</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(r_{n_1}\)</span></td>
<td style="text-align: center;">Read rate of tier 1 at each <span class="math inline">\(n\)</span>, in objects/sec</td>
<td style="text-align: center;">20</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(c^a_{n_1}\)</span>, <span class="math inline">\(c^e_{n_1}\)</span></td>
<td style="text-align: center;">Admission and eviction costs of tier 1 at each <span class="math inline">\(n\)</span></td>
<td style="text-align: center;">4, 2</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(r_{n_2}\)</span></td>
<td style="text-align: center;">Read rate of tier 2 at each <span class="math inline">\(n\)</span>, in objects/sec</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(c^a_{n_2}\)</span>, <span class="math inline">\(c^e_{n_2}\)</span></td>
<td style="text-align: center;">Admission and eviction costs of tier 2 at each <span class="math inline">\(n\)</span></td>
<td style="text-align: center;">2, 1</td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>As I said, there are a great number of parameters for these experiments and I’m not going to cover each one in the interest of time, but we have this table for reference if needed</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="results-i" class="slide level2 smaller">
<h2>Results I</h2>
<p><strong>Scenario</strong>: No penalties (<span class="math inline">\(\omega=0\)</span>), <span class="math inline">\(L_{n_1} = 5\)</span> and <span class="math inline">\(L_{n_2} = 100\)</span> at each <span class="math inline">\(n\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>  Total delay, as fraction of total delay without any caching</figcaption>
<p><img data-src="images/tops_delay_v3.svg" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Cache hits, percentage of hits in the first tier on the left, total number of hits on the right</figcaption>
<p><img data-src="images/tops_hits_v3.svg" style="width:75.0%;height:75.0%"></p>
</figure>
</div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>First, I’ll show results from a scenario where we actually ignore penalties, which we can easily do for our approach by setting omega to be zero</li>
<li>We’re comparing our strategy to cost-unaware baselines here and we’re just concerned about the capacity challenge</li>
<li>The figure up top shows the total delay in the network, normalized to the total delay achieved without any caching</li>
<li>This figure illustrates our point about how managing larger caches is difficult, because as you can see, the “naive” policies are struggling quite a bit, at times showing worse performance than would be achieved with no caches at all</li>
<li>Our VIP-based approach performs the best across all experiments, though LFU is not that far behind</li>
<li>The bottom figure reveals more insights since it shows the distribution of cache hits among the two tiers as well as total cache hits</li>
<li>Now note the cache capacities up top, the difference is 20-fold</li>
<li>However, with our approach, anywhere between 15% to 20% of cache hits are occurring on the first tier, much larger than other baselines, showing that we’re able to balance the amount of cache hits better</li>
<li>You’ll notice in most cases our approach doesn’t even have the highest total number of cache hits, and that’s because it is set up to handle the rate of cache hits properly</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="results-ii" class="slide level2 smaller">
<h2>Results II</h2>
<p><strong>Scenario</strong>: Cost-unaware policies excluded, <span class="math inline">\(\omega &gt; 0\)</span>. <span class="math inline">\(L_{n_1}=5\)</span>, best value of <span class="math inline">\(L_{n_2}\)</span> picked.</p>
<div class="body-centered">
<p>Delay vs.&nbsp;penalty (<span class="math inline">\(\omega\)</span> decreases to the right)</p>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>   Abilene</figcaption>
<p><img data-src="images/pen_vs_delay_abilene_v2.svg"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     4x4 Grid</figcaption>
<p><img data-src="images/pen_vs_delay_grid_v2.svg"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>Now we move on to a scenario with penalties, dropping the “naive” policies and keeping only the cost-aware adaptation of LFU as a baseline</li>
<li>We’ll be looking at how each policy balances the delay vs.&nbsp;penalty trade-off; total delay on the y-axis, total penalty on the x-axis</li>
<li>Now I want to point out here that different second tier capacities are used for the two policies. I experimented with a range of values for each and picked the best performing round value.</li>
<li>The reason for this connects to how well policies can actually use the larger capacities. As we saw from the last slide, not every policy can handle the same cache capacity as well.</li>
<li>The gist is that I want to represent the best of the competing policy and show that we’re still ahead.</li>
<li>As we can see, in the Abilene and Grid topologies our approach is generally outperforming the adapted LFU</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="results-ii-1" class="slide level2 smaller">
<h2>Results II</h2>
<p><strong>Scenario</strong>: Cost-unaware policies excluded, <span class="math inline">\(\omega &gt; 0\)</span>. Best value of <span class="math inline">\(L_{n_2}\)</span> picked.</p>
<div class="body-centered">
<p>Delay vs.&nbsp;penalty (<span class="math inline">\(\omega\)</span> decreases to the right)</p>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>    GEANT</figcaption>
<p><img data-src="images/pen_vs_delay_geant_v2.svg"></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>    3-Regular</figcaption>
<p><img data-src="images/pen_vs_delay_regular_v2.svg"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Experiments</p>
</div>
<aside class="notes">
<ul>
<li>The situation is similar for the Geant and 3-regular topologies as well, though in the latter, there is a small operating region where LFU overtakes our approach</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="proposed-work" class="title-slide slide level1 center">
<h1>Proposed Work</h1>

</section>
<section id="improvements" class="slide level2">
<h2>Improvements</h2>
<p>There is still room for improvement:</p>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/big-room.webp" class="quarto-figure quarto-figure-center" style="width:65.0%;height:65.0%"></p>
</figure>
</div>
<p>… and it’s a big room</p>
</div>
<div class="footer">
<p>Super Funny Joke</p>
</div>
<aside class="notes">
<ul>
<li>So as much as I’d like to say I’ll be pursuing a shiny new goal for the remainder of my time here, there are still aspects of this work that needs to be covered and improved</li>
<li>So this section will outline those improvements I’m planning on pursuing</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="improvements-1" class="slide level2">
<h2>Improvements</h2>
<p>There is still room for improvement:</p>
<div>
<ul>
<li class="fragment">Modeling of cache read rates</li>
<li class="fragment">Equal object sizes assumption</li>
<li class="fragment">Virtual plane - data plane gap</li>
<li class="fragment">Cache exclusivity constraint</li>
<li class="fragment">Better scalable simulator</li>
</ul>
</div>
<div class="footer">
<p>Proposed Work</p>
</div>
</section>
<section id="cache-read-bandwidth" class="slide level2">
<h2>Cache Read Bandwidth</h2>
<p>Model assumes read rate of each object is independent</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation}
    V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
    + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \sum\limits_{j \in \mathcal{J}_n} \color{#C8102E}{r_{n_j}} s^k_{n_j}(t) \Bigg)^+
\end{equation}\]</span>
</div>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside class="notes">
<ul>
<li>We treat the read rate parameter as if it is independent for each object, which indicates that there is a guaranteeable rate that can be provided per object, no matter how many objects are cached in that tier</li>
<li>This is an okay assumption, but given the strict rate limitations we’re working with, is not great</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="cache-read-bandwidth-1" class="slide level2">
<h2>Cache Read Bandwidth</h2>
<p>Model assumes read rate of each object is independent</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation}
    \color{#C0C0C0}{V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
    + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \sum\limits_{j \in \mathcal{J}_n}} \color{#C8102E}{r_{n_j}} \color{#C0C0C0}{s^k_{n_j}(t) \Bigg)^+}    
\end{equation}\]</span>
</div>
<p>Need to be more accurate for larger and slower caches</p>
<div style="font-size: 70%;">
<span class="math display">\[\begin{equation}
   \color{#C0C0C0}{V^k_n(t+1) \leq \Bigg(\Big(V^k_n(t) - \sum\limits_{b \in \mathcal{N}}\mu^k_{nb}(t)\Big)^+ + A^k_n(t)
   + \sum\limits_{a \in \mathcal{N}}\mu^k_{an}(t) - \sum\limits_{j \in \mathcal{J}_n}} \color{#C8102E}{r^k_{n_j}(t)} \color{#C0C0C0}{s^k_{n_j}(t) \Bigg)^+}
\end{equation}\]</span>
</div>
<span class="math display">\[\begin{equation}
   \sum_{\kin} r^k_{n_j}(t) \leq r_{n_j}   
\end{equation}\]</span>
<div class="footer">
<p>Proposed Work</p>
</div>
<aside class="notes">
<ul>
<li>The way we’ll do that is by enforcing a cache read bandwidth constraint</li>
<li>Additional control action each time slot, in product form with another control action</li>
<li>Stability region and its analysis changes significantly</li>
<li>Complexity of caching problem solution reduces</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="different-object-sizes" class="slide level2">
<h2>Different Object Sizes</h2>
<div>
<ul>
<li class="fragment">Equal object sizes assumption enables polynomial-time solution, but is not realistic</li>
<li class="fragment">Without it, we’ll need to solve a GAP (NP-hard)</li>
<li class="fragment">Need to reevaluate how we treat VIP counts:
<ul>
<li class="fragment">VIPs for smaller objects can be drained faster</li>
<li class="fragment">Service may prioritize smaller objects</li>
</ul></li>
</ul>
</div>
<div class="footer">
<p>Proposed Work</p>
</div>
</section>
<section id="virtual-plane---data-plane-gap" class="slide level2 smaller">
<h2>Virtual Plane - Data Plane Gap</h2>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>… oops, didn’t see you there</figcaption>
<p><img data-src="images/elephant.webp" style="width:65.0%;height:65.0%"></p>
</figure>
</div>
<audio data-autoplay="" id="elephant" src="audio/elephant.mp3">
</audio>
<script>
  var audio = document.getElementById("elephant");
  audio.volume = 0.1;
</script>
</div>
<div class="footer">
<p>Super Funny Callback</p>
</div>
<aside class="notes">
<ul>
<li>So this is the elephant in our room for improvement</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="virtual-plane---data-plane-gap-1" class="slide level2">
<h2>Virtual Plane - Data Plane Gap</h2>
<p>Disparities between the planes lead to a gap:</p>
<div>
<ul>
<li class="fragment">Virtual plane assumes nodes can immediately cache any object</li>
<li class="fragment"><span class="body-highlight">Upward migrations</span> not possible in data plane</li>
<li class="fragment">Data plane doesn’t allow <span class="body-highlight">redirecting</span> of cache hits</li>
<li class="fragment"><span class="body-highlight">Interest aggregation</span> extends this gap</li>
<li class="fragment">Amending the gap is difficult, but it can be quantified</li>
</ul>
</div>
<div class="footer">
<p>I also wanted to make “mind the gap” joke but there wasn’t a good place for it</p>
</div>
</section>
<section id="cache-exclusivity" class="slide level2">
<h2>Cache Exclusivity</h2>
<p>This constraint is reasonable, but very restrictive:</p>
<ul>
<li>Duplicates across tiers could extend bandwidth (SPDK, peer-to-peer DMA)</li>
<li>Minimal analytical implications, true impact can only be evaluated via experimentation</li>
</ul>
<div class="footer">
<p>Proposed Work</p>
</div>
</section>
<section id="better-experiments" class="slide level2">
<h2>Better Experiments</h2>
<div>
<ul>
<li class="fragment">Python is convenient but not highly-scalable for the task. Julia is a great alternative.</li>
<li class="fragment">Simulator core should be multi-threaded to improve <span class="body-highlight">scale-up</span>; per-experiment execution should <span class="body-highlight">scale-out</span>.</li>
<li class="fragment"><span class="body-highlight">Extendibility</span> and <span class="body-highlight">reproducibility</span> can still be improved.</li>
</ul>
</div>
<div class="footer">
<p>Proposed Work</p>
</div>
</section></section>
<section>
<section id="conclusion-other-work" class="title-slide slide level1 center">
<h1>Conclusion &amp; Other Work</h1>

</section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<div>
<ul>
<li class="fragment">We address a critical and practical problem in scaling high-throughput caching networks</li>
<li class="fragment">Our proposed model and approach achieves our goals and performs decently, but has shortcomings</li>
<li class="fragment">Some improvements can be made by reiterating on technical details, further fine tuning requires experimentation</li>
</ul>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
<aside class="notes">
<ul>
<li>I should also note that we submitted a paper on this to MobiHoc last year which was rejected</li>
<li>We’re currently revising the paper for the upcoming ICC</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="power-caching-in-wireless-hetnets" class="slide level2">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<ul>
<li>Delay minimization in multi-hop wireless HetNets via caching and power control (led by Derya Malak)</li>
</ul>
<p><img src="images/hetnet.svg" style="display: block; margin-left: auto; margin-right: auto; width: 40%; height: 40%;"></p>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-1" class="slide level2">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<ul>
<li>Delay minimization in multi-hop wireless HetNets via caching and power control</li>
<li>Contributed with:
<ul>
<li>Joint convexity analysis of optimization problem</li>
<li>Projected subgradient method algorithm for finding local minima</li>
<li>Simulator built in Julia, numerical experiments using said simulator</li>
</ul></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-2" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Model</strong>: Arbitrary multi-hop wireless heterogenous network (HetNet) topology:</p>
<ul>
<li>MCs, SCs, and users; MCs and SCs have wireline backhaul connections</li>
<li>All wireless transmissions share channel, i.e.&nbsp;no interference management</li>
<li>All nodes can be equipped with caches</li>
<li>Pre-determined shortest path (in hops) routing</li>
</ul>
<p><strong>Goal</strong>: Minimize delay in network by controlling power and caching allocation</p>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>HetNet illustration</figcaption>
<p><img data-src="images/hetnet.svg"></p>
</figure>
</div>
</div></div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-3" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p>
<span class="math display">\[\begin{equation}
\text{SINR}_{vu}(S)=\frac{ G_{vu}s_{vu}}{N_u+  \sum\limits_{j\in V\backslash v}G_{ju}\sum\limits_{w}s_{jw}+G_{vu}\sum\limits_{w\neq u}s_{vw}}
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
f(\text{SINR}_{vu}(S)) = \frac{1}{\log_2(1+\text{SINR}_{vu}(S))}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-4" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p>
<span class="math display">\[\begin{equation}
D_{(i,p)}^o(X,S)=\sum\limits_{k=1}^{|p|-1}f(\text{SINR}_{p_{k+1}p_k}(S))\prod\limits_{l=1}^k (1-x_{p_l i})
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
D^o(X,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)}{D_{(i,p)}^o(X,S)}}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-5" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p></li>
<li><p>Convex relaxation on these leads to reduced-complexity formulation (RCF)</p>
<span class="math display">\[\begin{equation}
D_{(i,p)}(Y,S)={\sum\limits_{k=1}^{|p|-1}f(\text{SINR}_{p_{k+1}p_k}(S)) g_{p_k i}(Y) }
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
g_{p_k i}(Y)=1-\min\Big\{1,\sum\limits_{l=1}^k y_{p_l i}\Big\},\,\quad\forall\, y_{p_li}\in [0, 1]
\end{equation}\]</span>
<span class="math display">\[\begin{equation}
D(Y,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)} D_{(i,p)}(Y,S)}
\end{equation}\]</span></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-6" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p><strong>Optimization</strong>: Minimize total delay of user requests:</p>
<ul>
<li><p>Wireless link transmission delay dependent on SINR</p></li>
<li><p>Problem is NP-hard due to integer constraints on caching variables</p></li>
<li><p>Convex relaxation on these leads to reduced-complexity formulation (RCF)</p>
<span class="math display">\[\begin{equation}
D(Y,S)=\sum\limits_{(i,p)\in\mathcal{R}}{\lambda_{(i,p)} D_{(i,p)}(Y,S)}
\end{equation}\]</span></li>
<li><p>RCF is not jointly convex in power and caching</p></li>
</ul>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="subgradient-projection-algorithm" class="slide level2 smaller">
<h2>Subgradient Projection Algorithm</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 90%;">
<div class="pseudocode-container quarto-float" data-caption-prefix="Algorithm" data-pseudocode-number="1" data-line-number="true">
<div class="pseudocode">
\begin{algorithm} \caption{Subgradient Projection}\begin{algorithmic} \State{Choose $S^{0}$, $Y^{0}$, small scalar $\epsilon &gt; 0$ and let $t=0$.} \While{$D^t - D^{t-1} &gt; \epsilon \;$} \State{Compute subgradients $d^t_S, d^t_Y$.} \State{Determine step sizes $\xi^t_Y$, $\xi^t_S $.} \State{Compute projected variables $\bar{S}^t$, ${\bar{Y}}^t$.} \State{$t \gets t+1, S^{t+1} \gets \bar{S}^t, Y^{t+1} \gets \bar{Y}^t$.} \EndWhile \State{$(Y^{*}_{sub},S^{*}_{sub}) \gets (Y^{t},S^{t})$.} \State{Perform pipage rounding on $(Y^{*}_{sub},S^{*}_{sub})$.} \end{algorithmic} \end{algorithm}
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="font-size: 80%;">
<span class="math display">\[\begin{equation*}
\begin{split}
    &amp; \quad d_S^t = \nabla_S D(Y^t,S^t), \; d^t_{Y} \in \partial_{Y}D(Y^t,S^t) \\
    &amp; \quad \xi^t_{Y} = \frac{D^t - \hat{D}^t}{\norm{d_{Y}^t}}, \; \xi_S^t = \frac{D^t - \hat{D}^t}{\norm{d_S^t}} \\
    &amp; \quad \bar{S}^t = \mc{P}_{\mc{D}_S}(S^t - \xi_{S}^t d_{S}^t), \; \bar{Y}^t = \mc{P}_{\mc{D}_Y}(Y^t - \xi^t_{Y} d^t_{Y})
\end{split}
\end{equation*}\]</span>
</div>
</div></div>
<div class="footer">
<p>Power &amp; Caching in Wireless HetNets</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-7" class="slide level2 smaller">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Use projected subgradient method to solve for local minima in general case</p>
<span class="math display">\[\begin{equation}
\begin{aligned}
    &amp; S^{t+1} = S^t + \xi_S^t(\bar{S}^t - S^t) \\
    &amp; \bar{S}^t = [S^t - w_S^t d_S^t]^+_{\mathcal{D}_S} \\
    &amp; \boldsymbol{y}^{t+1} = \boldsymbol{y}^t + \xi^t_{\boldsymbol{y}}(\boldsymbol{\bar{y}}^t - \boldsymbol{y}^t) \\
    &amp; \boldsymbol{\bar{y}}^t = [\boldsymbol{y}^t - w_Y^t d^t_{\boldsymbol{y}}]^+_{\mathcal{D}_{\boldsymbol{y}}} \\
    &amp; d_S^t = \nabla_S D(Y^t,S^t), \; d^t_{\boldsymbol{y}} \in \partial_{\boldsymbol{y}}D(Y^t,S^t) \\
    &amp; \xi^t_{\boldsymbol{y}} = \frac{D^t - \hat{D}^t}{||d_{\boldsymbol{y}}^t||^2}, \; \xi_S^t = \frac{D^t - \hat{D}^t}{||d_S^t||^2}
\end{aligned}
\end{equation}\]</span>
</div><div class="column" style="width:50%;">
<p><strong>Projected Subgradient Method</strong></p>
<ul>
<li><p>Initialize: Choose <span class="math inline">\(S^{0}\)</span>, <span class="math inline">\(\boldsymbol{y}^{0}\)</span></p></li>
<li><p><strong>do</strong></p>
<ul>
<li>Compute subgradient <span class="math inline">\(d^t_S, d^t_{\boldsymbol{y}}\)</span></li>
<li>Determine step sizes <span class="math inline">\(\xi^t_{\boldsymbol{y}}\)</span>, <span class="math inline">\(\xi_S^t\)</span></li>
<li>Compute projected variables <span class="math inline">\(\boldsymbol{\bar{y}}^t\)</span>, <span class="math inline">\(\bar{S}^t\)</span></li>
<li>Update <span class="math inline">\(S^{t+1}\)</span> and <span class="math inline">\(\boldsymbol{y}^{t+1}\)</span></li>
<li>Let <span class="math inline">\(t=t+1\)</span></li>
</ul></li>
<li><p><strong>while</strong> <span class="math inline">\(D^t - D^{t-1} &gt; \epsilon\)</span></p></li>
<li><p>Let <span class="math inline">\((\boldsymbol{y}^{*}_{sub},S^{*}_{sub}) = (\boldsymbol{y}^{t},S^{t})\)</span></p></li>
<li><p>Rounding</p></li>
</ul>
</div></div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-8" class="slide level2 smaller" data-visibility="uncounted">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     Power budget</figcaption>
<p><img data-src="images/hetnet_result1.svg" style="width:55.0%;height:55.0%"></p>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-9" class="slide level2 smaller" data-visibility="uncounted">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     SC cache capacity</figcaption>
<p><img data-src="images/hetnet_result3.svg" style="width:55.0%;height:55.0%"></p>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section>
<section id="power-caching-in-wireless-hetnets-10" class="slide level2 smaller" data-visibility="uncounted">
<h2>Power &amp; Caching in Wireless HetNets</h2>
<p>Experimental results under different scenarios compare performance against baseline replacement policies paired with cache-unaware power optimization</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>     Zipf parameter</figcaption>
<p><img data-src="images/hetnet_result2.svg" style="width:55.0%;height:55.0%"></p>
</figure>
</div>
<div class="footer">
<p>Conclusion &amp; Other Work</p>
</div>
</section></section>
<section>
<section id="appendices" class="title-slide slide level1 center" data-visibility="uncounted">
<h1>Appendices</h1>

</section>
<section id="appendix-a-pseudocode" class="slide level2">
<h2>Appendix A: Pseudocode</h2>
<div style="font-size: 50%;">
<div class="pseudocode-container quarto-float" data-caption-prefix="Algorithm" data-pseudocode-number="1">
<div class="pseudocode">
\begin{algorithm} \caption{Quicksort} \begin{algorithmic} \Procedure{Quicksort}{$A, p, r$} \If{$p &lt; r$} \State $q = $ \Call{Partition}{$A, p, r$} \State \Call{Quicksort}{$A, p, q - 1$} \State \Call{Quicksort}{$A, q + 1, r$} \EndIf \EndProcedure \Procedure{Partition}{$A, p, r$} \State $x = A[r]$ \State $i = p - 1$ \For{$j = p$ \To $r - 1$} \If{$A[j] &lt; x$} \State $i = i + 1$ \State exchange $A[i]$ with $A[j]$ \EndIf \State exchange $A[i]$ with $A[r]$ \EndFor \EndProcedure \end{algorithmic} \end{algorithm}
</div>
</div>
</div>
<div class="footer">
<p>Appendices</p>
</div>
</section>
<section id="appendix-b-model-notation" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix B: Model Notation</h2>
<table class="caption-top">
<caption>Table of Notations</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 80%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mathcal{G}\)</span></td>
<td style="text-align: left;">Directed graph representing the network topology</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\((\mathcal{N},\mathcal{L})\)</span></td>
<td style="text-align: left;">Set of nodes and links in <span class="math inline">\(\mathcal{G}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(C_{ab}\)</span></td>
<td style="text-align: left;">Transmission capacity (in objects/sec) of link <span class="math inline">\((a,b)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mathcal{K}\)</span></td>
<td style="text-align: left;">Set of data objects in the network</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mc{S}(k)\)</span></td>
<td style="text-align: left;">Content source node for <span class="math inline">\(k \in \mathcal{K}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mathcal{J}_n\)</span></td>
<td style="text-align: left;">Set of cache tiers at node <span class="math inline">\(n \in \mathcal{N}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(L_{n_j}\)</span></td>
<td style="text-align: left;">Size (in objects) of cache tier <span class="math inline">\(j \in \mathcal{J}_n\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(r_{n_j}\)</span></td>
<td style="text-align: left;">Read rate of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(c^a_{n_j}\)</span></td>
<td style="text-align: left;">Admission cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(c^e_{n_j}\)</span></td>
<td style="text-align: left;">Eviction cost of tier <span class="math inline">\(j\)</span> at node <span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Appendices</p>
</div>
</section>
<section id="appendix-b-model-notation-1" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix B: Model Notation</h2>
<table class="caption-top">
<caption>Table of Notations</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 80%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\lambda^k_n\)</span></td>
<td style="text-align: left;">Exogenous request arrival rate for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(t\)</span></td>
<td style="text-align: left;">Time slot referring to time interval <span class="math inline">\([t, t+1)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(A^k_n(t)\)</span></td>
<td style="text-align: left;">Number of exogenous requests for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(s^k_{n_j}(t)\)</span></td>
<td style="text-align: left;">Caching state of <span class="math inline">\(k\)</span> in tier <span class="math inline">\(j\)</span> at <span class="math inline">\(n\)</span> at the beginning of <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(p^k_{n_j}(t)\)</span></td>
<td style="text-align: left;">Penalty incurred by the choice of <span class="math inline">\(s^k_{n_j}(t)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(p(t)\)</span></td>
<td style="text-align: left;">Sum penalty incurred during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\omega\)</span></td>
<td style="text-align: left;">Penalty importance weight</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(V^k_n(t)\)</span></td>
<td style="text-align: left;">VIP count for <span class="math inline">\(k\)</span> at <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mathbf{V}(t)\)</span></td>
<td style="text-align: left;">Vector of VIP queue states during <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mu^k_{ab}(t)\)</span></td>
<td style="text-align: left;">Allocated rate of VIPs for <span class="math inline">\(k\)</span> over <span class="math inline">\((a,b)\)</span> during <span class="math inline">\(t\)</span></td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Appendices</p>
</div>
</section>
<section id="appendix-c-analysis-notation" class="slide level2 smaller" data-visibility="uncounted">
<h2>Appendix C: Analysis Notation</h2>
<table class="caption-top">
<colgroup>
<col style="width: 30%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Notation</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(A^k_{n,max}\)</span></td>
<td style="text-align: left;">Finite value such that <span class="math inline">\(A^k_n(t) \leq A^k_{n,max}\)</span> for all <span class="math inline">\(t\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(A_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total exogenous arrivals at node <span class="math inline">\(n\)</span> during <span class="math inline">\(t\)</span> across all <span class="math inline">\(\kin\)</span>, i.e.&nbsp;<span class="math inline">\(A_{n,max} \triangleq \sum_{\kin}A^k_{n,max}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\mu^{out}_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total allocated transmission rate for VIPs across all <span class="math inline">\((n,b) \in \mc{L}\)</span>, i.e.&nbsp;<span class="math inline">\(\mu^{out}_{n,max} \triangleq \sum_{\bin}C_{nb}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\mu^{in}_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total allocated transmission rate for VIPs across all <span class="math inline">\((a,n) \in \mc{L}\)</span>, i.e.&nbsp;<span class="math inline">\(\mu^{in}_{n,max} \triangleq \sum_{\bin}C_{an}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(r_{n,max}\)</span></td>
<td style="text-align: left;">Maximum total rate that can be served by all cache tiers at <span class="math inline">\(n\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\Psi(\boldsymbol{\lambda})\)</span></td>
<td style="text-align: left;">Minimum time-average sum penalty achievable by a feasible and stabilizing randomized policy</td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Appendices</p>
</div>
<div class="quarto-auto-generated-content">
<p><img src="images/neu_logo.svg" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section></section>

    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="index_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="index_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="index_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="index_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="index_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="index_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="index_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
        <script type="text/javascript">
        (function(d) {
          d.querySelectorAll(".pseudocode-container").forEach(function(el) {
            let pseudocodeOptions = {
              indentSize: el.dataset.indentSize || "1.2em",
              commentDelimiter: el.dataset.commentDelimiter || "//",
              lineNumber: el.dataset.lineNumber === "true" ? true : false,
              lineNumberPunc: el.dataset.lineNumberPunc || ":",
              noEnd: el.dataset.noEnd === "true" ? true : false,
              titlePrefix: el.dataset.captionPrefix || "Algorithm"
            };
            pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
          });
        })(document);
        (function(d) {
          d.querySelectorAll(".pseudocode-container").forEach(function(el) {
            let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
            if (captionSpan !== null) {
              let captionPrefix = el.dataset.captionPrefix + " ";
              let captionNumber = "";
              if (el.dataset.pseudocodeNumber) {
                captionNumber = el.dataset.pseudocodeNumber + " ";
                if (el.dataset.chapterLevel) {
                  captionNumber = el.dataset.chapterLevel + "." + captionNumber;
                }
              }
              captionSpan.innerHTML = captionPrefix + captionNumber;
            }
          });
        })(document);
        </script>
      
    

</body></html>